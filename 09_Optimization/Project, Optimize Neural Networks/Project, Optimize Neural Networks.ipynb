{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a binary classification dataset\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=5, n_informative=2, n_redundant=1, random_state=1)\n",
    "\n",
    "# summarize the shape of the dataset\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple perceptron model for binary classification\n",
    "from numpy.random import rand\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# transfer function\n",
    "def transfer(activation):\n",
    "    if activation >= 0.0:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "# activation function\n",
    "def activate(row, weights):\n",
    "    \n",
    "    # add the bias, the last weight\n",
    "    activation = weights[-1]\n",
    "    \n",
    "    # add the weighted input\n",
    "    for i in range(len(row)):\n",
    "        activation += weights[i] * row[i]\n",
    "    return activation\n",
    "\n",
    "# use model weights to predict 0 or 1 for a given row of data\n",
    "def predict_row(row, weights):\n",
    "    \n",
    "    # activate for input\n",
    "    activation = activate(row, weights)\n",
    "    \n",
    "    # transfer for activation\n",
    "    return transfer(activation)\n",
    "\n",
    "# use model weights to generate predictions for a dataset of rows\n",
    "def predict_dataset(X, weights):\n",
    "    yhats = list()\n",
    "    for row in X:\n",
    "        yhat = predict_row(row, weights)\n",
    "        yhats.append(yhat)\n",
    "    return yhats\n",
    "\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=5, n_informative=2, n_redundant=1, random_state=1)\n",
    "\n",
    "# determine the number of weights\n",
    "n_weights = X.shape[1] + 1\n",
    "\n",
    "# generate random weights\n",
    "weights = rand(n_weights)\n",
    "\n",
    "# generate predictions for dataset\n",
    "yhat = predict_dataset(X, weights)\n",
    "\n",
    "# calculate accuracy\n",
    "score = accuracy_score(y, yhat)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hill climbing to optimize weights of a perceptron model for classification\n",
    "from numpy import asarray\n",
    "from numpy.random import randn\n",
    "from numpy.random import rand\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# transfer function\n",
    "def transfer(activation):\n",
    "    if activation >= 0.0:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "# activation function\n",
    "def activate(row, weights):\n",
    "    \n",
    "    # add the bias, the last weight\n",
    "    activation = weights[-1]\n",
    "    \n",
    "    # add the weighted input\n",
    "    for i in range(len(row)):\n",
    "        activation += weights[i] * row[i]\n",
    "    return activation\n",
    "\n",
    "# # use model weights to predict 0 or 1 for a given row of data\n",
    "def predict_row(row, weights):\n",
    "    \n",
    "    # activate for input\n",
    "    activation = activate(row, weights)\n",
    "    \n",
    "    # transfer for activation\n",
    "    return transfer(activation)\n",
    "\n",
    "# use model weights to generate predictions for a dataset of rows\n",
    "def predict_dataset(X, weights):\n",
    "    yhats = list()\n",
    "    for row in X:\n",
    "        yhat = predict_row(row, weights)\n",
    "        yhats.append(yhat)\n",
    "    return yhats\n",
    "\n",
    "# objective function\n",
    "def objective(X, y, weights):\n",
    "    \n",
    "    # generate predictions for dataset\n",
    "    yhat = predict_dataset(X, weights)\n",
    "    \n",
    "    # calculate accuracy\n",
    "    score = accuracy_score(y, yhat)\n",
    "    return score\n",
    "\n",
    "# hill climbing local search algorithm\n",
    "def hillclimbing(X, y, objective, solution, n_iter, step_size):\n",
    "    \n",
    "    # evaluate the initial point\n",
    "    solution_eval = objective(X, y, solution)\n",
    "    \n",
    "    # run the hill climb\n",
    "    for i in range(n_iter):\n",
    "        \n",
    "        # take a step\n",
    "        candidate = solution + randn(len(solution)) * step_size\n",
    "        \n",
    "        # evaluate candidate point\n",
    "        candidte_eval = objective(X, y, candidate)\n",
    "        \n",
    "        # check if we should keep the new point\n",
    "        if candidte_eval >= solution_eval:\n",
    "            \n",
    "            # store the new point\n",
    "            solution, solution_eval = candidate, candidte_eval\n",
    "            \n",
    "            # report progress\n",
    "            print('>%d %.5f' % (i, solution_eval))\n",
    "    return [solution, solution_eval]\n",
    "\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=5, n_informative=2, n_redundant=1, random_state=1)\n",
    "\n",
    "# split into train test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "# define the total iterations\n",
    "n_iter = 1000\n",
    "\n",
    "# define the maximum step size\n",
    "step_size = 0.05\n",
    "\n",
    "# determine the number of weights\n",
    "n_weights = X.shape[1] + 1\n",
    "\n",
    "# define the initial solution\n",
    "solution = rand(n_weights)\n",
    "\n",
    "# perform the hill climbing search\n",
    "weights, score = hillclimbing(X_train, y_train, objective, solution, n_iter, step_size)\n",
    "print('Done!')\n",
    "print('f(%s) = %f' % (weights, score))\n",
    "\n",
    "# generate predictions for the test dataset\n",
    "yhat = predict_dataset(X_test, weights)\n",
    "\n",
    "# calculate accuracy\n",
    "score = accuracy_score(y_test, yhat)\n",
    "print('Test Accuracy: %.5f' % (score * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# develop an mlp model for classification\n",
    "from math import exp\n",
    "from numpy.random import rand\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# transfer function\n",
    "def transfer(activation):\n",
    "    # sigmoid transfer function\n",
    "    return 1.0 / (1.0 + exp(-activation))\n",
    "\n",
    "# activation function\n",
    "def activate(row, weights):\n",
    "    \n",
    "    # add the bias, the last weight\n",
    "    activation = weights[-1]\n",
    "    \n",
    "    # add the weighted input\n",
    "    for i in range(len(row)):\n",
    "        activation += weights[i] * row[i]\n",
    "    return activation\n",
    "\n",
    "# activation function for a network\n",
    "def predict_row(row, network):\n",
    "    inputs = row\n",
    "    \n",
    "    # enumerate the layers in the network from input to output\n",
    "    for layer in network:\n",
    "        new_inputs = list()\n",
    "        \n",
    "        # enumerate nodes in the layer\n",
    "        for node in layer:\n",
    "            \n",
    "            # activate the node\n",
    "            activation = activate(inputs, node)\n",
    "            \n",
    "            # transfer activation\n",
    "            output = transfer(activation)\n",
    "            \n",
    "            # store output\n",
    "            new_inputs.append(output)\n",
    "            \n",
    "        # output from this layer is input to the next layer\n",
    "        inputs = new_inputs\n",
    "    return inputs[0]\n",
    "\n",
    "# use model weights to generate predictions for a dataset of rows\n",
    "def predict_dataset(X, network):\n",
    "    yhats = list()\n",
    "    for row in X:\n",
    "        yhat = predict_row(row, network)\n",
    "        yhats.append(yhat)\n",
    "    return yhats\n",
    "\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=5, n_informative=2, n_redundant=1, random_state=1)\n",
    "\n",
    "# determine the number of inputs\n",
    "n_inputs = X.shape[1]\n",
    "\n",
    "# one hidden layer and an output layer\n",
    "n_hidden = 10\n",
    "hidden1 = [rand(n_inputs + 1) for _ in range(n_hidden)]\n",
    "output1 = [rand(n_hidden + 1)]\n",
    "network = [hidden1, output1]\n",
    "\n",
    "# generate predictions for dataset\n",
    "yhat = predict_dataset(X, network)\n",
    "\n",
    "# round the predictions\n",
    "yhat = [round(y) for y in yhat]\n",
    "\n",
    "# calculate accuracy\n",
    "score = accuracy_score(y, yhat)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stochastic hill climbing to optimize a multilayer perceptron for classification\n",
    "from math import exp\n",
    "from numpy.random import randn\n",
    "from numpy.random import rand\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# transfer function\n",
    "def transfer(activation):\n",
    "    \n",
    "    # sigmoid transfer function\n",
    "    return 1.0 / (1.0 + exp(-activation))\n",
    "\n",
    "# activation function\n",
    "def activate(row, weights):\n",
    "    \n",
    "    # add the bias, the last weight\n",
    "    activation = weights[-1]\n",
    "    \n",
    "    # add the weighted input\n",
    "    for i in range(len(row)):\n",
    "        activation += weights[i] * row[i]\n",
    "    return activation\n",
    "\n",
    "# activation function for a network\n",
    "def predict_row(row, network):\n",
    "    inputs = row\n",
    "    \n",
    "    # enumerate the layers in the network from input to output\n",
    "    for layer in network:\n",
    "        new_inputs = list()\n",
    "        \n",
    "        # enumerate nodes in the layer\n",
    "        for node in layer:\n",
    "            \n",
    "            # activate the node\n",
    "            activation = activate(inputs, node)\n",
    "            \n",
    "            # transfer activation\n",
    "            output = transfer(activation)\n",
    "            \n",
    "            # store output\n",
    "            new_inputs.append(output)\n",
    "            \n",
    "        # output from this layer is input to the next layer\n",
    "        inputs = new_inputs\n",
    "    return inputs[0]\n",
    "\n",
    "# use model weights to generate predictions for a dataset of rows\n",
    "def predict_dataset(X, network):\n",
    "    yhats = list()\n",
    "    for row in X:\n",
    "        yhat = predict_row(row, network)\n",
    "        yhats.append(yhat)\n",
    "    return yhats\n",
    "\n",
    "# objective function\n",
    "def objective(X, y, network):\n",
    "    \n",
    "    # generate predictions for dataset\n",
    "    yhat = predict_dataset(X, network)\n",
    "    \n",
    "    # round the predictions\n",
    "    yhat = [round(y) for y in yhat]\n",
    "    \n",
    "    # calculate accuracy\n",
    "    score = accuracy_score(y, yhat)\n",
    "    return score\n",
    "\n",
    "# take a step in the search space\n",
    "def step(network, step_size):\n",
    "    new_net = list()\n",
    "    \n",
    "    # enumerate layers in the network\n",
    "    for layer in network:\n",
    "        new_layer = list()\n",
    "        \n",
    "        # enumerate nodes in this layer\n",
    "        for node in layer:\n",
    "            \n",
    "            # mutate the node\n",
    "            new_node = node.copy() + randn(len(node)) * step_size\n",
    "            \n",
    "            # store node in layer\n",
    "            new_layer.append(new_node)\n",
    "            \n",
    "        # store layer in network\n",
    "        new_net.append(new_layer)\n",
    "    return new_net\n",
    "\n",
    "# hill climbing local search algorithm\n",
    "def hillclimbing(X, y, objective, solution, n_iter, step_size):\n",
    "    \n",
    "    # evaluate the initial point\n",
    "    solution_eval = objective(X, y, solution)\n",
    "    \n",
    "    # run the hill climb\n",
    "    for i in range(n_iter):\n",
    "        \n",
    "        # take a step\n",
    "        candidate = step(solution, step_size)\n",
    "        \n",
    "        # evaluate candidate point\n",
    "        candidte_eval = objective(X, y, candidate)\n",
    "        \n",
    "        # check if we should keep the new point\n",
    "        if candidte_eval >= solution_eval:\n",
    "            \n",
    "            # store the new point\n",
    "            solution, solution_eval = candidate, candidte_eval\n",
    "            \n",
    "            # report progress\n",
    "            print('>%d %f' % (i, solution_eval))\n",
    "    return [solution, solution_eval]\n",
    "\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=5, n_informative=2, n_redundant=1, random_state=1)\n",
    "\n",
    "# split into train test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "# define the total iterations\n",
    "n_iter = 1000\n",
    "\n",
    "# define the maximum step size\n",
    "step_size = 0.1\n",
    "\n",
    "# determine the number of inputs\n",
    "n_inputs = X.shape[1]\n",
    "\n",
    "# one hidden layer and an output layer, each perceptron has a bias term\n",
    "n_hidden = 10\n",
    "hidden1 = [rand(n_inputs + 1) for _ in range(n_hidden)]\n",
    "output1 = [rand(n_hidden + 1)]\n",
    "network = [hidden1, output1]\n",
    "\n",
    "# perform the hill climbing search\n",
    "network, score = hillclimbing(X_train, y_train, objective, network, n_iter, step_size)\n",
    "print('Done!')\n",
    "print('Best: %f' % (score))\n",
    "\n",
    "# generate predictions for the test dataset\n",
    "yhat = predict_dataset(X_test, network)\n",
    "\n",
    "# round the predictions\n",
    "yhat = [round(y) for y in yhat]\n",
    "\n",
    "# calculate accuracy\n",
    "score = accuracy_score(y_test, yhat)\n",
    "print('Test Accuracy: %.5f' % (score * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
