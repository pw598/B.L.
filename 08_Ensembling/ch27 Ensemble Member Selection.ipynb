{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test classification dataset\n",
    "from sklearn.datasets import make_classification\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=5000, n_features=20, n_informative=10, n_redundant=10, random_state=1)\n",
    "# summarize the dataset\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate standard models on the synthetic dataset\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "\tX, y = make_classification(n_samples=5000, n_features=20, n_informative=10, n_redundant=10, random_state=1)\n",
    "\treturn X, y\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = list()\n",
    "\tmodels.append(('lr', LogisticRegression()))\n",
    "\tmodels.append(('knn', KNeighborsClassifier()))\n",
    "\tmodels.append(('tree', DecisionTreeClassifier()))\n",
    "\tmodels.append(('nb', GaussianNB()))\n",
    "\tmodels.append(('svm', SVC(probability=True)))\n",
    "\treturn models\n",
    "\n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "\t# define the model evaluation procedure\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\t# evaluate the model\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\treturn scores\n",
    "\n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models:\n",
    "\t# evaluate model\n",
    "\tscores = evaluate_model(model, X, y)\n",
    "\t# store results\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\t# summarize result\n",
    "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of a voting ensemble with soft voting of ensemble members\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "\tX, y = make_classification(n_samples=5000, n_features=20, n_informative=10, n_redundant=10, random_state=1)\n",
    "\treturn X, y\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = list()\n",
    "\tmodels.append(('lr', LogisticRegression()))\n",
    "\tmodels.append(('knn', KNeighborsClassifier()))\n",
    "\tmodels.append(('tree', DecisionTreeClassifier()))\n",
    "\tmodels.append(('nb', GaussianNB()))\n",
    "\tmodels.append(('svm', SVC(probability=True)))\n",
    "\treturn models\n",
    "\n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# create the ensemble\n",
    "ensemble = VotingClassifier(estimators=models, voting='soft')\n",
    "# define the evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate the ensemble\n",
    "scores = cross_val_score(ensemble, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# summarize the result\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of ensemble pruning for classification\n",
    "from numpy import mean\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "\tX, y = make_classification(n_samples=5000, n_features=20, n_informative=10, n_redundant=10, random_state=1)\n",
    "\treturn X, y\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = list()\n",
    "\tmodels.append(('lr', LogisticRegression()))\n",
    "\tmodels.append(('knn', KNeighborsClassifier()))\n",
    "\tmodels.append(('tree', DecisionTreeClassifier()))\n",
    "\tmodels.append(('nb', GaussianNB()))\n",
    "\tmodels.append(('svm', SVC(probability=True)))\n",
    "\treturn models\n",
    "\n",
    "# evaluate a list of models\n",
    "def evaluate_ensemble(models, X, y):\n",
    "\t# check for no models\n",
    "\tif len(models) == 0:\n",
    "\t\treturn 0.0\n",
    "\t# create the ensemble\n",
    "\tensemble = VotingClassifier(estimators=models, voting='soft')\n",
    "\t# define the evaluation procedure\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\t# evaluate the ensemble\n",
    "\tscores = cross_val_score(ensemble, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\t# return mean score\n",
    "\treturn mean(scores)\n",
    "\n",
    "# perform a single round of pruning the ensemble\n",
    "def prune_round(models_in, X, y):\n",
    "\t# establish a baseline\n",
    "\tbaseline = evaluate_ensemble(models_in, X, y)\n",
    "\tbest_score, removed = baseline, None\n",
    "\t# enumerate removing each candidate and see if we can improve performance\n",
    "\tfor m in models_in:\n",
    "\t\t# copy the list of chosen models\n",
    "\t\tdup = models_in.copy()\n",
    "\t\t# remove this model\n",
    "\t\tdup.remove(m)\n",
    "\t\t# evaluate new ensemble\n",
    "\t\tresult = evaluate_ensemble(dup, X, y)\n",
    "\t\t# check for new best\n",
    "\t\tif result > best_score:\n",
    "\t\t\t# store the new best\n",
    "\t\t\tbest_score, removed = result, m\n",
    "\treturn best_score, removed\n",
    "\n",
    "# prune an ensemble from scratch\n",
    "def prune_ensemble(models, X, y):\n",
    "\tbest_score = 0.0\n",
    "\t# prune ensemble until no further improvement\n",
    "\twhile True:\n",
    "\t\t# remove one model to the ensemble\n",
    "\t\tscore, removed = prune_round(models, X, y)\n",
    "\t\t# check for no improvement\n",
    "\t\tif removed is None:\n",
    "\t\t\tprint('>no further improvement')\n",
    "\t\t\tbreak\n",
    "\t\t# keep track of best score\n",
    "\t\tbest_score = score\n",
    "\t\t# remove model from the list\n",
    "\t\tmodels.remove(removed)\n",
    "\t\t# report results along the way\n",
    "\t\tprint('>%.3f (removed: %s)' % (score, removed[0]))\n",
    "\treturn best_score, models\n",
    "\n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# prune the ensemble\n",
    "score, model_list = prune_ensemble(models, X, y)\n",
    "names = ','.join([n for n,_ in model_list])\n",
    "print('Models: %s' % names)\n",
    "print('Final Mean Accuracy: %.3f' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of ensemble growing for classification\n",
    "from numpy import mean\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "\tX, y = make_classification(n_samples=5000, n_features=20, n_informative=10, n_redundant=10, random_state=1)\n",
    "\treturn X, y\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = list()\n",
    "\tmodels.append(('lr', LogisticRegression()))\n",
    "\tmodels.append(('knn', KNeighborsClassifier()))\n",
    "\tmodels.append(('tree', DecisionTreeClassifier()))\n",
    "\tmodels.append(('nb', GaussianNB()))\n",
    "\tmodels.append(('svm', SVC(probability=True)))\n",
    "\treturn models\n",
    "\n",
    "# evaluate a list of models\n",
    "def evaluate_ensemble(models, X, y):\n",
    "\t# check for no models\n",
    "\tif len(models) == 0:\n",
    "\t\treturn 0.0\n",
    "\t# create the ensemble\n",
    "\tensemble = VotingClassifier(estimators=models, voting='soft')\n",
    "\t# define the evaluation procedure\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\t# evaluate the ensemble\n",
    "\tscores = cross_val_score(ensemble, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\t# return mean score\n",
    "\treturn mean(scores)\n",
    "\n",
    "# perform a single round of growing the ensemble\n",
    "def grow_round(models_in, models_candidate, X, y):\n",
    "\t# establish a baseline\n",
    "\tbaseline = evaluate_ensemble(models_in, X, y)\n",
    "\tbest_score, addition = baseline, None\n",
    "\t# enumerate adding each candidate and see if we can improve performance\n",
    "\tfor m in models_candidate:\n",
    "\t\t# copy the list of chosen models\n",
    "\t\tdup = models_in.copy()\n",
    "\t\t# add the candidate\n",
    "\t\tdup.append(m)\n",
    "\t\t# evaluate new ensemble\n",
    "\t\tresult = evaluate_ensemble(dup, X, y)\n",
    "\t\t# check for new best\n",
    "\t\tif result > best_score:\n",
    "\t\t\t# store the new best\n",
    "\t\t\tbest_score, addition = result, m\n",
    "\treturn best_score, addition\n",
    "\n",
    "# grow an ensemble from scratch\n",
    "def grow_ensemble(models, X, y):\n",
    "\tbest_score, best_list = 0.0, list()\n",
    "\t# grow ensemble until no further improvement\n",
    "\twhile True:\n",
    "\t\t# add one model to the ensemble\n",
    "\t\tscore, addition = grow_round(best_list, models, X, y)\n",
    "\t\t# check for no improvement\n",
    "\t\tif addition is None:\n",
    "\t\t\tprint('>no further improvement')\n",
    "\t\t\tbreak\n",
    "\t\t# keep track of best score\n",
    "\t\tbest_score = score\n",
    "\t\t# remove new model from the list of candidates\n",
    "\t\tmodels.remove(addition)\n",
    "\t\t# add new model to the list of models in the ensemble\n",
    "\t\tbest_list.append(addition)\n",
    "\t\t# report results along the way\n",
    "\t\tnames = ','.join([n for n,_ in best_list])\n",
    "\t\tprint('>%.3f (%s)' % (score, names))\n",
    "\treturn best_score, best_list\n",
    "\n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# grow the ensemble\n",
    "score, model_list = grow_ensemble(models, X, y)\n",
    "names = ','.join([n for n,_ in model_list])\n",
    "print('Models: %s' % names)\n",
    "print('Final Mean Accuracy: %.3f' % score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
