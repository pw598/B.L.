{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic binary classification dataset\n",
    "from sklearn.datasets import make_classification\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=10000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "# summarize the dataset\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blending ensemble for classification using hard voting\n",
    "from numpy import hstack\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "\tX, y = make_classification(n_samples=10000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "\treturn X, y\n",
    "\n",
    "# get a list of base models\n",
    "def get_models():\n",
    "\tmodels = list()\n",
    "\tmodels.append(('lr', LogisticRegression()))\n",
    "\tmodels.append(('knn', KNeighborsClassifier()))\n",
    "\tmodels.append(('cart', DecisionTreeClassifier()))\n",
    "\tmodels.append(('svm', SVC()))\n",
    "\tmodels.append(('bayes', GaussianNB()))\n",
    "\treturn models\n",
    "\n",
    "# fit the blending ensemble\n",
    "def fit_ensemble(models, X_train, X_val, y_train, y_val):\n",
    "\t# fit all models on the training set and predict on hold out set\n",
    "\tmeta_X = list()\n",
    "\tfor _, model in models:\n",
    "\t\t# fit in training set\n",
    "\t\tmodel.fit(X_train, y_train)\n",
    "\t\t# predict on hold out set\n",
    "\t\tyhat = model.predict(X_val)\n",
    "\t\t# reshape predictions into a matrix with one column\n",
    "\t\tyhat = yhat.reshape(len(yhat), 1)\n",
    "\t\t# store predictions as input for blending\n",
    "\t\tmeta_X.append(yhat)\n",
    "\t# create 2d array from predictions, each set is an input feature\n",
    "\tmeta_X = hstack(meta_X)\n",
    "\t# define blending model\n",
    "\tblender = LogisticRegression()\n",
    "\t# fit on predictions from base models\n",
    "\tblender.fit(meta_X, y_val)\n",
    "\treturn blender\n",
    "\n",
    "# make a prediction with the blending ensemble\n",
    "def predict_ensemble(models, blender, X_test):\n",
    "\t# make predictions with base models\n",
    "\tmeta_X = list()\n",
    "\tfor _, model in models:\n",
    "\t\t# predict with base model\n",
    "\t\tyhat = model.predict(X_test)\n",
    "\t\t# reshape predictions into a matrix with one column\n",
    "\t\tyhat = yhat.reshape(len(yhat), 1)\n",
    "\t\t# store prediction\n",
    "\t\tmeta_X.append(yhat)\n",
    "\t# create 2d array from predictions, each set is an input feature\n",
    "\tmeta_X = hstack(meta_X)\n",
    "\t# predict\n",
    "\treturn blender.predict(meta_X)\n",
    "\n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# split dataset into train and test sets\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.5, random_state=1)\n",
    "# split training set into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.33, random_state=1)\n",
    "# summarize data split\n",
    "print('Train: %s, Val: %s, Test: %s' % (X_train.shape, X_val.shape, X_test.shape))\n",
    "# create the base models\n",
    "models = get_models()\n",
    "# train the blending ensemble\n",
    "blender = fit_ensemble(models, X_train, X_val, y_train, y_val)\n",
    "# make predictions on test set\n",
    "yhat = predict_ensemble(models, blender, X_test)\n",
    "# evaluate predictions\n",
    "score = accuracy_score(y_test, yhat)\n",
    "print('Blending Accuracy: %.3f' % (score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blending ensemble for classification using soft voting\n",
    "from numpy import hstack\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "\tX, y = make_classification(n_samples=10000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "\treturn X, y\n",
    "\n",
    "# get a list of base models\n",
    "def get_models():\n",
    "\tmodels = list()\n",
    "\tmodels.append(('lr', LogisticRegression()))\n",
    "\tmodels.append(('knn', KNeighborsClassifier()))\n",
    "\tmodels.append(('cart', DecisionTreeClassifier()))\n",
    "\tmodels.append(('svm', SVC(probability=True)))\n",
    "\tmodels.append(('bayes', GaussianNB()))\n",
    "\treturn models\n",
    "\n",
    "# fit the blending ensemble\n",
    "def fit_ensemble(models, X_train, X_val, y_train, y_val):\n",
    "\t# fit all models on the training set and predict on hold out set\n",
    "\tmeta_X = list()\n",
    "\tfor _, model in models:\n",
    "\t\t# fit in training set\n",
    "\t\tmodel.fit(X_train, y_train)\n",
    "\t\t# predict on hold out set\n",
    "\t\tyhat = model.predict_proba(X_val)\n",
    "\t\t# store predictions as input for blending\n",
    "\t\tmeta_X.append(yhat)\n",
    "\t# create 2d array from predictions, each set is an input feature\n",
    "\tmeta_X = hstack(meta_X)\n",
    "\t# define blending model\n",
    "\tblender = LogisticRegression()\n",
    "\t# fit on predictions from base models\n",
    "\tblender.fit(meta_X, y_val)\n",
    "\treturn blender\n",
    "\n",
    "# make a prediction with the blending ensemble\n",
    "def predict_ensemble(models, blender, X_test):\n",
    "\t# make predictions with base models\n",
    "\tmeta_X = list()\n",
    "\tfor _, model in models:\n",
    "\t\t# predict with base model\n",
    "\t\tyhat = model.predict_proba(X_test)\n",
    "\t\t# store prediction\n",
    "\t\tmeta_X.append(yhat)\n",
    "\t# create 2d array from predictions, each set is an input feature\n",
    "\tmeta_X = hstack(meta_X)\n",
    "\t# predict\n",
    "\treturn blender.predict(meta_X)\n",
    "\n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# split dataset into train and test sets\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.5, random_state=1)\n",
    "# split training set into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.33, random_state=1)\n",
    "# summarize data split\n",
    "print('Train: %s, Val: %s, Test: %s' % (X_train.shape, X_val.shape, X_test.shape))\n",
    "# create the base models\n",
    "models = get_models()\n",
    "# train the blending ensemble\n",
    "blender = fit_ensemble(models, X_train, X_val, y_train, y_val)\n",
    "# make predictions on test set\n",
    "yhat = predict_ensemble(models, blender, X_test)\n",
    "# evaluate predictions\n",
    "score = accuracy_score(y_test, yhat)\n",
    "print('Blending Accuracy: %.3f' % (score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate base models on the entire training dataset\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "\tX, y = make_classification(n_samples=10000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "\treturn X, y\n",
    "\n",
    "# get a list of base models\n",
    "def get_models():\n",
    "\tmodels = list()\n",
    "\tmodels.append(('lr', LogisticRegression()))\n",
    "\tmodels.append(('knn', KNeighborsClassifier()))\n",
    "\tmodels.append(('cart', DecisionTreeClassifier()))\n",
    "\tmodels.append(('svm', SVC(probability=True)))\n",
    "\tmodels.append(('bayes', GaussianNB()))\n",
    "\treturn models\n",
    "\n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# split dataset into train and test sets\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.5, random_state=1)\n",
    "# summarize data split\n",
    "print('Train: %s, Test: %s' % (X_train_full.shape, X_test.shape))\n",
    "# create the base models\n",
    "models = get_models()\n",
    "# evaluate standalone model\n",
    "for name, model in models:\n",
    "\t# fit the model on the training dataset\n",
    "\tmodel.fit(X_train_full, y_train_full)\n",
    "\t# make a prediction on the test dataset\n",
    "\tyhat = model.predict(X_test)\n",
    "\t# evaluate the predictions\n",
    "\tscore = accuracy_score(y_test, yhat)\n",
    "\t# report the score\n",
    "\tprint('>%s Accuracy: %.3f' % (name, score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of making a prediction with a blending ensemble for classification\n",
    "from numpy import hstack\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "\tX, y = make_classification(n_samples=10000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "\treturn X, y\n",
    "\n",
    "# get a list of base models\n",
    "def get_models():\n",
    "\tmodels = list()\n",
    "\tmodels.append(('lr', LogisticRegression()))\n",
    "\tmodels.append(('knn', KNeighborsClassifier()))\n",
    "\tmodels.append(('cart', DecisionTreeClassifier()))\n",
    "\tmodels.append(('svm', SVC(probability=True)))\n",
    "\tmodels.append(('bayes', GaussianNB()))\n",
    "\treturn models\n",
    "\n",
    "# fit the blending ensemble\n",
    "def fit_ensemble(models, X_train, X_val, y_train, y_val):\n",
    "\t# fit all models on the training set and predict on hold out set\n",
    "\tmeta_X = list()\n",
    "\tfor _, model in models:\n",
    "\t\t# fit in training set\n",
    "\t\tmodel.fit(X_train, y_train)\n",
    "\t\t# predict on hold out set\n",
    "\t\tyhat = model.predict_proba(X_val)\n",
    "\t\t# store predictions as input for blending\n",
    "\t\tmeta_X.append(yhat)\n",
    "\t# create 2d array from predictions, each set is an input feature\n",
    "\tmeta_X = hstack(meta_X)\n",
    "\t# define blending model\n",
    "\tblender = LogisticRegression()\n",
    "\t# fit on predictions from base models\n",
    "\tblender.fit(meta_X, y_val)\n",
    "\treturn blender\n",
    "\n",
    "# make a prediction with the blending ensemble\n",
    "def predict_ensemble(models, blender, X_test):\n",
    "\t# make predictions with base models\n",
    "\tmeta_X = list()\n",
    "\tfor _, model in models:\n",
    "\t\t# predict with base model\n",
    "\t\tyhat = model.predict_proba(X_test)\n",
    "\t\t# store prediction\n",
    "\t\tmeta_X.append(yhat)\n",
    "\t# create 2d array from predictions, each set is an input feature\n",
    "\tmeta_X = hstack(meta_X)\n",
    "\t# predict\n",
    "\treturn blender.predict(meta_X)\n",
    "\n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# split dataset set into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# summarize data split\n",
    "print('Train: %s, Val: %s' % (X_train.shape, X_val.shape))\n",
    "# create the base models\n",
    "models = get_models()\n",
    "# train the blending ensemble\n",
    "blender = fit_ensemble(models, X_train, X_val, y_train, y_val)\n",
    "# make a prediction on a new row of data\n",
    "row = [-0.30335011, 2.68066314, 2.07794281, 1.15253537, -2.0583897, -2.51936601, 0.67513028, -3.20651939, -1.60345385, 3.68820714, 0.05370913, 1.35804433, 0.42011397, 1.4732839, 2.89997622, 1.61119399, 7.72630965, -2.84089477, -1.83977415, 1.34381989]\n",
    "yhat = predict_ensemble(models, blender, [row])\n",
    "# summarize prediction\n",
    "print('Predicted Class: %d' % (yhat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic regression dataset\n",
    "from sklearn.datasets import make_regression\n",
    "# define dataset\n",
    "X, y = make_regression(n_samples=10000, n_features=20, n_informative=10, noise=0.3, random_state=7)\n",
    "# summarize the dataset\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate blending ensemble for regression\n",
    "from numpy import hstack\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "\tX, y = make_regression(n_samples=10000, n_features=20, n_informative=10, noise=0.3, random_state=7)\n",
    "\treturn X, y\n",
    "\n",
    "# get a list of base models\n",
    "def get_models():\n",
    "\tmodels = list()\n",
    "\tmodels.append(('lr', LinearRegression()))\n",
    "\tmodels.append(('knn', KNeighborsRegressor()))\n",
    "\tmodels.append(('cart', DecisionTreeRegressor()))\n",
    "\tmodels.append(('svm', SVR()))\n",
    "\treturn models\n",
    "\n",
    "# fit the blending ensemble\n",
    "def fit_ensemble(models, X_train, X_val, y_train, y_val):\n",
    "\t# fit all models on the training set and predict on hold out set\n",
    "\tmeta_X = list()\n",
    "\tfor _, model in models:\n",
    "\t\t# fit in training set\n",
    "\t\tmodel.fit(X_train, y_train)\n",
    "\t\t# predict on hold out set\n",
    "\t\tyhat = model.predict(X_val)\n",
    "\t\t# reshape predictions into a matrix with one column\n",
    "\t\tyhat = yhat.reshape(len(yhat), 1)\n",
    "\t\t# store predictions as input for blending\n",
    "\t\tmeta_X.append(yhat)\n",
    "\t# create 2d array from predictions, each set is an input feature\n",
    "\tmeta_X = hstack(meta_X)\n",
    "\t# define blending model\n",
    "\tblender = LinearRegression()\n",
    "\t# fit on predictions from base models\n",
    "\tblender.fit(meta_X, y_val)\n",
    "\treturn blender\n",
    "\n",
    "# make a prediction with the blending ensemble\n",
    "def predict_ensemble(models, blender, X_test):\n",
    "\t# make predictions with base models\n",
    "\tmeta_X = list()\n",
    "\tfor _, model in models:\n",
    "\t\t# predict with base model\n",
    "\t\tyhat = model.predict(X_test)\n",
    "\t\t# reshape predictions into a matrix with one column\n",
    "\t\tyhat = yhat.reshape(len(yhat), 1)\n",
    "\t\t# store prediction\n",
    "\t\tmeta_X.append(yhat)\n",
    "\t# create 2d array from predictions, each set is an input feature\n",
    "\tmeta_X = hstack(meta_X)\n",
    "\t# predict\n",
    "\treturn blender.predict(meta_X)\n",
    "\n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# split dataset into train and test sets\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.5, random_state=1)\n",
    "# split training set into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.33, random_state=1)\n",
    "# summarize data split\n",
    "print('Train: %s, Val: %s, Test: %s' % (X_train.shape, X_val.shape, X_test.shape))\n",
    "# create the base models\n",
    "models = get_models()\n",
    "# train the blending ensemble\n",
    "blender = fit_ensemble(models, X_train, X_val, y_train, y_val)\n",
    "# make predictions on test set\n",
    "yhat = predict_ensemble(models, blender, X_test)\n",
    "# evaluate predictions\n",
    "score = mean_absolute_error(y_test, yhat)\n",
    "print('Blending MAE: %.3f' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate base models in isolation on the regression dataset\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "\tX, y = make_regression(n_samples=10000, n_features=20, n_informative=10, noise=0.3, random_state=7)\n",
    "\treturn X, y\n",
    "\n",
    "# get a list of base models\n",
    "def get_models():\n",
    "\tmodels = list()\n",
    "\tmodels.append(('lr', LinearRegression()))\n",
    "\tmodels.append(('knn', KNeighborsRegressor()))\n",
    "\tmodels.append(('cart', DecisionTreeRegressor()))\n",
    "\tmodels.append(('svm', SVR()))\n",
    "\treturn models\n",
    "\n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# split dataset into train and test sets\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.5, random_state=1)\n",
    "# summarize data split\n",
    "print('Train: %s, Test: %s' % (X_train_full.shape, X_test.shape))\n",
    "# create the base models\n",
    "models = get_models()\n",
    "# evaluate standalone model\n",
    "for name, model in models:\n",
    "\t# fit the model on the training dataset\n",
    "\tmodel.fit(X_train_full, y_train_full)\n",
    "\t# make a prediction on the test dataset\n",
    "\tyhat = model.predict(X_test)\n",
    "\t# evaluate the predictions\n",
    "\tscore = mean_absolute_error(y_test, yhat)\n",
    "\t# report the score\n",
    "\tprint('>%s MAE: %.3f' % (name, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of making a prediction with a blending ensemble for regression\n",
    "from numpy import hstack\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "\tX, y = make_regression(n_samples=10000, n_features=20, n_informative=10, noise=0.3, random_state=7)\n",
    "\treturn X, y\n",
    "\n",
    "# get a list of base models\n",
    "def get_models():\n",
    "\tmodels = list()\n",
    "\tmodels.append(('lr', LinearRegression()))\n",
    "\tmodels.append(('knn', KNeighborsRegressor()))\n",
    "\tmodels.append(('cart', DecisionTreeRegressor()))\n",
    "\tmodels.append(('svm', SVR()))\n",
    "\treturn models\n",
    "\n",
    "# fit the blending ensemble\n",
    "def fit_ensemble(models, X_train, X_val, y_train, y_val):\n",
    "\t# fit all models on the training set and predict on hold out set\n",
    "\tmeta_X = list()\n",
    "\tfor _, model in models:\n",
    "\t\t# fit in training set\n",
    "\t\tmodel.fit(X_train, y_train)\n",
    "\t\t# predict on hold out set\n",
    "\t\tyhat = model.predict(X_val)\n",
    "\t\t# reshape predictions into a matrix with one column\n",
    "\t\tyhat = yhat.reshape(len(yhat), 1)\n",
    "\t\t# store predictions as input for blending\n",
    "\t\tmeta_X.append(yhat)\n",
    "\t# create 2d array from predictions, each set is an input feature\n",
    "\tmeta_X = hstack(meta_X)\n",
    "\t# define blending model\n",
    "\tblender = LinearRegression()\n",
    "\t# fit on predictions from base models\n",
    "\tblender.fit(meta_X, y_val)\n",
    "\treturn blender\n",
    "\n",
    "# make a prediction with the blending ensemble\n",
    "def predict_ensemble(models, blender, X_test):\n",
    "\t# make predictions with base models\n",
    "\tmeta_X = list()\n",
    "\tfor _, model in models:\n",
    "\t\t# predict with base model\n",
    "\t\tyhat = model.predict(X_test)\n",
    "\t\t# reshape predictions into a matrix with one column\n",
    "\t\tyhat = yhat.reshape(len(yhat), 1)\n",
    "\t\t# store prediction\n",
    "\t\tmeta_X.append(yhat)\n",
    "\t# create 2d array from predictions, each set is an input feature\n",
    "\tmeta_X = hstack(meta_X)\n",
    "\t# predict\n",
    "\treturn blender.predict(meta_X)\n",
    "\n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# split dataset set into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# summarize data split\n",
    "print('Train: %s, Val: %s' % (X_train.shape, X_val.shape))\n",
    "# create the base models\n",
    "models = get_models()\n",
    "# train the blending ensemble\n",
    "blender = fit_ensemble(models, X_train, X_val, y_train, y_val)\n",
    "# make a prediction on a new row of data\n",
    "row = [-0.24038754, 0.55423865, -0.48979221, 1.56074459, -1.16007611, 1.10049103, 1.18385406, -1.57344162, 0.97862519, -0.03166643, 1.77099821, 1.98645499, 0.86780193, 2.01534177, 2.51509494, -1.04609004, -0.19428148, -0.05967386, -2.67168985, 1.07182911]\n",
    "yhat = predict_ensemble(models, blender, [row])\n",
    "# summarize prediction\n",
    "print('Predicted: %.3f' % (yhat[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
