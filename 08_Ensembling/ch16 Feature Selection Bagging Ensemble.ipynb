{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic classification dataset\n",
    "from sklearn.datasets import make_classification\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=5)\n",
    "# summarize the dataset\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a decision tree on the classification dataset\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=5)\n",
    "# define the random subspace ensemble model\n",
    "model = DecisionTreeClassifier()\n",
    "# define the evaluation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate the model on the dataset\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of an ensemble created from features selected with the anova f-statistic\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# get a voting ensemble of models\n",
    "def get_ensemble(n_features):\n",
    "\t# define the base models\n",
    "\tmodels = list()\n",
    "\t# enumerate the features in the training dataset\n",
    "\tfor i in range(1, n_features+1):\n",
    "\t\t# create the feature selection transform\n",
    "\t\tfs = SelectKBest(score_func=f_classif, k=i)\n",
    "\t\t# create the model\n",
    "\t\tmodel = DecisionTreeClassifier()\n",
    "\t\t# create the pipeline\n",
    "\t\tpipe = Pipeline([('fs', fs), ('m', model)])\n",
    "\t\t# add as a tuple to the list of models for voting\n",
    "\t\tmodels.append((str(i),pipe))\n",
    "\t# define the voting ensemble\n",
    "\tensemble = VotingClassifier(estimators=models, voting='hard')\n",
    "\treturn ensemble\n",
    "\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=5)\n",
    "# get the ensemble model\n",
    "ensemble = get_ensemble(X.shape[1])\n",
    "# define the evaluation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate the model on the dataset\n",
    "n_scores = cross_val_score(ensemble, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of an ensemble created from features selected with mutual information\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# get a voting ensemble of models\n",
    "def get_ensemble(n_features):\n",
    "\t# define the base models\n",
    "\tmodels = list()\n",
    "\t# enumerate the features in the training dataset\n",
    "\tfor i in range(1, n_features+1):\n",
    "\t\t# create the feature selection transform\n",
    "\t\tfs = SelectKBest(score_func=mutual_info_classif, k=i)\n",
    "\t\t# create the model\n",
    "\t\tmodel = DecisionTreeClassifier()\n",
    "\t\t# create the pipeline\n",
    "\t\tpipe = Pipeline([('fs', fs), ('m', model)])\n",
    "\t\t# add as a tuple to the list of models for voting\n",
    "\t\tmodels.append((str(i),pipe))\n",
    "\t# define the voting ensemble\n",
    "\tensemble = VotingClassifier(estimators=models, voting='hard')\n",
    "\treturn ensemble\n",
    "\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=5)\n",
    "# get the ensemble model\n",
    "ensemble = get_ensemble(X.shape[1])\n",
    "# define the evaluation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate the model on the dataset\n",
    "n_scores = cross_val_score(ensemble, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of an ensemble created from features selected with RFE\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# get a voting ensemble of models\n",
    "def get_ensemble(n_features):\n",
    "\t# define the base models\n",
    "\tmodels = list()\n",
    "\t# enumerate the features in the training dataset\n",
    "\tfor i in range(1, n_features+1):\n",
    "\t\t# create the feature selection transform\n",
    "\t\tfs = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=i)\n",
    "\t\t# create the model\n",
    "\t\tmodel = DecisionTreeClassifier()\n",
    "\t\t# create the pipeline\n",
    "\t\tpipe = Pipeline([('fs', fs), ('m', model)])\n",
    "\t\t# add as a tuple to the list of models for voting\n",
    "\t\tmodels.append((str(i),pipe))\n",
    "\t# define the voting ensemble\n",
    "\tensemble = VotingClassifier(estimators=models, voting='hard')\n",
    "\treturn ensemble\n",
    "\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=5)\n",
    "# get the ensemble model\n",
    "ensemble = get_ensemble(X.shape[1])\n",
    "# define the evaluation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate the model on the dataset\n",
    "n_scores = cross_val_score(ensemble, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble of a fixed number of features selected by different feature selection methods\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# get a voting ensemble of models\n",
    "def get_ensemble(n_features):\n",
    "\t# define the base models\n",
    "\tmodels = list()\n",
    "\t# anova member\n",
    "\tfs = SelectKBest(score_func=f_classif, k=n_features)\n",
    "\tanova = Pipeline([('fs', fs), ('m', DecisionTreeClassifier())])\n",
    "\tmodels.append(('anova', anova))\n",
    "\t# mutual information member\n",
    "\tfs = SelectKBest(score_func=mutual_info_classif, k=n_features)\n",
    "\tmutinfo = Pipeline([('fs', fs), ('m', DecisionTreeClassifier())])\n",
    "\tmodels.append(('mutinfo', mutinfo))\n",
    "\t# rfe member\n",
    "\tfs = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=n_features)\n",
    "\trfe = Pipeline([('fs', fs), ('m', DecisionTreeClassifier())])\n",
    "\tmodels.append(('rfe', rfe))\n",
    "\t# define the voting ensemble\n",
    "\tensemble = VotingClassifier(estimators=models, voting='hard')\n",
    "\treturn ensemble\n",
    "\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
    "# get the ensemble model\n",
    "ensemble = get_ensemble(15)\n",
    "# define the evaluation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate the model on the dataset\n",
    "n_scores = cross_val_score(ensemble, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison of ensemble of a fixed number of features to standalone models\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# get a voting ensemble of models\n",
    "def get_ensemble(n_features):\n",
    "\t# define the base models\n",
    "\tmodels, names = list(), list()\n",
    "\t# anova member\n",
    "\tfs = SelectKBest(score_func=f_classif, k=n_features)\n",
    "\tanova = Pipeline([('fs', fs), ('m', DecisionTreeClassifier())])\n",
    "\tmodels.append(('anova', anova))\n",
    "\tnames.append('anova')\n",
    "\t# mutual information member\n",
    "\tfs = SelectKBest(score_func=mutual_info_classif, k=n_features)\n",
    "\tmutinfo = Pipeline([('fs', fs), ('m', DecisionTreeClassifier())])\n",
    "\tmodels.append(('mutinfo', mutinfo))\n",
    "\tnames.append('mutinfo')\n",
    "\t# rfe member\n",
    "\tfs = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=n_features)\n",
    "\trfe = Pipeline([('fs', fs), ('m', DecisionTreeClassifier())])\n",
    "\tmodels.append(('rfe', rfe))\n",
    "\tnames.append('rfe')\n",
    "\t# define the voting ensemble\n",
    "\tensemble = VotingClassifier(estimators=models, voting='hard')\n",
    "\tnames.append('ensemble')\n",
    "\treturn names, [anova, mutinfo, rfe, ensemble]\n",
    "\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
    "# get the ensemble model\n",
    "names, models = get_ensemble(15)\n",
    "# evaluate each model\n",
    "results = list()\n",
    "for model,name in zip(models,names):\n",
    "\t# define the evaluation method\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\t# evaluate the model on the dataset\n",
    "\tn_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\t# store the results\n",
    "\tresults.append(n_scores)\n",
    "\t# report performance\n",
    "\tprint('>%s: %.3f (%.3f)' % (name, mean(n_scores), std(n_scores)))\n",
    "# plot the results for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble of many subsets of features selected by multiple feature selection methods\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# get a voting ensemble of models\n",
    "def get_ensemble(n_features_start, n_features_end):\n",
    "\t# define the base models\n",
    "\tmodels = list()\n",
    "\tfor i in range(n_features_start, n_features_end+1):\n",
    "\t\t# anova member\n",
    "\t\tfs = SelectKBest(score_func=f_classif, k=i)\n",
    "\t\tanova = Pipeline([('fs', fs), ('m', DecisionTreeClassifier())])\n",
    "\t\tmodels.append(('anova'+str(i), anova))\n",
    "\t\t# mutual information member\n",
    "\t\tfs = SelectKBest(score_func=mutual_info_classif, k=i)\n",
    "\t\tmutinfo = Pipeline([('fs', fs), ('m', DecisionTreeClassifier())])\n",
    "\t\tmodels.append(('mutinfo'+str(i), mutinfo))\n",
    "\t\t# rfe member\n",
    "\t\tfs = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=i)\n",
    "\t\trfe = Pipeline([('fs', fs), ('m', DecisionTreeClassifier())])\n",
    "\t\tmodels.append(('rfe'+str(i), rfe))\n",
    "\t# define the voting ensemble\n",
    "\tensemble = VotingClassifier(estimators=models, voting='hard')\n",
    "\treturn ensemble\n",
    "\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
    "# get the ensemble model\n",
    "ensemble = get_ensemble(1, 20)\n",
    "# define the evaluation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate the model on the dataset\n",
    "n_scores = cross_val_score(ensemble, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
