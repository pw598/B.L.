{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (60000, 28, 28) (60000,)\n",
      "Test ((10000, 28, 28), (10000,))\n",
      "Train 0 255 33.318421449829934 78.56748998339798\n",
      "Test 0 255 33.791224489795916 79.17246322228644\n"
     ]
    }
   ],
   "source": [
    "# load and summarize the MNIST dataset\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# load dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# summarize dataset shape\n",
    "print('Train', train_images.shape, train_labels.shape)\n",
    "print('Test', (test_images.shape, test_labels.shape))\n",
    "\n",
    "# summarize pixel values\n",
    "print('Train', train_images.min(), train_images.max(), train_images.mean(), train_images.std())\n",
    "print('Test', test_images.min(), test_images.max(), test_images.mean(), test_images.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train min=0.000, max=255.000\n",
      "Test min=0.000, max=255.000\n",
      "Batches train=938, test=157\n",
      "Batch shape=(64, 28, 28, 1), min=0.000, max=1.000\n"
     ]
    }
   ],
   "source": [
    "# example of normalizing a image dataset\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# load dataset\n",
    "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "\n",
    "# reshape dataset to have a single channel\n",
    "width, height, channels = trainX.shape[1], trainX.shape[2], 1\n",
    "trainX = trainX.reshape((trainX.shape[0], width, height, channels))\n",
    "testX = testX.reshape((testX.shape[0], width, height, channels))\n",
    "\n",
    "# confirm scale of pixels\n",
    "print('Train min=%.3f, max=%.3f' % (trainX.min(), trainX.max()))\n",
    "print('Test min=%.3f, max=%.3f' % (testX.min(), testX.max()))\n",
    "\n",
    "# create generator (1.0/255.0 = 0.003921568627451)\n",
    "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Note: there is no need to fit the generator in this case\n",
    "\n",
    "# prepare a iterators to scale images\n",
    "train_iterator = datagen.flow(trainX, trainY, batch_size=64)\n",
    "test_iterator = datagen.flow(testX, testY, batch_size=64)\n",
    "print('Batches train=%d, test=%d' % (len(train_iterator), len(test_iterator)))\n",
    "\n",
    "# confirm the scaling works\n",
    "batchX, batchy = train_iterator.next()\n",
    "print('Batch shape=%s, min=%.3f, max=%.3f' % (batchX.shape, batchX.min(), batchX.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means train=33.318, test=33.791\n",
      "Data Generator Mean: 33.318\n",
      "(64, 28, 28, 1) -0.93075275\n",
      "(60000, 28, 28, 1) -1.9512918e-05\n"
     ]
    }
   ],
   "source": [
    "# example of centering a image dataset\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# load dataset\n",
    "(trainX, trainy), (testX, testy) = mnist.load_data()\n",
    "\n",
    "# reshape dataset to have a single channel\n",
    "width, height, channels = trainX.shape[1], trainX.shape[2], 1\n",
    "trainX = trainX.reshape((trainX.shape[0], width, height, channels))\n",
    "testX = testX.reshape((testX.shape[0], width, height, channels))\n",
    "\n",
    "# report per-image mean\n",
    "print('Means train=%.3f, test=%.3f' % (trainX.mean(), testX.mean()))\n",
    "\n",
    "# create generator that centers pixel values\n",
    "datagen = ImageDataGenerator(featurewise_center=True)\n",
    "\n",
    "# calculate the mean on the training dataset\n",
    "datagen.fit(trainX)\n",
    "print('Data Generator Mean: %.3f' % datagen.mean)\n",
    "\n",
    "# demonstrate effect on a single batch of samples\n",
    "iterator = datagen.flow(trainX, trainy, batch_size=64)\n",
    "\n",
    "# get a batch\n",
    "batchX, batchy = iterator.next()\n",
    "\n",
    "# mean pixel value in the batch\n",
    "print(batchX.shape, batchX.mean())\n",
    "\n",
    "# demonstrate effect on entire training dataset\n",
    "iterator = datagen.flow(trainX, trainy, batch_size=len(trainX), shuffle=False)\n",
    "\n",
    "# get a batch\n",
    "batchX, batchy = iterator.next()\n",
    "\n",
    "# mean pixel value in the batch\n",
    "print(batchX.shape, batchX.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics train=33.318 (78.567), test=33.791 (79.172)\n",
      "Data Generator mean=33.318, std=78.567\n",
      "(64, 28, 28, 1) 0.014580063 1.022308\n",
      "(60000, 28, 28, 1) -3.4560264e-07 0.9999998\n"
     ]
    }
   ],
   "source": [
    "# example of standardizing a image dataset\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# load dataset\n",
    "(trainX, trainy), (testX, testy) = mnist.load_data()\n",
    "\n",
    "# reshape dataset to have a single channel\n",
    "width, height, channels = trainX.shape[1], trainX.shape[2], 1\n",
    "trainX = trainX.reshape((trainX.shape[0], width, height, channels))\n",
    "testX = testX.reshape((testX.shape[0], width, height, channels))\n",
    "\n",
    "# report pixel means and standard deviations\n",
    "print('Statistics train=%.3f (%.3f), test=%.3f (%.3f)' % (trainX.mean(), trainX.std(), testX.mean(), testX.std()))\n",
    "\n",
    "# create generator that centers pixel values\n",
    "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
    "\n",
    "# calculate the mean on the training dataset\n",
    "datagen.fit(trainX)\n",
    "print('Data Generator mean=%.3f, std=%.3f' % (datagen.mean, datagen.std))\n",
    "\n",
    "# demonstrate effect on a single batch of samples\n",
    "iterator = datagen.flow(trainX, trainy, batch_size=64)\n",
    "\n",
    "# get a batch\n",
    "batchX, batchy = iterator.next()\n",
    "\n",
    "# pixel stats in the batch\n",
    "print(batchX.shape, batchX.mean(), batchX.std())\n",
    "\n",
    "# demonstrate effect on entire training dataset\n",
    "iterator = datagen.flow(trainX, trainy, batch_size=len(trainX), shuffle=False)\n",
    "\n",
    "# get a batch\n",
    "batchX, batchy = iterator.next()\n",
    "\n",
    "# pixel stats in the batch\n",
    "print(batchX.shape, batchX.mean(), batchX.std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
