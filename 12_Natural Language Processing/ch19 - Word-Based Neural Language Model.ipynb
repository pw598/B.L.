{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "\n",
    "# generate a sequence from the model\n",
    "def generate_seq(model, tokenizer, seed_text, n_words):\n",
    "\tin_text, result = seed_text, seed_text\n",
    "\t# generate a fixed number of words\n",
    "\tfor _ in range(n_words):\n",
    "\t\t# encode the text as integer\n",
    "\t\tencoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "\t\tencoded = array(encoded)\n",
    "\t\t# predict a word in the vocabulary\n",
    "\t\tyhat = model.predict_classes(encoded, verbose=0)\n",
    "\t\t# map predicted word index to word\n",
    "\t\tout_word = ''\n",
    "\t\tfor word, index in tokenizer.word_index.items():\n",
    "\t\t\tif index == yhat:\n",
    "\t\t\t\tout_word = word\n",
    "\t\t\t\tbreak\n",
    "\t\t# append to input\n",
    "\t\tin_text, result = out_word, result + ' ' + out_word\n",
    "\treturn result\n",
    "\n",
    "# define the model\n",
    "def define_model(vocab_size):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Embedding(vocab_size, 10, input_length=1))\n",
    "\tmodel.add(LSTM(50))\n",
    "\tmodel.add(Dense(vocab_size, activation='softmax'))\n",
    "\t# compile network\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\t# summarize defined model\n",
    "\tmodel.summary()\n",
    "\tplot_model(model, to_file='model.png', show_shapes=True)\n",
    "\treturn model\n",
    "\n",
    "# source text\n",
    "data = \"\"\" Jack and Jill went up the hill\\n\n",
    "\t\tTo fetch a pail of water\\n\n",
    "\t\tJack fell down and broke his crown\\n\n",
    "\t\tAnd Jill came tumbling after\\n \"\"\"\n",
    "# integer encode text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([data])\n",
    "encoded = tokenizer.texts_to_sequences([data])[0]\n",
    "# determine the vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Vocabulary Size: %d' % vocab_size)\n",
    "# create word -> word sequences\n",
    "sequences = list()\n",
    "for i in range(1, len(encoded)):\n",
    "\tsequence = encoded[i-1:i+1]\n",
    "\tsequences.append(sequence)\n",
    "print('Total Sequences: %d' % len(sequences))\n",
    "# split into X and y elements\n",
    "sequences = array(sequences)\n",
    "X, y = sequences[:,0],sequences[:,1]\n",
    "# one hot encode outputs\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "# define model\n",
    "model = define_model(vocab_size)\n",
    "# fit network\n",
    "model.fit(X, y, epochs=500, verbose=2)\n",
    "# evaluate\n",
    "print(generate_seq(model, tokenizer, 'Jack', 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "\n",
    "# generate a sequence from a language model\n",
    "def generate_seq(model, tokenizer, max_length, seed_text, n_words):\n",
    "\tin_text = seed_text\n",
    "\t# generate a fixed number of words\n",
    "\tfor _ in range(n_words):\n",
    "\t\t# encode the text as integer\n",
    "\t\tencoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "\t\t# pre-pad sequences to a fixed length\n",
    "\t\tencoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
    "\t\t# predict probabilities for each word\n",
    "\t\tyhat = model.predict_classes(encoded, verbose=0)\n",
    "\t\t# map predicted word index to word\n",
    "\t\tout_word = ''\n",
    "\t\tfor word, index in tokenizer.word_index.items():\n",
    "\t\t\tif index == yhat:\n",
    "\t\t\t\tout_word = word\n",
    "\t\t\t\tbreak\n",
    "\t\t# append to input\n",
    "\t\tin_text += ' ' + out_word\n",
    "\treturn in_text\n",
    "\n",
    "# define the model\n",
    "def define_model(vocab_size, max_length):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Embedding(vocab_size, 10, input_length=max_length-1))\n",
    "\tmodel.add(LSTM(50))\n",
    "\tmodel.add(Dense(vocab_size, activation='softmax'))\n",
    "\t# compile network\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\t# summarize defined model\n",
    "\tmodel.summary()\n",
    "\tplot_model(model, to_file='model.png', show_shapes=True)\n",
    "\treturn model\n",
    "\n",
    "# source text\n",
    "data = \"\"\" Jack and Jill went up the hill\\n\n",
    "\t\tTo fetch a pail of water\\n\n",
    "\t\tJack fell down and broke his crown\\n\n",
    "\t\tAnd Jill came tumbling after\\n \"\"\"\n",
    "# prepare the tokenizer on the source text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([data])\n",
    "# determine the vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Vocabulary Size: %d' % vocab_size)\n",
    "# create line-based sequences\n",
    "sequences = list()\n",
    "for line in data.split('\\n'):\n",
    "\tencoded = tokenizer.texts_to_sequences([line])[0]\n",
    "\tfor i in range(1, len(encoded)):\n",
    "\t\tsequence = encoded[:i+1]\n",
    "\t\tsequences.append(sequence)\n",
    "print('Total Sequences: %d' % len(sequences))\n",
    "# pad input sequences\n",
    "max_length = max([len(seq) for seq in sequences])\n",
    "sequences = pad_sequences(sequences, maxlen=max_length, padding='pre')\n",
    "print('Max Sequence Length: %d' % max_length)\n",
    "# split into input and output elements\n",
    "sequences = array(sequences)\n",
    "X, y = sequences[:,:-1],sequences[:,-1]\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "# define model\n",
    "model = define_model(vocab_size, max_length)\n",
    "# fit network\n",
    "model.fit(X, y, epochs=500, verbose=2)\n",
    "# evaluate model\n",
    "print(generate_seq(model, tokenizer, max_length-1, 'Jack', 4))\n",
    "print(generate_seq(model, tokenizer, max_length-1, 'Jill', 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "\n",
    "# generate a sequence from a language model\n",
    "def generate_seq(model, tokenizer, max_length, seed_text, n_words):\n",
    "\tin_text = seed_text\n",
    "\t# generate a fixed number of words\n",
    "\tfor _ in range(n_words):\n",
    "\t\t# encode the text as integer\n",
    "\t\tencoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "\t\t# pre-pad sequences to a fixed length\n",
    "\t\tencoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
    "\t\t# predict probabilities for each word\n",
    "\t\tyhat = model.predict_classes(encoded, verbose=0)\n",
    "\t\t# map predicted word index to word\n",
    "\t\tout_word = ''\n",
    "\t\tfor word, index in tokenizer.word_index.items():\n",
    "\t\t\tif index == yhat:\n",
    "\t\t\t\tout_word = word\n",
    "\t\t\t\tbreak\n",
    "\t\t# append to input\n",
    "\t\tin_text += ' ' + out_word\n",
    "\treturn in_text\n",
    "\n",
    "# define the model\n",
    "def define_model(vocab_size, max_length):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Embedding(vocab_size, 10, input_length=max_length-1))\n",
    "\tmodel.add(LSTM(50))\n",
    "\tmodel.add(Dense(vocab_size, activation='softmax'))\n",
    "\t# compile network\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\t# summarize defined model\n",
    "\tmodel.summary()\n",
    "\tplot_model(model, to_file='model.png', show_shapes=True)\n",
    "\treturn model\n",
    "\n",
    "# source text\n",
    "data = \"\"\" Jack and Jill went up the hill\\n\n",
    "\t\tTo fetch a pail of water\\n\n",
    "\t\tJack fell down and broke his crown\\n\n",
    "\t\tAnd Jill came tumbling after\\n \"\"\"\n",
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([data])\n",
    "encoded = tokenizer.texts_to_sequences([data])[0]\n",
    "# retrieve vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Vocabulary Size: %d' % vocab_size)\n",
    "# encode 2 words -> 1 word\n",
    "sequences = list()\n",
    "for i in range(2, len(encoded)):\n",
    "\tsequence = encoded[i-2:i+1]\n",
    "\tsequences.append(sequence)\n",
    "print('Total Sequences: %d' % len(sequences))\n",
    "# pad sequences\n",
    "max_length = max([len(seq) for seq in sequences])\n",
    "sequences = pad_sequences(sequences, maxlen=max_length, padding='pre')\n",
    "print('Max Sequence Length: %d' % max_length)\n",
    "# split into input and output elements\n",
    "sequences = array(sequences)\n",
    "X, y = sequences[:,:-1],sequences[:,-1]\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "# define model\n",
    "model = define_model(vocab_size, max_length)\n",
    "# fit network\n",
    "model.fit(X, y, epochs=500, verbose=2)\n",
    "# evaluate model\n",
    "print(generate_seq(model, tokenizer, max_length-1, 'Jack and', 5))\n",
    "print(generate_seq(model, tokenizer, max_length-1, 'And Jill', 3))\n",
    "print(generate_seq(model, tokenizer, max_length-1, 'fell down', 5))\n",
    "print(generate_seq(model, tokenizer, max_length-1, 'pail of', 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
