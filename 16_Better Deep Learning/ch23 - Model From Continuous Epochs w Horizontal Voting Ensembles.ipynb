{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bagging mlp ensemble on blobs dataset\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from matplotlib import pyplot\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "import numpy\n",
    "\n",
    "# evaluate a single mlp model\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "\t# encode targets\n",
    "\ttrainy_enc = to_categorical(trainy)\n",
    "\ttesty_enc = to_categorical(testy)\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(50, input_dim=2, activation='relu'))\n",
    "\tmodel.add(Dense(3, activation='softmax'))\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\t# fit model\n",
    "\tmodel.fit(trainX, trainy_enc, epochs=50, verbose=0)\n",
    "\t# evaluate the model\n",
    "\t_, test_acc = model.evaluate(testX, testy_enc, verbose=0)\n",
    "\treturn model, test_acc\n",
    "\n",
    "# make an ensemble prediction for multi-class classification\n",
    "def ensemble_predictions(members, testX):\n",
    "\t# make predictions\n",
    "\tyhats = [model.predict(testX) for model in members]\n",
    "\tyhats = array(yhats)\n",
    "\t# sum across ensemble members\n",
    "\tsummed = numpy.sum(yhats, axis=0)\n",
    "\t# argmax across classes\n",
    "\tresult = argmax(summed, axis=1)\n",
    "\treturn result\n",
    "\n",
    "# evaluate a specific number of members in an ensemble\n",
    "def evaluate_n_members(members, n_members, testX, testy):\n",
    "\t# select a subset of members\n",
    "\tsubset = members[:n_members]\n",
    "\t# make prediction\n",
    "\tyhat = ensemble_predictions(subset, testX)\n",
    "\t# calculate accuracy\n",
    "\treturn accuracy_score(testy, yhat)\n",
    "\n",
    "# generate 2d classification dataset\n",
    "dataX, datay = make_blobs(n_samples=55000, centers=3, n_features=2, cluster_std=2, random_state=2)\n",
    "X, newX = dataX[:5000, :], dataX[5000:, :]\n",
    "y, newy = datay[:5000], datay[5000:]\n",
    "# multiple train-test splits\n",
    "n_splits = 10\n",
    "scores, members = list(), list()\n",
    "for _ in range(n_splits):\n",
    "\t# select indexes\n",
    "\tix = [i for i in range(len(X))]\n",
    "\ttrain_ix = resample(ix, replace=True, n_samples=4500)\n",
    "\ttest_ix = [x for x in ix if x not in train_ix]\n",
    "\t# select data\n",
    "\ttrainX, trainy = X[train_ix], y[train_ix]\n",
    "\ttestX, testy = X[test_ix], y[test_ix]\n",
    "\t# evaluate model\n",
    "\tmodel, test_acc = evaluate_model(trainX, trainy, testX, testy)\n",
    "\tprint('>%.3f' % test_acc)\n",
    "\tscores.append(test_acc)\n",
    "\tmembers.append(model)\n",
    "# summarize expected performance\n",
    "print('Estimated Accuracy %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "# evaluate different numbers of ensembles on hold out set\n",
    "single_scores, ensemble_scores = list(), list()\n",
    "for i in range(1, n_splits+1):\n",
    "\tensemble_score = evaluate_n_members(members, i, newX, newy)\n",
    "\tnewy_enc = to_categorical(newy)\n",
    "\t_, single_score = members[i-1].evaluate(newX, newy_enc, verbose=0)\n",
    "\tprint('> %d: single=%.3f, ensemble=%.3f' % (i, single_score, ensemble_score))\n",
    "\tensemble_scores.append(ensemble_score)\n",
    "\tsingle_scores.append(single_score)\n",
    "# plot score vs number of ensemble members\n",
    "print('Accuracy %.3f (%.3f)' % (mean(single_scores), std(single_scores)))\n",
    "x_axis = [i for i in range(1, n_splits+1)]\n",
    "pyplot.plot(x_axis, single_scores, marker='o', linestyle='None')\n",
    "pyplot.plot(x_axis, ensemble_scores, marker='o')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# develop an mlp for blobs dataset\n",
    "from sklearn.datasets import make_blobs\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from matplotlib import pyplot\n",
    "# generate 2d classification dataset\n",
    "X, y = make_blobs(n_samples=1100, centers=3, n_features=2, cluster_std=2, random_state=2)\n",
    "# one hot encode output variable\n",
    "y = to_categorical(y)\n",
    "# split into train and test\n",
    "n_train = 100\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=2, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit model\n",
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=1000, verbose=0)\n",
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "# plot loss learning curves\n",
    "pyplot.subplot(211)\n",
    "pyplot.title('Cross-Entropy Loss', pad=-40)\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "# plot accuracy learning curves\n",
    "pyplot.subplot(212)\n",
    "pyplot.title('Accuracy', pad=-40)\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save horizontal voting ensemble members during training\n",
    "from sklearn.datasets import make_blobs\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from os import makedirs\n",
    "# generate 2d classification dataset\n",
    "X, y = make_blobs(n_samples=1100, centers=3, n_features=2, cluster_std=2, random_state=2)\n",
    "# one hot encode output variable\n",
    "y = to_categorical(y)\n",
    "# split into train and test\n",
    "n_train = 100\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=2, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# create directory for models\n",
    "makedirs('models')\n",
    "# fit model\n",
    "n_epochs, n_save_after = 1000, 950\n",
    "for i in range(n_epochs):\n",
    "\t# fit model for a single epoch\n",
    "\tmodel.fit(trainX, trainy, epochs=1, verbose=0)\n",
    "\t# check if we should save the model\n",
    "\tif i >= n_save_after:\n",
    "\t\tmodel.save('models/model_' + str(i) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models and make predictions using a horizontal voting ensemble\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model\n",
    "from matplotlib import pyplot\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "import numpy\n",
    "\n",
    "# load models from file\n",
    "def load_all_models(n_start, n_end):\n",
    "\tall_models = list()\n",
    "\tfor epoch in range(n_start, n_end):\n",
    "\t\t# define filename for this ensemble\n",
    "\t\tfilename = 'models/model_' + str(epoch) + '.h5'\n",
    "\t\t# load model from file\n",
    "\t\tmodel = load_model(filename)\n",
    "\t\t# add to list of members\n",
    "\t\tall_models.append(model)\n",
    "\t\tprint('>loaded %s' % filename)\n",
    "\treturn all_models\n",
    "\n",
    "# make an ensemble prediction for multi-class classification\n",
    "def ensemble_predictions(members, testX):\n",
    "\t# make predictions\n",
    "\tyhats = [model.predict(testX) for model in members]\n",
    "\tyhats = array(yhats)\n",
    "\t# sum across ensemble members\n",
    "\tsummed = numpy.sum(yhats, axis=0)\n",
    "\t# argmax across classes\n",
    "\tresult = argmax(summed, axis=1)\n",
    "\treturn result\n",
    "\n",
    "# evaluate a specific number of members in an ensemble\n",
    "def evaluate_n_members(members, n_members, testX, testy):\n",
    "\t# select a subset of members\n",
    "\tsubset = members[:n_members]\n",
    "\t# make prediction\n",
    "\tyhat = ensemble_predictions(subset, testX)\n",
    "\t# calculate accuracy\n",
    "\treturn accuracy_score(testy, yhat)\n",
    "\n",
    "# generate 2d classification dataset\n",
    "X, y = make_blobs(n_samples=1100, centers=3, n_features=2, cluster_std=2, random_state=2)\n",
    "# split into train and test\n",
    "n_train = 100\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "# load models in order\n",
    "members = load_all_models(950, 1000)\n",
    "print('Loaded %d models' % len(members))\n",
    "# reverse loaded models so we build the ensemble with the last models first\n",
    "members = list(reversed(members))\n",
    "# evaluate different numbers of ensembles on hold out set\n",
    "single_scores, ensemble_scores = list(), list()\n",
    "for i in range(1, len(members)+1):\n",
    "\t# evaluate model with i members\n",
    "\tensemble_score = evaluate_n_members(members, i, testX, testy)\n",
    "\t# evaluate the i'th model standalone\n",
    "\ttesty_enc = to_categorical(testy)\n",
    "\t_, single_score = members[i-1].evaluate(testX, testy_enc, verbose=0)\n",
    "\t# summarize this step\n",
    "\tprint('> %d: single=%.3f, ensemble=%.3f' % (i, single_score, ensemble_score))\n",
    "\tensemble_scores.append(ensemble_score)\n",
    "\tsingle_scores.append(single_score)\n",
    "# summarize average accuracy of a single final model\n",
    "print('Accuracy %.3f (%.3f)' % (mean(single_scores), std(single_scores)))\n",
    "# plot score vs number of ensemble members\n",
    "x_axis = [i for i in range(1, len(members)+1)]\n",
    "pyplot.plot(x_axis, single_scores, marker='o', linestyle='None')\n",
    "pyplot.plot(x_axis, ensemble_scores, marker='o')\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
