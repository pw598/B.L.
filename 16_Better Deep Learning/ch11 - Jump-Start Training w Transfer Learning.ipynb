{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of blobs multiclass classification problems 1 and 2\n",
    "from sklearn.datasets import make_blobs\n",
    "from numpy import where\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# generate samples for blobs problem with a given random seed\n",
    "def samples_for_seed(seed):\n",
    "\t# generate samples\n",
    "\tX, y = make_blobs(n_samples=1000, centers=3, n_features=2, cluster_std=2, random_state=seed)\n",
    "\treturn X, y\n",
    "\n",
    "# create a scatter plot of points colored by class value\n",
    "def plot_samples(X, y, classes=3):\n",
    "\t# plot points for each class\n",
    "\tfor i in range(classes):\n",
    "\t\t# select indices of points with each class label\n",
    "\t\tsamples_ix = where(y == i)\n",
    "\t\t# plot points for this class with a given color\n",
    "\t\tpyplot.scatter(X[samples_ix, 0], X[samples_ix, 1])\n",
    "\n",
    "# generate multiple problems\n",
    "n_problems = 2\n",
    "for i in range(1, n_problems+1):\n",
    "\t# specify subplot\n",
    "\tpyplot.subplot(210 + i)\n",
    "\t# generate samples\n",
    "\tX, y = samples_for_seed(i)\n",
    "\t# scatter plot of samples\n",
    "\tplot_samples(X, y)\n",
    "# plot figure\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit mlp model on problem 1 and save model to file\n",
    "from sklearn.datasets import make_blobs\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# prepare a blobs examples with a given random seed\n",
    "def samples_for_seed(seed):\n",
    "\t# generate samples\n",
    "\tX, y = make_blobs(n_samples=1000, centers=3, n_features=2, cluster_std=2, random_state=seed)\n",
    "\t# one hot encode output variable\n",
    "\ty = to_categorical(y)\n",
    "\t# split into train and test\n",
    "\tn_train = 500\n",
    "\ttrainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "\ttrainy, testy = y[:n_train], y[n_train:]\n",
    "\treturn trainX, trainy, testX, testy\n",
    "\n",
    "# define and fit model on a training dataset\n",
    "def fit_model(trainX, trainy, testX, testy):\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(5, input_dim=2, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(5, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(3, activation='softmax'))\n",
    "\t# compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\t# fit model\n",
    "\thistory = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=100, verbose=0)\n",
    "\treturn model, history\n",
    "\n",
    "# summarize the performance of the fit model\n",
    "def summarize_model(model, history, trainX, trainy, testX, testy):\n",
    "\t# evaluate the model\n",
    "\t_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "\t_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "\tprint('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "\t# plot loss during training\n",
    "\tpyplot.subplot(211)\n",
    "\tpyplot.title('Loss')\n",
    "\tpyplot.plot(history.history['loss'], label='train')\n",
    "\tpyplot.plot(history.history['val_loss'], label='test')\n",
    "\tpyplot.legend()\n",
    "\t# plot accuracy during training\n",
    "\tpyplot.subplot(212)\n",
    "\tpyplot.title('Accuracy')\n",
    "\tpyplot.plot(history.history['accuracy'], label='train')\n",
    "\tpyplot.plot(history.history['val_accuracy'], label='test')\n",
    "\tpyplot.legend()\n",
    "\tpyplot.show()\n",
    "\n",
    "# prepare data\n",
    "trainX, trainy, testX, testy = samples_for_seed(1)\n",
    "# fit model on train dataset\n",
    "model, history = fit_model(trainX, trainy, testX, testy)\n",
    "# evaluate model behavior\n",
    "summarize_model(model, history, trainX, trainy, testX, testy)\n",
    "# save model to file\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit mlp model on problem 2 and save model to file\n",
    "from sklearn.datasets import make_blobs\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# prepare a blobs examples with a given random seed\n",
    "def samples_for_seed(seed):\n",
    "\t# generate samples\n",
    "\tX, y = make_blobs(n_samples=1000, centers=3, n_features=2, cluster_std=2, random_state=seed)\n",
    "\t# one hot encode output variable\n",
    "\ty = to_categorical(y)\n",
    "\t# split into train and test\n",
    "\tn_train = 500\n",
    "\ttrainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "\ttrainy, testy = y[:n_train], y[n_train:]\n",
    "\treturn trainX, trainy, testX, testy\n",
    "\n",
    "# define and fit model on a training dataset\n",
    "def fit_model(trainX, trainy, testX, testy):\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(5, input_dim=2, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(5, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(3, activation='softmax'))\n",
    "\t# compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\t# fit model\n",
    "\thistory = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=100, verbose=0)\n",
    "\treturn model, history\n",
    "\n",
    "# summarize the performance of the fit model\n",
    "def summarize_model(model, history, trainX, trainy, testX, testy):\n",
    "\t# evaluate the model\n",
    "\t_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "\t_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "\tprint('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "\t# plot loss during training\n",
    "\tpyplot.subplot(211)\n",
    "\tpyplot.title('Loss')\n",
    "\tpyplot.plot(history.history['loss'], label='train')\n",
    "\tpyplot.plot(history.history['val_loss'], label='test')\n",
    "\tpyplot.legend()\n",
    "\t# plot accuracy during training\n",
    "\tpyplot.subplot(212)\n",
    "\tpyplot.title('Accuracy')\n",
    "\tpyplot.plot(history.history['accuracy'], label='train')\n",
    "\tpyplot.plot(history.history['val_accuracy'], label='test')\n",
    "\tpyplot.legend()\n",
    "\tpyplot.show()\n",
    "\n",
    "# prepare data\n",
    "trainX, trainy, testX, testy = samples_for_seed(2)\n",
    "# fit model on train dataset\n",
    "model, history = fit_model(trainX, trainy, testX, testy)\n",
    "# evaluate model behavior\n",
    "summarize_model(model, history, trainX, trainy, testX, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer learning with mlp model on problem 2\n",
    "from sklearn.datasets import make_blobs\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# prepare a blobs examples with a given random seed\n",
    "def samples_for_seed(seed):\n",
    "\t# generate samples\n",
    "\tX, y = make_blobs(n_samples=1000, centers=3, n_features=2, cluster_std=2, random_state=seed)\n",
    "\t# one hot encode output variable\n",
    "\ty = to_categorical(y)\n",
    "\t# split into train and test\n",
    "\tn_train = 500\n",
    "\ttrainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "\ttrainy, testy = y[:n_train], y[n_train:]\n",
    "\treturn trainX, trainy, testX, testy\n",
    "\n",
    "# load and re-fit model on a training dataset\n",
    "def fit_model(trainX, trainy, testX, testy):\n",
    "\t# load model\n",
    "\tmodel = load_model('model.h5')\n",
    "\t# compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\t# re-fit model\n",
    "\thistory = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=100, verbose=0)\n",
    "\treturn model, history\n",
    "\n",
    "# summarize the performance of the fit model\n",
    "def summarize_model(model, history, trainX, trainy, testX, testy):\n",
    "\t# evaluate the model\n",
    "\t_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "\t_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "\tprint('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "\t# plot loss during training\n",
    "\tpyplot.subplot(211)\n",
    "\tpyplot.title('Loss')\n",
    "\tpyplot.plot(history.history['loss'], label='train')\n",
    "\tpyplot.plot(history.history['val_loss'], label='test')\n",
    "\tpyplot.legend()\n",
    "\t# plot accuracy during training\n",
    "\tpyplot.subplot(212)\n",
    "\tpyplot.title('Accuracy')\n",
    "\tpyplot.plot(history.history['accuracy'], label='train')\n",
    "\tpyplot.plot(history.history['val_accuracy'], label='test')\n",
    "\tpyplot.legend()\n",
    "\tpyplot.show()\n",
    "\n",
    "# prepare data\n",
    "trainX, trainy, testX, testy = samples_for_seed(2)\n",
    "# fit model on train dataset\n",
    "model, history = fit_model(trainX, trainy, testX, testy)\n",
    "# evaluate model behavior\n",
    "summarize_model(model, history, trainX, trainy, testX, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare standalone mlp model performance to transfer learning\n",
    "from sklearn.datasets import make_blobs\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model\n",
    "from matplotlib import pyplot\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "\n",
    "# prepare a blobs examples with a given random seed\n",
    "def samples_for_seed(seed):\n",
    "\t# generate samples\n",
    "\tX, y = make_blobs(n_samples=1000, centers=3, n_features=2, cluster_std=2, random_state=seed)\n",
    "\t# one hot encode output variable\n",
    "\ty = to_categorical(y)\n",
    "\t# split into train and test\n",
    "\tn_train = 500\n",
    "\ttrainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "\ttrainy, testy = y[:n_train], y[n_train:]\n",
    "\treturn trainX, trainy, testX, testy\n",
    "\n",
    "# define and fit model on a training dataset\n",
    "def fit_model(trainX, trainy):\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(5, input_dim=2, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(5, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(3, activation='softmax'))\n",
    "\t# compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\t# fit model\n",
    "\tmodel.fit(trainX, trainy, epochs=100, verbose=0)\n",
    "\treturn model\n",
    "\n",
    "# repeated evaluation of a standalone model\n",
    "def eval_standalone_model(trainX, trainy, testX, testy, n_repeats):\n",
    "\tscores = list()\n",
    "\tfor _ in range(n_repeats):\n",
    "\t\t# define and fit a new model on the train dataset\n",
    "\t\tmodel = fit_model(trainX, trainy)\n",
    "\t\t# evaluate model on test dataset\n",
    "\t\t_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "\t\tscores.append(test_acc)\n",
    "\treturn scores\n",
    "\n",
    "# repeated evaluation of a model with transfer learning\n",
    "def eval_transfer_model(trainX, trainy, testX, testy, n_fixed, n_repeats):\n",
    "\tscores = list()\n",
    "\tfor _ in range(n_repeats):\n",
    "\t\t# load model\n",
    "\t\tmodel = load_model('model.h5')\n",
    "\t\t# mark layer weights as fixed or not trainable\n",
    "\t\tfor i in range(n_fixed):\n",
    "\t\t\tmodel.layers[i].trainable = False\n",
    "\t\t# re-compile model\n",
    "\t\tmodel.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\t\t# fit model on train dataset\n",
    "\t\tmodel.fit(trainX, trainy, epochs=100, verbose=0)\n",
    "\t\t# evaluate model on test dataset\n",
    "\t\t_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "\t\tscores.append(test_acc)\n",
    "\treturn scores\n",
    "\n",
    "# prepare data for problem 2\n",
    "trainX, trainy, testX, testy = samples_for_seed(2)\n",
    "n_repeats = 30\n",
    "dists, dist_labels = list(), list()\n",
    "\n",
    "# repeated evaluation of standalone model\n",
    "standalone_scores = eval_standalone_model(trainX, trainy, testX, testy, n_repeats)\n",
    "print('Standalone %.3f (%.3f)' % (mean(standalone_scores), std(standalone_scores)))\n",
    "dists.append(standalone_scores)\n",
    "dist_labels.append('standalone')\n",
    "\n",
    "# repeated evaluation of transfer learning model, vary fixed layers\n",
    "n_fixed = 3\n",
    "for i in range(n_fixed):\n",
    "\tscores = eval_transfer_model(trainX, trainy, testX, testy, i, n_repeats)\n",
    "\tprint('Transfer (fixed=%d) %.3f (%.3f)' % (i, mean(scores), std(scores)))\n",
    "\tdists.append(scores)\n",
    "\tdist_labels.append('transfer f='+str(i))\n",
    "\n",
    "# box and whisker plot of score distributions\n",
    "pyplot.boxplot(dists, labels=dist_labels)\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
