{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot of blobs dataset\n",
    "from sklearn.datasets import make_blobs\n",
    "from matplotlib import pyplot\n",
    "from numpy import where\n",
    "# generate 2d classification dataset\n",
    "X, y = make_blobs(n_samples=1000, centers=3, n_features=2, cluster_std=2, random_state=2)\n",
    "# scatter plot for each class value\n",
    "for class_value in range(3):\n",
    "\t# select indices of points with the class label\n",
    "\trow_ix = where(y == class_value)\n",
    "\t# scatter plot for points with a different color\n",
    "\tpyplot.scatter(X[row_ix, 0], X[row_ix, 1])\n",
    "# show plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# develop an mlp for blobs dataset\n",
    "from sklearn.datasets import make_blobs\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from matplotlib import pyplot\n",
    "# generate 2d classification dataset\n",
    "X, y = make_blobs(n_samples=1100, centers=3, n_features=2, cluster_std=2, random_state=2)\n",
    "# one hot encode output variable\n",
    "y = to_categorical(y)\n",
    "# split into train and test\n",
    "n_train = 100\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=2, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "opt = SGD(lr=0.01, momentum=0.9)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "# fit model\n",
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=200, verbose=0)\n",
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "# plot loss learning curves\n",
    "pyplot.subplot(211)\n",
    "pyplot.title('Cross-Entropy Loss', pad=-40)\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "# plot accuracy learning curves\n",
    "pyplot.subplot(212)\n",
    "pyplot.title('Accuracy', pad=-40)\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of a cosine annealing learning rate schedule\n",
    "from matplotlib import pyplot\n",
    "from math import pi\n",
    "from math import cos\n",
    "from math import floor\n",
    "\n",
    "# cosine annealing learning rate schedule\n",
    "def cosine_annealing(epoch, n_epochs, n_cycles, lrate_max):\n",
    "\tepochs_per_cycle = floor(n_epochs/n_cycles)\n",
    "\tcos_inner = (pi * (epoch % epochs_per_cycle)) / (epochs_per_cycle)\n",
    "\treturn lrate_max/2 * (cos(cos_inner) + 1)\n",
    "\n",
    "# create learning rate series\n",
    "n_epochs = 100\n",
    "n_cycles = 5\n",
    "lrate_max = 0.01\n",
    "series = [cosine_annealing(i, n_epochs, n_cycles, lrate_max) for i in range(n_epochs)]\n",
    "# plot series\n",
    "pyplot.plot(series)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp with cosine annealing learning rate schedule on blobs problem\n",
    "from sklearn.datasets import make_blobs\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import Callback\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend\n",
    "from math import pi\n",
    "from math import cos\n",
    "from math import floor\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# define custom learning rate schedule\n",
    "class CosineAnnealingLearningRateSchedule(Callback):\n",
    "\t# constructor\n",
    "\tdef __init__(self, n_epochs, n_cycles, lrate_max, verbose=0):\n",
    "\t\tself.epochs = n_epochs\n",
    "\t\tself.cycles = n_cycles\n",
    "\t\tself.lr_max = lrate_max\n",
    "\t\tself.lrates = list()\n",
    "\n",
    "\t# calculate learning rate for an epoch\n",
    "\tdef cosine_annealing(self, epoch, n_epochs, n_cycles, lrate_max):\n",
    "\t\tepochs_per_cycle = floor(n_epochs/n_cycles)\n",
    "\t\tcos_inner = (pi * (epoch % epochs_per_cycle)) / (epochs_per_cycle)\n",
    "\t\treturn lrate_max/2 * (cos(cos_inner) + 1)\n",
    "\n",
    "\t# calculate and set learning rate at the start of the epoch\n",
    "\tdef on_epoch_begin(self, epoch, logs=None):\n",
    "\t\t# calculate learning rate\n",
    "\t\tlr = self.cosine_annealing(epoch, self.epochs, self.cycles, self.lr_max)\n",
    "\t\t# set learning rate\n",
    "\t\tbackend.set_value(self.model.optimizer.lr, lr)\n",
    "\t\t# log value\n",
    "\t\tself.lrates.append(lr)\n",
    "\n",
    "# generate 2d classification dataset\n",
    "X, y = make_blobs(n_samples=1100, centers=3, n_features=2, cluster_std=2, random_state=2)\n",
    "# one hot encode output variable\n",
    "y = to_categorical(y)\n",
    "# split into train and test\n",
    "n_train = 100\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=2, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "opt = SGD(momentum=0.9)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "# define learning rate callback\n",
    "n_epochs = 400\n",
    "n_cycles = n_epochs / 50\n",
    "ca = CosineAnnealingLearningRateSchedule(n_epochs, n_cycles, 0.01)\n",
    "# fit model\n",
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=n_epochs, verbose=0, callbacks=[ca])\n",
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "# plot learning rate\n",
    "pyplot.plot(ca.lrates)\n",
    "pyplot.show()\n",
    "# plot loss learning curves\n",
    "pyplot.subplot(211)\n",
    "pyplot.title('Cross-Entropy Loss', pad=-40)\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "# plot accuracy learning curves\n",
    "pyplot.subplot(212)\n",
    "pyplot.title('Accuracy', pad=-40)\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of saving models for a snapshot ensemble\n",
    "from sklearn.datasets import make_blobs\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import Callback\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend\n",
    "from math import pi\n",
    "from math import cos\n",
    "from math import floor\n",
    "\n",
    "# snapshot ensemble with custom learning rate schedule\n",
    "class SnapshotEnsemble(Callback):\n",
    "\t# constructor\n",
    "\tdef __init__(self, n_epochs, n_cycles, lrate_max, verbose=0):\n",
    "\t\tself.epochs = n_epochs\n",
    "\t\tself.cycles = n_cycles\n",
    "\t\tself.lr_max = lrate_max\n",
    "\t\tself.lrates = list()\n",
    "\n",
    "\t# calculate learning rate for epoch\n",
    "\tdef cosine_annealing(self, epoch, n_epochs, n_cycles, lrate_max):\n",
    "\t\tepochs_per_cycle = floor(n_epochs/n_cycles)\n",
    "\t\tcos_inner = (pi * (epoch % epochs_per_cycle)) / (epochs_per_cycle)\n",
    "\t\treturn lrate_max/2 * (cos(cos_inner) + 1)\n",
    "\n",
    "\t# calculate and set learning rate at the start of the epoch\n",
    "\tdef on_epoch_begin(self, epoch, logs={}):\n",
    "\t\t# calculate learning rate\n",
    "\t\tlr = self.cosine_annealing(epoch, self.epochs, self.cycles, self.lr_max)\n",
    "\t\t# set learning rate\n",
    "\t\tbackend.set_value(self.model.optimizer.lr, lr)\n",
    "\t\t# log value\n",
    "\t\tself.lrates.append(lr)\n",
    "\n",
    "\t# save models at the end of each cycle\n",
    "\tdef on_epoch_end(self, epoch, logs={}):\n",
    "\t\t# check if we can save model\n",
    "\t\tepochs_per_cycle = floor(self.epochs / self.cycles)\n",
    "\t\tif epoch != 0 and (epoch + 1) % epochs_per_cycle == 0:\n",
    "\t\t\t# save model to file\n",
    "\t\t\tfilename = \"snapshot_model_%d.h5\" % int((epoch + 1) / epochs_per_cycle)\n",
    "\t\t\tself.model.save(filename)\n",
    "\t\t\tprint('>saved snapshot %s, epoch %d' % (filename, epoch))\n",
    "\n",
    "# generate 2d classification dataset\n",
    "X, y = make_blobs(n_samples=1100, centers=3, n_features=2, cluster_std=2, random_state=2)\n",
    "# one hot encode output variable\n",
    "y = to_categorical(y)\n",
    "# split into train and test\n",
    "n_train = 100\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim=2, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "opt = SGD(momentum=0.9)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "# create snapshot ensemble callback\n",
    "n_epochs = 500\n",
    "n_cycles = n_epochs / 50\n",
    "ca = SnapshotEnsemble(n_epochs, n_cycles, 0.01)\n",
    "# fit model\n",
    "model.fit(trainX, trainy, validation_data=(testX, testy), epochs=n_epochs, verbose=0, callbacks=[ca])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models and make a snapshot ensemble prediction\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model\n",
    "from matplotlib import pyplot\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "import numpy\n",
    "\n",
    "# load models from file\n",
    "def load_all_models(n_models):\n",
    "\tall_models = list()\n",
    "\tfor i in range(n_models):\n",
    "\t\t# define filename for this ensemble\n",
    "\t\tfilename = 'snapshot_model_' + str(i + 1) + '.h5'\n",
    "\t\t# load model from file\n",
    "\t\tmodel = load_model(filename)\n",
    "\t\t# add to list of members\n",
    "\t\tall_models.append(model)\n",
    "\t\tprint('>loaded %s' % filename)\n",
    "\treturn all_models\n",
    "\n",
    "# make an ensemble prediction for multi-class classification\n",
    "def ensemble_predictions(members, testX):\n",
    "\t# make predictions\n",
    "\tyhats = [model.predict(testX) for model in members]\n",
    "\tyhats = array(yhats)\n",
    "\t# sum across ensemble members\n",
    "\tsummed = numpy.sum(yhats, axis=0)\n",
    "\t# argmax across classes\n",
    "\tresult = argmax(summed, axis=1)\n",
    "\treturn result\n",
    "\n",
    "# evaluate a specific number of members in an ensemble\n",
    "def evaluate_n_members(members, n_members, testX, testy):\n",
    "\t# select a subset of members\n",
    "\tsubset = members[:n_members]\n",
    "\t# make prediction\n",
    "\tyhat = ensemble_predictions(subset, testX)\n",
    "\t# calculate accuracy\n",
    "\treturn accuracy_score(testy, yhat)\n",
    "\n",
    "# generate 2d classification dataset\n",
    "X, y = make_blobs(n_samples=1100, centers=3, n_features=2, cluster_std=2, random_state=2)\n",
    "# split into train and test\n",
    "n_train = 100\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "print(trainX.shape, testX.shape)\n",
    "# load models in order\n",
    "members = load_all_models(10)\n",
    "print('Loaded %d models' % len(members))\n",
    "# reverse loaded models so we build the ensemble with the last models first\n",
    "members = list(reversed(members))\n",
    "# evaluate different numbers of ensembles on hold out set\n",
    "single_scores, ensemble_scores = list(), list()\n",
    "for i in range(1, len(members)+1):\n",
    "\t# evaluate model with i members\n",
    "\tensemble_score = evaluate_n_members(members, i, testX, testy)\n",
    "\t# evaluate the i'th model standalone\n",
    "\ttesty_enc = to_categorical(testy)\n",
    "\t_, single_score = members[i-1].evaluate(testX, testy_enc, verbose=0)\n",
    "\t# summarize this step\n",
    "\tprint('> %d: single=%.3f, ensemble=%.3f' % (i, single_score, ensemble_score))\n",
    "\tensemble_scores.append(ensemble_score)\n",
    "\tsingle_scores.append(single_score)\n",
    "# summarize average accuracy of a single final model\n",
    "print('Accuracy %.3f (%.3f)' % (mean(single_scores), std(single_scores)))\n",
    "# plot score vs number of ensemble members\n",
    "x_axis = [i for i in range(1, len(members)+1)]\n",
    "pyplot.plot(x_axis, single_scores, marker='o', linestyle='None')\n",
    "pyplot.plot(x_axis, ensemble_scores, marker='o')\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
