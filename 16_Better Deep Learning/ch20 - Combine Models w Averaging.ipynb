{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot of blobs dataset\n",
    "from sklearn.datasets import make_blobs\n",
    "from matplotlib import pyplot\n",
    "from numpy import where\n",
    "# generate 2d classification dataset\n",
    "X, y = make_blobs(n_samples=500, centers=3, n_features=2, cluster_std=2, random_state=2)\n",
    "# scatter plot for each class value\n",
    "for class_value in range(3):\n",
    "\t# select indices of points with the class label\n",
    "\trow_ix = where(y == class_value)\n",
    "\t# scatter plot for points with a different color\n",
    "\tpyplot.scatter(X[row_ix, 0], X[row_ix, 1])\n",
    "# show plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit high variance mlp on blobs classification problem\n",
    "from sklearn.datasets import make_blobs\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from matplotlib import pyplot\n",
    "# generate 2d classification dataset\n",
    "X, y = make_blobs(n_samples=500, centers=3, n_features=2, cluster_std=2, random_state=2)\n",
    "y = to_categorical(y)\n",
    "# split into train and test\n",
    "n_train = int(0.3 * X.shape[0])\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(15, input_dim=2, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit model\n",
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=200, verbose=0)\n",
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "# plot loss learning curves\n",
    "pyplot.subplot(211)\n",
    "pyplot.title('Cross-Entropy Loss', pad=-40)\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "# plot accuracy learning curves\n",
    "pyplot.subplot(212)\n",
    "pyplot.title('Accuracy', pad=-40)\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate high variance of mlp model on blobs classification problem\n",
    "from sklearn.datasets import make_blobs\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# fit and evaluate a neural net model on the dataset\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(15, input_dim=2, activation='relu'))\n",
    "\tmodel.add(Dense(3, activation='softmax'))\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\t# fit model\n",
    "\tmodel.fit(trainX, trainy, epochs=200, verbose=0)\n",
    "\t# evaluate the model\n",
    "\t_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "\treturn test_acc\n",
    "\n",
    "# generate 2d classification dataset\n",
    "X, y = make_blobs(n_samples=500, centers=3, n_features=2, cluster_std=2, random_state=2)\n",
    "y = to_categorical(y)\n",
    "# split into train and test\n",
    "n_train = int(0.3 * X.shape[0])\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "# repeated evaluation\n",
    "n_repeats = 30\n",
    "scores = list()\n",
    "for _ in range(n_repeats):\n",
    "\tscore = evaluate_model(trainX, trainy, testX, testy)\n",
    "\tprint('> %.3f' % score)\n",
    "\tscores.append(score)\n",
    "# summarize the distribution of scores\n",
    "print('Scores Mean: %.3f, Standard Deviation: %.3f' % (mean(scores), std(scores)))\n",
    "# histogram of distribution\n",
    "pyplot.hist(scores, bins=10)\n",
    "pyplot.show()\n",
    "# boxplot of distribution\n",
    "pyplot.boxplot(scores)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model averaging ensemble and a study of ensemble size on test accuracy\n",
    "from sklearn.datasets import make_blobs\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib import pyplot\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "import numpy\n",
    "\n",
    "# fit model on dataset\n",
    "def fit_model(trainX, trainy):\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(15, input_dim=2, activation='relu'))\n",
    "\tmodel.add(Dense(3, activation='softmax'))\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\t# fit model\n",
    "\tmodel.fit(trainX, trainy, epochs=200, verbose=0)\n",
    "\treturn model\n",
    "\n",
    "# make an ensemble prediction for multi-class classification\n",
    "def ensemble_predictions(members, testX):\n",
    "\t# make predictions\n",
    "\tyhats = [model.predict(testX) for model in members]\n",
    "\tyhats = array(yhats)\n",
    "\t# sum across ensemble members\n",
    "\tsummed = numpy.sum(yhats, axis=0)\n",
    "\t# argmax across classes\n",
    "\tresult = argmax(summed, axis=1)\n",
    "\treturn result\n",
    "\n",
    "# evaluate a specific number of members in an ensemble\n",
    "def evaluate_n_members(members, n_members, testX, testy):\n",
    "\t# select a subset of members\n",
    "\tsubset = members[:n_members]\n",
    "\tprint(len(subset))\n",
    "\t# make prediction\n",
    "\tyhat = ensemble_predictions(subset, testX)\n",
    "\t# calculate accuracy\n",
    "\treturn accuracy_score(testy, yhat)\n",
    "\n",
    "# generate 2d classification dataset\n",
    "X, y = make_blobs(n_samples=500, centers=3, n_features=2, cluster_std=2, random_state=2)\n",
    "# split into train and test\n",
    "n_train = int(0.3 * X.shape[0])\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "trainy = to_categorical(trainy)\n",
    "# fit all models\n",
    "n_members = 20\n",
    "members = [fit_model(trainX, trainy) for _ in range(n_members)]\n",
    "# evaluate different numbers of ensembles\n",
    "scores = list()\n",
    "for i in range(1, n_members+1):\n",
    "\tscore = evaluate_n_members(members, i, testX, testy)\n",
    "\tprint('> %.3f' % score)\n",
    "\tscores.append(score)\n",
    "# plot score vs number of ensemble members\n",
    "x_axis = [i for i in range(1, n_members+1)]\n",
    "pyplot.plot(x_axis, scores)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeated evaluation of model averaging ensemble on blobs dataset\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import numpy\n",
    "\n",
    "# fit model on dataset\n",
    "def fit_model(trainX, trainy):\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(15, input_dim=2, activation='relu'))\n",
    "\tmodel.add(Dense(3, activation='softmax'))\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\t# fit model\n",
    "\tmodel.fit(trainX, trainy, epochs=200, verbose=0)\n",
    "\treturn model\n",
    "\n",
    "# make an ensemble prediction for multi-class classification\n",
    "def ensemble_predictions(members, testX):\n",
    "\t# make predictions\n",
    "\tyhats = [model.predict(testX) for model in members]\n",
    "\tyhats = array(yhats)\n",
    "\t# sum across ensemble members\n",
    "\tsummed = numpy.sum(yhats, axis=0)\n",
    "\t# argmax across classes\n",
    "\tresult = argmax(summed, axis=1)\n",
    "\treturn result\n",
    "\n",
    "# evaluate ensemble model\n",
    "def evaluate_members(members, testX, testy):\n",
    "\t# make prediction\n",
    "\tyhat = ensemble_predictions(members, testX)\n",
    "\t# calculate accuracy\n",
    "\treturn accuracy_score(testy, yhat)\n",
    "\n",
    "# generate 2d classification dataset\n",
    "X, y = make_blobs(n_samples=500, centers=3, n_features=2, cluster_std=2, random_state=2)\n",
    "# split into train and test\n",
    "n_train = int(0.3 * X.shape[0])\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "trainy = to_categorical(trainy)\n",
    "# repeated evaluation\n",
    "n_repeats = 30\n",
    "n_members = 5\n",
    "scores = list()\n",
    "for _ in range(n_repeats):\n",
    "\t# fit all models\n",
    "\tmembers = [fit_model(trainX, trainy) for _ in range(n_members)]\n",
    "\t# evaluate ensemble\n",
    "\tscore = evaluate_members(members, testX, testy)\n",
    "\tprint('> %.3f' % score)\n",
    "\tscores.append(score)\n",
    "# summarize the distribution of scores\n",
    "print('Scores Mean: %.3f, Standard Deviation: %.3f' % (mean(scores), std(scores)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
