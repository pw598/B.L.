{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4241da4f-1b06-46d4-8d50-1121e4605971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data into NumPy arrays\n",
    "data = load_iris()\n",
    "X, y = data[\"data\"], data[\"target\"]\n",
    "\n",
    "# convert NumPy array into PyTorch tensors\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "# split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
    "\n",
    "# PyTorch model\n",
    "class Multiclass(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(4, 8)\n",
    "        self.act = nn.ReLU()\n",
    "        self.output = nn.Linear(8, 3)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.hidden(x))\n",
    "        x = self.logsoftmax(self.output(x))\n",
    "        return x\n",
    "\n",
    "model = Multiclass()\n",
    "\n",
    "# loss metric and optimizer\n",
    "loss_fn = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# prepare model and training parameters\n",
    "n_epochs = 100\n",
    "batch_size = 5\n",
    "batch_start = torch.arange(0, len(X), batch_size)\n",
    "\n",
    "# training loop\n",
    "for epoch in range(n_epochs):\n",
    "    for start in batch_start:\n",
    "        # take a batch\n",
    "        X_batch = X_train[start:start+batch_size]\n",
    "        y_batch = y_train[start:start+batch_size]\n",
    "        # forward pass\n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # update weights\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2072470-798b-43f7-bfe3-1b74340ebdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98\n",
      "Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data into NumPy arrays\n",
    "data = load_iris()\n",
    "X, y = data[\"data\"], data[\"target\"]\n",
    "\n",
    "# convert NumPy array into PyTorch tensors\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "# split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
    "\n",
    "# PyTorch model\n",
    "class Multiclass(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(4, 8)\n",
    "        self.act = nn.ReLU()\n",
    "        self.output = nn.Linear(8, 3)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.hidden(x))\n",
    "        x = self.logsoftmax(self.output(x))\n",
    "        return x\n",
    "\n",
    "model = Multiclass()\n",
    "\n",
    "# loss metric and optimizer\n",
    "loss_fn = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# prepare model and training parameters\n",
    "n_epochs = 100\n",
    "batch_size = 5\n",
    "batch_start = torch.arange(0, len(X), batch_size)\n",
    "\n",
    "# training loop\n",
    "for epoch in range(n_epochs):\n",
    "    for start in batch_start:\n",
    "        # take a batch\n",
    "        X_batch = X_train[start:start+batch_size]\n",
    "        y_batch = y_train[start:start+batch_size]\n",
    "        # forward pass\n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "\n",
    "# test for accuracy\n",
    "y_pred = model(X_test)\n",
    "acc = (torch.argmax(y_pred, 1) == y_test).float().mean()\n",
    "print(\"Accuracy: %.2f\" % acc)\n",
    "\n",
    "# create a new model\n",
    "newmodel = Multiclass()\n",
    "# ask PyTorch to ignore autograd on update and overwrite parameters\n",
    "with torch.no_grad():\n",
    "    for newtensor, oldtensor in zip(newmodel.parameters(), model.parameters()):\n",
    "        newtensor.copy_(oldtensor)\n",
    "# test with new model using copied tensor\n",
    "y_pred = newmodel(X_test)\n",
    "acc = (torch.argmax(y_pred, 1) == y_test).float().mean()\n",
    "print(\"Accuracy: %.2f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c00b39a-8377-480e-8336-63939d88bce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([   (   'hidden.weight',\n",
      "                    tensor([[ 0.2262,  0.3639,  0.2870, -0.1101],\n",
      "        [-0.2166, -0.2163,  0.4238,  0.3000],\n",
      "        [-0.1015, -0.3168,  0.3749,  0.0970],\n",
      "        [ 0.2416,  0.3581,  0.3239,  0.3959],\n",
      "        [-0.2048,  0.4351, -0.1350, -0.0258],\n",
      "        [ 0.0370,  0.4877,  0.2952, -0.3643],\n",
      "        [-0.1532, -0.4151,  0.4357,  0.0910],\n",
      "        [-0.3102,  0.0893, -0.0526,  0.4622]])),\n",
      "                (   'hidden.bias',\n",
      "                    tensor([ 0.2753, -0.1190, -0.3213, -0.3782, -0.1379,  0.2295, -0.0717, -0.1520])),\n",
      "                (   'output.weight',\n",
      "                    tensor([[ 0.0970,  0.1932, -0.2580, -0.0094, -0.1149, -0.1099, -0.1019, -0.0886],\n",
      "        [-0.2906,  0.1498,  0.0478, -0.1677, -0.2994, -0.0380,  0.1761, -0.0975],\n",
      "        [-0.2932, -0.2377,  0.1616, -0.3163,  0.3109, -0.2100,  0.3068,  0.1511]])),\n",
      "                ('output.bias', tensor([-0.2588,  0.3301, -0.1467]))])\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "import torch.nn as nn\n",
    "\n",
    "# PyTorch model\n",
    "class Multiclass(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(4, 8)\n",
    "        self.act = nn.ReLU()\n",
    "        self.output = nn.Linear(8, 3)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.hidden(x))\n",
    "        x = self.logsoftmax(self.output(x))\n",
    "        return x\n",
    "\n",
    "model = Multiclass()\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce79dbb9-c4b5-41af-b66d-4e6dc17a95e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n",
      "Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data into NumPy arrays\n",
    "data = load_iris()\n",
    "X, y = data[\"data\"], data[\"target\"]\n",
    "\n",
    "# convert NumPy array into PyTorch tensors\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "# split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
    "\n",
    "# PyTorch model\n",
    "class Multiclass(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(4, 8)\n",
    "        self.act = nn.ReLU()\n",
    "        self.output = nn.Linear(8, 3)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.hidden(x))\n",
    "        x = self.logsoftmax(self.output(x))\n",
    "        return x\n",
    "\n",
    "model = Multiclass()\n",
    "\n",
    "# loss metric and optimizer\n",
    "loss_fn = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# prepare model and training parameters\n",
    "n_epochs = 100\n",
    "batch_size = 5\n",
    "batch_start = torch.arange(0, len(X), batch_size)\n",
    "\n",
    "# training loop\n",
    "for epoch in range(n_epochs):\n",
    "    for start in batch_start:\n",
    "        # take a batch\n",
    "        X_batch = X_train[start:start+batch_size]\n",
    "        y_batch = y_train[start:start+batch_size]\n",
    "        # forward pass\n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "\n",
    "# test for accuracy\n",
    "y_pred = model(X_test)\n",
    "acc = (torch.argmax(y_pred, 1) == y_test).float().mean()\n",
    "print(\"Accuracy: %.2f\" % acc)\n",
    "\n",
    "# Save model\n",
    "with open(\"iris-model.pickle\", \"wb\") as fp:\n",
    "    pickle.dump(model.state_dict(), fp)\n",
    "\n",
    "# Create new model and load states\n",
    "newmodel = Multiclass()\n",
    "with open(\"iris-model.pickle\", \"rb\") as fp:\n",
    "    newmodel.load_state_dict(pickle.load(fp))\n",
    "\n",
    "# test with new model using copied tensor\n",
    "y_pred = newmodel(X_test)\n",
    "acc = (torch.argmax(y_pred, 1) == y_test).float().mean()\n",
    "print(\"Accuracy: %.2f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03bc46dc-88d6-4bd8-8a9a-d6550eccd10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.93\n",
      "Accuracy: 0.93\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data into NumPy arrays\n",
    "data = load_iris()\n",
    "X, y = data[\"data\"], data[\"target\"]\n",
    "\n",
    "# convert NumPy array into PyTorch tensors\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "# split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
    "\n",
    "# PyTorch model\n",
    "class Multiclass(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(4, 8)\n",
    "        self.act = nn.ReLU()\n",
    "        self.output = nn.Linear(8, 3)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.hidden(x))\n",
    "        x = self.logsoftmax(self.output(x))\n",
    "        return x\n",
    "\n",
    "model = Multiclass()\n",
    "\n",
    "# loss metric and optimizer\n",
    "loss_fn = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# prepare model and training parameters\n",
    "n_epochs = 100\n",
    "batch_size = 5\n",
    "batch_start = torch.arange(0, len(X), batch_size)\n",
    "\n",
    "# training loop\n",
    "for epoch in range(n_epochs):\n",
    "    for start in batch_start:\n",
    "        # take a batch\n",
    "        X_batch = X_train[start:start+batch_size]\n",
    "        y_batch = y_train[start:start+batch_size]\n",
    "        # forward pass\n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "\n",
    "# test for accuracy\n",
    "y_pred = model(X_test)\n",
    "acc = (torch.argmax(y_pred, 1) == y_test).float().mean()\n",
    "print(\"Accuracy: %.2f\" % acc)\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), \"iris-model.pth\")\n",
    "\n",
    "# Create new model and load states\n",
    "newmodel = Multiclass()\n",
    "newmodel.load_state_dict(torch.load(\"iris-model.pth\"))\n",
    "\n",
    "# test with new model using copied tensor\n",
    "y_pred = newmodel(X_test)\n",
    "acc = (torch.argmax(y_pred, 1) == y_test).float().mean()\n",
    "print(\"Accuracy: %.2f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b711dee2-de5e-403e-993e-da66bae1c4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n",
      "Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data into NumPy arrays\n",
    "data = load_iris()\n",
    "X, y = data[\"data\"], data[\"target\"]\n",
    "\n",
    "# convert NumPy array into PyTorch tensors\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "# split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
    "\n",
    "# PyTorch model\n",
    "class Multiclass(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(4, 8)\n",
    "        self.act = nn.ReLU()\n",
    "        self.output = nn.Linear(8, 3)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.hidden(x))\n",
    "        x = self.logsoftmax(self.output(x))\n",
    "        return x\n",
    "\n",
    "model = Multiclass()\n",
    "\n",
    "# loss metric and optimizer\n",
    "loss_fn = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# prepare model and training parameters\n",
    "n_epochs = 100\n",
    "batch_size = 5\n",
    "batch_start = torch.arange(0, len(X), batch_size)\n",
    "\n",
    "# training loop\n",
    "for epoch in range(n_epochs):\n",
    "    for start in batch_start:\n",
    "        # take a batch\n",
    "        X_batch = X_train[start:start+batch_size]\n",
    "        y_batch = y_train[start:start+batch_size]\n",
    "        # forward pass\n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "\n",
    "# test for accuracy\n",
    "y_pred = model(X_test)\n",
    "acc = (torch.argmax(y_pred, 1) == y_test).float().mean()\n",
    "print(\"Accuracy: %.2f\" % acc)\n",
    "\n",
    "# Save model\n",
    "torch.save(model, \"iris-model-full.pth\")\n",
    "\n",
    "# Load model\n",
    "newmodel = torch.load(\"iris-model-full.pth\")\n",
    "\n",
    "# test with new model using copied tensor\n",
    "y_pred = newmodel(X_test)\n",
    "acc = (torch.argmax(y_pred, 1) == y_test).float().mean()\n",
    "print(\"Accuracy: %.2f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e5511a5-fc41-4c48-8921-e64012579e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data into NumPy arrays\n",
    "data = load_iris()\n",
    "X, y = data[\"data\"], data[\"target\"]\n",
    "\n",
    "# convert NumPy array into PyTorch tensors\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "# split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
    "\n",
    "# PyTorch model\n",
    "class Multiclass(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(4, 8)\n",
    "        self.act = nn.ReLU()\n",
    "        self.output = nn.Linear(8, 3)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.hidden(x))\n",
    "        x = self.logsoftmax(self.output(x))\n",
    "        return x\n",
    "\n",
    "model = Multiclass()\n",
    "\n",
    "# loss metric and optimizer\n",
    "loss_fn = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# prepare model and training parameters\n",
    "n_epochs = 100\n",
    "batch_size = 5\n",
    "batch_start = torch.arange(0, len(X), batch_size)\n",
    "\n",
    "# training loop\n",
    "for epoch in range(n_epochs):\n",
    "    for start in batch_start:\n",
    "        # take a batch\n",
    "        X_batch = X_train[start:start+batch_size]\n",
    "        y_batch = y_train[start:start+batch_size]\n",
    "        # forward pass\n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), \"iris-model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6279a688-8919-4a64-bb52-590c1435f3d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data into NumPy arrays\n",
    "data = load_iris()\n",
    "X, y = data[\"data\"], data[\"target\"]\n",
    "\n",
    "# convert NumPy array into PyTorch tensors\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "# split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
    "\n",
    "# PyTorch model\n",
    "class Multiclass(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(4, 8)\n",
    "        self.act = nn.ReLU()\n",
    "        self.output = nn.Linear(8, 3)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.hidden(x))\n",
    "        x = self.logsoftmax(self.output(x))\n",
    "        return x\n",
    "\n",
    "# Create new model and load states\n",
    "model = Multiclass()\n",
    "model.load_state_dict(torch.load(\"iris-model.pth\"))\n",
    "\n",
    "# Run model for inference\n",
    "y_pred = model(X_test)\n",
    "acc = (torch.argmax(y_pred, 1) == y_test).float().mean()\n",
    "print(\"Accuracy: %.2f\" % acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
