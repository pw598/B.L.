{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "515f2bd3-eb6e-437d-b52c-8cd48811cf5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0900e-02, 2.6100e-02, 1.2000e-02, 7.6800e-02, 1.0640e-01, 1.6800e-01,\n",
      "         3.0160e-01, 3.4600e-01, 3.3140e-01, 4.1250e-01, 3.9430e-01, 1.3340e-01,\n",
      "         4.6220e-01, 9.9700e-01, 9.1370e-01, 8.2920e-01, 6.9940e-01, 7.8250e-01,\n",
      "         8.7890e-01, 8.5010e-01, 8.9200e-01, 9.4730e-01, 1.0000e+00, 8.9750e-01,\n",
      "         7.8060e-01, 8.3210e-01, 6.5020e-01, 4.5480e-01, 4.7320e-01, 3.3910e-01,\n",
      "         2.7470e-01, 9.7800e-02, 4.7700e-02, 1.4030e-01, 1.8340e-01, 2.1480e-01,\n",
      "         1.2710e-01, 1.9120e-01, 3.3910e-01, 3.4440e-01, 2.3690e-01, 1.1950e-01,\n",
      "         2.6650e-01, 2.5870e-01, 1.3930e-01, 1.0830e-01, 1.3830e-01, 1.3210e-01,\n",
      "         1.0690e-01, 3.2500e-02, 3.1600e-02, 5.7000e-03, 1.5900e-02, 8.5000e-03,\n",
      "         3.7200e-02, 1.0100e-02, 1.2700e-02, 2.8800e-02, 1.2900e-02, 2.3000e-03],\n",
      "        [2.0900e-02, 2.7800e-02, 1.1500e-02, 4.4500e-02, 4.2700e-02, 7.6600e-02,\n",
      "         1.4580e-01, 1.4300e-01, 1.8940e-01, 1.8530e-01, 1.7480e-01, 1.5560e-01,\n",
      "         1.4760e-01, 1.3780e-01, 2.5840e-01, 3.8270e-01, 4.7840e-01, 5.3600e-01,\n",
      "         6.1920e-01, 7.9120e-01, 9.2640e-01, 1.0000e+00, 9.0800e-01, 7.4350e-01,\n",
      "         5.5570e-01, 3.1720e-01, 1.2950e-01, 5.9800e-02, 2.7220e-01, 3.6160e-01,\n",
      "         3.2930e-01, 4.8550e-01, 3.9360e-01, 1.8450e-01, 3.4200e-02, 2.4890e-01,\n",
      "         3.8370e-01, 3.5140e-01, 2.6540e-01, 1.7600e-01, 1.5990e-01, 8.6600e-02,\n",
      "         5.9000e-02, 8.1300e-02, 4.9200e-02, 4.1700e-02, 4.9500e-02, 3.6700e-02,\n",
      "         1.1500e-02, 1.1800e-02, 1.3300e-02, 9.6000e-03, 1.4000e-03, 4.9000e-03,\n",
      "         3.9000e-03, 2.9000e-03, 7.8000e-03, 4.7000e-03, 2.1000e-03, 1.1000e-03],\n",
      "        [7.0700e-02, 1.2520e-01, 1.4470e-01, 1.6440e-01, 1.6930e-01, 8.4400e-02,\n",
      "         7.1500e-02, 9.4700e-02, 1.5830e-01, 1.2470e-01, 2.3400e-01, 1.7640e-01,\n",
      "         2.2840e-01, 3.1150e-01, 4.7250e-01, 5.5430e-01, 5.3860e-01, 3.7460e-01,\n",
      "         4.5830e-01, 5.9610e-01, 7.4640e-01, 7.6440e-01, 5.7110e-01, 6.2570e-01,\n",
      "         6.6950e-01, 7.1310e-01, 7.5670e-01, 8.0770e-01, 8.4770e-01, 9.2890e-01,\n",
      "         9.5130e-01, 7.9950e-01, 4.3620e-01, 4.0480e-01, 4.9520e-01, 1.7120e-01,\n",
      "         3.6520e-01, 3.7630e-01, 2.8410e-01, 4.2700e-02, 5.3310e-01, 6.9520e-01,\n",
      "         4.2880e-01, 3.0630e-01, 5.8350e-01, 5.6920e-01, 2.6300e-01, 1.1960e-01,\n",
      "         9.8300e-02, 3.7400e-02, 2.9100e-02, 1.5600e-02, 1.9700e-02, 1.3500e-02,\n",
      "         1.2700e-02, 1.3800e-02, 1.3300e-02, 1.3100e-02, 1.5400e-02, 2.1800e-02],\n",
      "        [1.3200e-02, 8.0000e-03, 1.8800e-02, 1.4100e-02, 4.3600e-02, 6.6800e-02,\n",
      "         6.0900e-02, 1.3100e-02, 8.9900e-02, 9.2200e-02, 1.4450e-01, 1.4750e-01,\n",
      "         2.0870e-01, 2.5580e-01, 2.6030e-01, 1.9850e-01, 2.3940e-01, 3.1340e-01,\n",
      "         4.0770e-01, 4.5290e-01, 4.8930e-01, 5.6660e-01, 6.2340e-01, 6.7410e-01,\n",
      "         8.2820e-01, 8.8230e-01, 9.1960e-01, 8.9650e-01, 7.5490e-01, 6.7360e-01,\n",
      "         6.4630e-01, 5.0070e-01, 3.6630e-01, 2.2980e-01, 1.3620e-01, 2.1230e-01,\n",
      "         2.3950e-01, 2.6730e-01, 2.8650e-01, 2.0600e-01, 1.6590e-01, 2.6330e-01,\n",
      "         2.5520e-01, 1.6960e-01, 1.4670e-01, 1.2860e-01, 9.2600e-02, 7.1600e-02,\n",
      "         3.2500e-02, 2.5800e-02, 1.3600e-02, 4.4000e-03, 2.8000e-03, 2.1000e-03,\n",
      "         2.2000e-03, 4.8000e-03, 1.3800e-02, 1.4000e-02, 2.8000e-03, 6.4000e-03],\n",
      "        [7.9000e-02, 7.0700e-02, 3.5200e-02, 1.6600e-01, 1.3300e-01, 2.2600e-02,\n",
      "         7.7100e-02, 2.6780e-01, 5.6640e-01, 6.6090e-01, 5.0020e-01, 2.5830e-01,\n",
      "         1.6500e-01, 4.3470e-01, 4.5150e-01, 4.5790e-01, 3.3660e-01, 4.0000e-01,\n",
      "         5.3250e-01, 9.0100e-01, 9.9390e-01, 3.6890e-01, 1.0120e-01, 2.4800e-02,\n",
      "         2.3180e-01, 3.9810e-01, 2.2590e-01, 5.2470e-01, 6.8980e-01, 8.3160e-01,\n",
      "         4.3260e-01, 3.7410e-01, 5.7560e-01, 8.0430e-01, 7.9630e-01, 7.1740e-01,\n",
      "         7.0560e-01, 8.1480e-01, 7.6010e-01, 6.0340e-01, 4.5540e-01, 4.7290e-01,\n",
      "         4.4780e-01, 3.7220e-01, 4.6930e-01, 3.8390e-01, 7.6800e-02, 1.4670e-01,\n",
      "         7.7700e-02, 4.6900e-02, 1.9300e-02, 2.9800e-02, 3.9000e-02, 2.9400e-02,\n",
      "         1.7500e-02, 2.4900e-02, 1.4100e-02, 7.3000e-03, 2.5000e-03, 1.0100e-02],\n",
      "        [2.9800e-02, 6.1500e-02, 6.5000e-02, 9.2100e-02, 1.6150e-01, 2.2940e-01,\n",
      "         2.1760e-01, 2.0330e-01, 1.4590e-01, 8.5200e-02, 2.4760e-01, 3.6450e-01,\n",
      "         2.7770e-01, 2.8260e-01, 3.2370e-01, 4.3350e-01, 5.6380e-01, 4.5550e-01,\n",
      "         4.3480e-01, 6.4330e-01, 3.9320e-01, 1.9890e-01, 3.5400e-01, 9.1650e-01,\n",
      "         9.3710e-01, 4.6200e-01, 2.7710e-01, 6.6130e-01, 8.0280e-01, 4.2000e-01,\n",
      "         5.1920e-01, 6.9620e-01, 5.7920e-01, 8.8890e-01, 7.8630e-01, 7.1330e-01,\n",
      "         7.6150e-01, 4.4010e-01, 3.0090e-01, 3.1630e-01, 2.8090e-01, 2.8980e-01,\n",
      "         5.2600e-02, 1.8670e-01, 1.5530e-01, 1.6330e-01, 1.2520e-01, 7.4800e-02,\n",
      "         4.5200e-02, 6.4000e-03, 1.5400e-02, 3.1000e-03, 1.5300e-02, 7.1000e-03,\n",
      "         2.1200e-02, 7.6000e-03, 1.5200e-02, 4.9000e-03, 2.0000e-02, 7.3000e-03],\n",
      "        [1.3000e-02, 6.0000e-04, 8.8000e-03, 4.5600e-02, 5.2500e-02, 7.7800e-02,\n",
      "         9.3100e-02, 9.4100e-02, 1.7110e-01, 1.4830e-01, 1.5320e-01, 1.1000e-01,\n",
      "         8.9000e-02, 1.2360e-01, 1.1970e-01, 1.1450e-01, 2.1370e-01, 2.8380e-01,\n",
      "         3.6400e-01, 5.4300e-01, 6.6730e-01, 7.9790e-01, 9.2730e-01, 9.0270e-01,\n",
      "         9.1920e-01, 1.0000e+00, 9.8210e-01, 9.0920e-01, 8.1840e-01, 6.9620e-01,\n",
      "         5.9000e-01, 5.4470e-01, 5.1420e-01, 5.3890e-01, 5.5310e-01, 5.3180e-01,\n",
      "         4.8260e-01, 3.7900e-01, 1.8310e-01, 1.7500e-01, 1.6790e-01, 6.7400e-02,\n",
      "         6.0900e-02, 3.7500e-02, 5.3300e-02, 2.7800e-02, 1.7900e-02, 1.1400e-02,\n",
      "         7.3000e-03, 1.1600e-02, 9.2000e-03, 7.8000e-03, 4.1000e-03, 1.3000e-03,\n",
      "         1.1000e-03, 4.5000e-03, 3.9000e-03, 2.2000e-03, 2.3000e-03, 1.6000e-03],\n",
      "        [2.3300e-02, 3.9400e-02, 4.1600e-02, 5.4700e-02, 9.9300e-02, 1.5150e-01,\n",
      "         1.6740e-01, 1.5130e-01, 1.7230e-01, 2.0780e-01, 1.2390e-01, 2.3600e-02,\n",
      "         1.7710e-01, 3.1150e-01, 4.9900e-01, 6.7070e-01, 7.6550e-01, 8.4850e-01,\n",
      "         9.8050e-01, 1.0000e+00, 1.0000e+00, 9.9920e-01, 9.0670e-01, 6.8030e-01,\n",
      "         5.1030e-01, 4.7160e-01, 4.9800e-01, 6.1960e-01, 7.1710e-01, 6.3160e-01,\n",
      "         3.5540e-01, 2.8970e-01, 4.3160e-01, 3.7910e-01, 2.4210e-01, 9.4400e-02,\n",
      "         3.5100e-02, 8.4400e-02, 4.3600e-02, 1.1300e-01, 2.0450e-01, 1.9370e-01,\n",
      "         8.3400e-02, 1.5020e-01, 1.6750e-01, 1.0580e-01, 1.1110e-01, 8.4900e-02,\n",
      "         5.9600e-02, 2.0100e-02, 7.1000e-03, 1.0400e-02, 6.2000e-03, 2.6000e-03,\n",
      "         2.5000e-03, 6.1000e-03, 3.8000e-03, 1.0100e-02, 7.8000e-03, 6.0000e-04],\n",
      "        [2.5000e-03, 3.0900e-02, 1.7100e-02, 2.2800e-02, 4.3400e-02, 1.2240e-01,\n",
      "         1.9470e-01, 1.6610e-01, 1.3680e-01, 1.4300e-01, 9.9400e-02, 2.2500e-01,\n",
      "         2.4440e-01, 3.2390e-01, 3.0390e-01, 2.4100e-01, 3.6700e-02, 1.6720e-01,\n",
      "         3.0380e-01, 4.0690e-01, 3.6130e-01, 1.9940e-01, 4.6110e-01, 6.8490e-01,\n",
      "         7.2720e-01, 7.1520e-01, 7.1020e-01, 8.5160e-01, 1.0000e+00, 7.6900e-01,\n",
      "         4.8410e-01, 3.7170e-01, 6.0960e-01, 5.1100e-01, 2.5860e-01, 9.1600e-02,\n",
      "         9.4700e-02, 2.2870e-01, 3.4800e-01, 2.0950e-01, 1.9010e-01, 2.9410e-01,\n",
      "         2.2110e-01, 1.5240e-01, 7.4600e-02, 6.0600e-02, 6.9200e-02, 4.4600e-02,\n",
      "         3.4400e-02, 8.2000e-03, 1.0800e-02, 1.4900e-02, 7.7000e-03, 3.6000e-03,\n",
      "         1.1400e-02, 8.5000e-03, 1.0100e-02, 1.6000e-03, 2.8000e-03, 1.4000e-03],\n",
      "        [1.5800e-02, 2.3900e-02, 1.5000e-02, 4.9400e-02, 9.8800e-02, 1.4250e-01,\n",
      "         1.4630e-01, 1.2190e-01, 1.6970e-01, 1.9230e-01, 2.3610e-01, 2.7190e-01,\n",
      "         3.0490e-01, 2.9860e-01, 2.2260e-01, 1.7450e-01, 2.4590e-01, 3.1000e-01,\n",
      "         3.5720e-01, 4.2830e-01, 4.2680e-01, 3.7350e-01, 4.5850e-01, 6.0940e-01,\n",
      "         7.2210e-01, 7.5950e-01, 8.7060e-01, 1.0000e+00, 9.8150e-01, 7.1870e-01,\n",
      "         5.8480e-01, 4.1920e-01, 3.7560e-01, 3.2630e-01, 1.9440e-01, 1.3940e-01,\n",
      "         1.6700e-01, 1.2750e-01, 1.6660e-01, 2.5740e-01, 2.2580e-01, 2.7770e-01,\n",
      "         1.6130e-01, 1.3350e-01, 1.9760e-01, 1.2340e-01, 1.5540e-01, 1.0570e-01,\n",
      "         4.9000e-02, 9.7000e-03, 2.2300e-02, 1.2100e-02, 1.0800e-02, 5.7000e-03,\n",
      "         2.8000e-03, 7.9000e-03, 3.4000e-03, 4.6000e-03, 2.2000e-03, 2.1000e-03],\n",
      "        [5.0000e-03, 1.7000e-03, 2.7000e-02, 4.5000e-02, 9.5800e-02, 8.3000e-02,\n",
      "         8.7900e-02, 1.2200e-01, 1.9770e-01, 2.2820e-01, 2.5210e-01, 3.4840e-01,\n",
      "         3.3090e-01, 2.6140e-01, 1.7820e-01, 2.0550e-01, 2.2980e-01, 3.5450e-01,\n",
      "         6.2180e-01, 7.2650e-01, 8.3460e-01, 8.2680e-01, 8.3660e-01, 9.4080e-01,\n",
      "         9.5100e-01, 9.8010e-01, 9.9740e-01, 1.0000e+00, 9.0360e-01, 6.4090e-01,\n",
      "         3.8570e-01, 2.9080e-01, 2.0400e-01, 1.6530e-01, 1.7690e-01, 1.1400e-01,\n",
      "         7.4000e-02, 9.4100e-02, 6.2100e-02, 4.2600e-02, 5.7200e-02, 1.0680e-01,\n",
      "         1.9090e-01, 2.2290e-01, 2.2030e-01, 2.2650e-01, 1.7660e-01, 1.0970e-01,\n",
      "         5.5800e-02, 1.4200e-02, 2.8100e-02, 1.6500e-02, 5.6000e-03, 1.0000e-03,\n",
      "         2.7000e-03, 6.2000e-03, 2.4000e-03, 6.3000e-03, 1.7000e-03, 2.8000e-03],\n",
      "        [7.1200e-02, 9.0100e-02, 1.2760e-01, 1.4970e-01, 1.2840e-01, 1.1650e-01,\n",
      "         1.2850e-01, 1.6840e-01, 1.8300e-01, 2.1270e-01, 2.8910e-01, 3.9850e-01,\n",
      "         4.5760e-01, 5.8210e-01, 5.0270e-01, 1.9300e-01, 2.5790e-01, 3.1770e-01,\n",
      "         2.7450e-01, 6.1860e-01, 8.9580e-01, 7.4420e-01, 5.1880e-01, 2.8110e-01,\n",
      "         1.7730e-01, 6.6070e-01, 7.5760e-01, 5.1220e-01, 4.7010e-01, 5.4790e-01,\n",
      "         4.3470e-01, 1.2760e-01, 8.4600e-02, 9.2700e-02, 3.1300e-02, 9.9800e-02,\n",
      "         1.7810e-01, 1.5860e-01, 3.0010e-01, 2.2080e-01, 1.4550e-01, 2.8950e-01,\n",
      "         3.2030e-01, 1.4140e-01, 6.2900e-02, 7.3400e-02, 8.0500e-02, 6.0800e-02,\n",
      "         5.6500e-02, 2.8600e-02, 1.5400e-02, 1.5400e-02, 1.5600e-02, 5.4000e-03,\n",
      "         3.0000e-03, 4.8000e-03, 8.7000e-03, 1.0100e-02, 9.5000e-03, 6.8000e-03],\n",
      "        [2.2800e-02, 1.0600e-02, 1.3000e-02, 8.4200e-02, 1.1170e-01, 1.5060e-01,\n",
      "         1.7760e-01, 9.9700e-02, 1.4280e-01, 2.2270e-01, 2.6210e-01, 3.1090e-01,\n",
      "         2.8590e-01, 3.3160e-01, 3.7550e-01, 4.4990e-01, 4.7650e-01, 6.2540e-01,\n",
      "         7.3040e-01, 8.7020e-01, 9.3490e-01, 9.6140e-01, 9.1260e-01, 9.4430e-01,\n",
      "         1.0000e+00, 9.4550e-01, 8.8150e-01, 7.5200e-01, 7.0680e-01, 5.9860e-01,\n",
      "         3.8570e-01, 2.5100e-01, 2.1620e-01, 9.6800e-02, 1.3230e-01, 1.3440e-01,\n",
      "         2.2500e-01, 3.2440e-01, 3.9390e-01, 3.8060e-01, 3.2580e-01, 3.6540e-01,\n",
      "         2.9830e-01, 1.7790e-01, 1.5350e-01, 1.1990e-01, 9.5900e-02, 7.6500e-02,\n",
      "         6.4900e-02, 3.1300e-02, 1.8500e-02, 9.8000e-03, 1.7800e-02, 7.7000e-03,\n",
      "         7.4000e-03, 9.5000e-03, 5.5000e-03, 4.5000e-03, 6.3000e-03, 3.9000e-03],\n",
      "        [1.9500e-02, 2.1300e-02, 5.8000e-03, 1.9000e-02, 3.1900e-02, 5.7100e-02,\n",
      "         1.0040e-01, 6.6800e-02, 6.9100e-02, 2.4200e-02, 7.2800e-02, 6.3900e-02,\n",
      "         3.0020e-01, 3.8540e-01, 4.7670e-01, 4.6020e-01, 3.1750e-01, 4.1600e-01,\n",
      "         6.4280e-01, 1.0000e+00, 8.6310e-01, 5.2120e-01, 3.1560e-01, 5.9520e-01,\n",
      "         7.7320e-01, 6.0420e-01, 4.3750e-01, 5.4870e-01, 4.7200e-01, 6.2350e-01,\n",
      "         3.8510e-01, 1.5900e-01, 3.8910e-01, 5.2940e-01, 3.5040e-01, 4.4800e-01,\n",
      "         4.0410e-01, 5.0310e-01, 6.4750e-01, 5.4930e-01, 3.5480e-01, 2.0280e-01,\n",
      "         1.8820e-01, 8.4500e-02, 1.3150e-01, 1.5900e-01, 5.6200e-02, 6.1700e-02,\n",
      "         3.4300e-02, 3.7000e-02, 2.6100e-02, 1.5700e-02, 7.4000e-03, 2.7100e-02,\n",
      "         2.0300e-02, 8.9000e-03, 9.5000e-03, 9.5000e-03, 2.1000e-03, 5.3000e-03],\n",
      "        [2.6400e-02, 7.1000e-03, 3.4200e-02, 7.9300e-02, 1.0430e-01, 7.8300e-02,\n",
      "         1.4170e-01, 1.1760e-01, 4.5300e-02, 9.4500e-02, 1.1320e-01, 8.4000e-02,\n",
      "         7.1700e-02, 1.9680e-01, 2.6330e-01, 4.1910e-01, 5.0500e-01, 6.7110e-01,\n",
      "         7.9220e-01, 8.3810e-01, 8.7590e-01, 9.4220e-01, 1.0000e+00, 9.9310e-01,\n",
      "         9.5750e-01, 8.6470e-01, 7.2150e-01, 5.8010e-01, 4.9640e-01, 4.8860e-01,\n",
      "         4.0790e-01, 2.4430e-01, 1.7680e-01, 2.4720e-01, 3.5180e-01, 3.7620e-01,\n",
      "         2.9090e-01, 2.3110e-01, 3.1680e-01, 3.5540e-01, 3.7410e-01, 4.4430e-01,\n",
      "         3.2610e-01, 1.9630e-01, 8.6400e-02, 1.6880e-01, 1.9910e-01, 1.2170e-01,\n",
      "         6.2800e-02, 3.2300e-02, 2.5300e-02, 2.1400e-02, 2.6200e-02, 1.7700e-02,\n",
      "         3.7000e-03, 6.8000e-03, 1.2100e-02, 7.7000e-03, 7.8000e-03, 6.6000e-03],\n",
      "        [2.5800e-02, 4.3300e-02, 5.4700e-02, 6.8100e-02, 7.8400e-02, 1.2500e-01,\n",
      "         1.2960e-01, 1.7290e-01, 2.7940e-01, 2.9540e-01, 2.5060e-01, 2.6010e-01,\n",
      "         2.2490e-01, 2.1150e-01, 1.2700e-01, 1.1930e-01, 1.7940e-01, 2.1850e-01,\n",
      "         1.6460e-01, 7.4000e-02, 6.2500e-02, 2.3810e-01, 4.8240e-01, 6.3720e-01,\n",
      "         7.5310e-01, 8.9590e-01, 9.9410e-01, 9.9570e-01, 9.3280e-01, 9.3440e-01,\n",
      "         8.8540e-01, 7.6900e-01, 6.8650e-01, 6.3900e-01, 6.3780e-01, 6.6290e-01,\n",
      "         5.9830e-01, 4.5650e-01, 3.1290e-01, 4.1580e-01, 4.3250e-01, 4.0310e-01,\n",
      "         4.2010e-01, 4.5570e-01, 3.9550e-01, 2.9660e-01, 2.0950e-01, 1.5580e-01,\n",
      "         8.8400e-02, 2.6500e-02, 1.2100e-02, 9.1000e-03, 6.2000e-03, 1.9000e-03,\n",
      "         4.5000e-03, 7.9000e-03, 3.1000e-03, 6.3000e-03, 4.8000e-03, 5.0000e-03]]) tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Read data, convert to NumPy arrays\n",
    "data = pd.read_csv(\"sonar.csv\", header=None)\n",
    "X = data.iloc[:, 0:60].values\n",
    "y = data.iloc[:, 60].values\n",
    "\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y)\n",
    "\n",
    "# convert into PyTorch tensors\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "# create DataLoader, then take one batch\n",
    "loader = DataLoader(list(zip(X,y)), shuffle=True, batch_size=16)\n",
    "for X_batch, y_batch in loader:\n",
    "    print(X_batch, y_batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c0d2ad0-6ffe-4721-bd5a-c903a61e9abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 84.13%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Read data, convert to NumPy arrays\n",
    "data = pd.read_csv(\"sonar.csv\", header=None)\n",
    "X = data.iloc[:, 0:60].values\n",
    "y = data.iloc[:, 60].values\n",
    "\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y)\n",
    "\n",
    "# convert into PyTorch tensors\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "# train-test split for evaluation of the model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
    "\n",
    "# set up DataLoader for training set\n",
    "loader = DataLoader(list(zip(X_train, y_train)), shuffle=True, batch_size=16)\n",
    "\n",
    "# create model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(60, 60),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(60, 30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "n_epochs = 200\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "model.train()\n",
    "for epoch in range(n_epochs):\n",
    "    for X_batch, y_batch in loader:\n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# evaluate accuracy after training\n",
    "model.eval()\n",
    "y_pred = model(X_test)\n",
    "acc = (y_pred.round() == y_test).float().mean()\n",
    "acc = float(acc)\n",
    "print(\"Model accuracy: %.2f%%\" % (acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e9a1140-9662-4aa4-858f-693366660fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SonarDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        # convert into PyTorch tensors and remember them\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        # this should return the size of the dataset\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # this should return one sample from the dataset\n",
    "        features = self.X[idx]\n",
    "        target = self.y[idx]\n",
    "        return features, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f5f8f79-3bb0-4b54-89c9-4a75554b4803",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 79.03%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, default_collate\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Read data, convert to NumPy arrays\n",
    "data = pd.read_csv(\"sonar.csv\", header=None)\n",
    "X = data.iloc[:, 0:60].values\n",
    "y = data.iloc[:, 60].values\n",
    "\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y).reshape(-1, 1)\n",
    "\n",
    "class SonarDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        # convert into PyTorch tensors and remember them\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        # this should return the size of the dataset\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # this should return one sample from the dataset\n",
    "        features = self.X[idx]\n",
    "        target = self.y[idx]\n",
    "        return features, target\n",
    "\n",
    "# set up DataLoader for data set\n",
    "dataset = SonarDataset(X, y)\n",
    "trainset, testset = random_split(dataset, [0.7, 0.3])\n",
    "loader = DataLoader(trainset, shuffle=True, batch_size=16)\n",
    "\n",
    "# create model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(60, 60),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(60, 30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "n_epochs = 200\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "model.train()\n",
    "for epoch in range(n_epochs):\n",
    "    for X_batch, y_batch in loader:\n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# create one test tensor from the testset\n",
    "X_test, y_test = default_collate(testset)\n",
    "model.eval()\n",
    "y_pred = model(X_test)\n",
    "acc = (y_pred.round() == y_test).float().mean()\n",
    "acc = float(acc)\n",
    "print(\"Model accuracy: %.2f%%\" % (acc*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
