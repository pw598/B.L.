{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0255385f-bb0a-4730-a7d9-75dc1f7e6f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read data\n",
    "data = pd.read_csv(\"sonar.csv\", header=None)\n",
    "X = data.iloc[:, 0:60]\n",
    "y = data.iloc[:, 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09db5634-1afb-44a4-af5c-7dccf6924cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Read data\n",
    "data = pd.read_csv(\"sonar.csv\", header=None)\n",
    "X = data.iloc[:, 0:60]\n",
    "y = data.iloc[:, 60]\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e28231e-0eff-4144-a5d7-7eae6e1f1cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Read data\n",
    "data = pd.read_csv(\"sonar.csv\", header=None)\n",
    "X = data.iloc[:, 0:60]\n",
    "y = data.iloc[:, 60]\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0201aaac-5f67-4a59-bef1-9d09a95ef3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Wide(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(60, 180)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output = nn.Linear(180, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.hidden(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ed903e0-218f-42d4-8768-25a6bd194f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Deep(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(60, 60)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(60, 60)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.layer3 = nn.Linear(60, 60)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.output = nn.Linear(60, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.layer1(x))\n",
    "        x = self.act2(self.layer2(x))\n",
    "        x = self.act3(self.layer3(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "545efc06-3ddf-4ebd-b288-7f67b3bf6721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11161\n",
      "11041\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Wide(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(60, 180)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output = nn.Linear(180, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.hidden(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x\n",
    "\n",
    "class Deep(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(60, 60)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(60, 60)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.layer3 = nn.Linear(60, 60)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.output = nn.Linear(60, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.layer1(x))\n",
    "        x = self.act2(self.layer2(x))\n",
    "        x = self.act3(self.layer3(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x\n",
    "\n",
    "# Compare model sizes\n",
    "model1 = Wide()\n",
    "model2 = Deep()\n",
    "print(sum([x.reshape(-1).shape[0] for x in model1.parameters()]))  # 11161\n",
    "print(sum([x.reshape(-1).shape[0] for x in model2.parameters()]))  # 11041"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "517c9fd6-8b42-445e-958c-cd182bd0d7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (wide): 0.79\n",
      "Accuracy (wide): 0.71\n",
      "Accuracy (wide): 0.74\n",
      "Accuracy (wide): 0.73\n",
      "Accuracy (wide): 0.88\n",
      "Model accuracy: 76.96% (+/- 5.92%)\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Read data\n",
    "data = pd.read_csv(\"sonar.csv\", header=None)\n",
    "X = data.iloc[:, 0:60]\n",
    "y = data.iloc[:, 60]\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y)\n",
    "\n",
    "X = torch.tensor(X.values, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "class Wide(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(60, 180)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output = nn.Linear(180, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.hidden(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x\n",
    "\n",
    "def model_train(model, X_train, y_train, X_val, y_val):\n",
    "    # loss function and optimizer\n",
    "    loss_fn = nn.BCELoss()  # binary cross entropy\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "    n_epochs = 250   # number of epochs to run\n",
    "    batch_size = 10  # size of each batch\n",
    "    batch_start = torch.arange(0, len(X_train), batch_size)\n",
    "\n",
    "    # Hold the best model\n",
    "    best_acc = - np.inf   # init to negative infinity\n",
    "    best_weights = None\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "            bar.set_description(f\"Epoch {epoch}\")\n",
    "            for start in bar:\n",
    "                # take a batch\n",
    "                X_batch = X_train[start:start+batch_size]\n",
    "                y_batch = y_train[start:start+batch_size]\n",
    "                # forward pass\n",
    "                y_pred = model(X_batch)\n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "                # backward pass\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                # update weights\n",
    "                optimizer.step()\n",
    "                # print progress\n",
    "                acc = (y_pred.round() == y_batch).float().mean()\n",
    "                bar.set_postfix(\n",
    "                    loss=float(loss),\n",
    "                    acc=float(acc)\n",
    "                )\n",
    "        # evaluate accuracy at end of each epoch\n",
    "        model.eval()\n",
    "        y_pred = model(X_val)\n",
    "        acc = (y_pred.round() == y_val).float().mean()\n",
    "        acc = float(acc)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "    # restore model and return best accuracy\n",
    "    model.load_state_dict(best_weights)\n",
    "    return best_acc\n",
    "\n",
    "# define 5-fold cross validation test harness\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "cv_scores = []\n",
    "\n",
    "for train, test in kfold.split(X, y):\n",
    "    # create model, train, and get accuracy\n",
    "    model = Wide()\n",
    "    acc = model_train(model, X[train], y[train], X[test], y[test])\n",
    "    print(\"Accuracy (wide): %.2f\" % acc)\n",
    "    cv_scores.append(acc)\n",
    "\n",
    "# evaluate the model\n",
    "acc = np.mean(cv_scores)\n",
    "std = np.std(cv_scores)\n",
    "print(\"Model accuracy: %.2f%% (+/- %.2f%%)\" % (acc*100, std*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dacef1f-3de8-4f56-97d5-e61dd302732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "\n",
    "def model_train(model, X_train, y_train, X_val, y_val):\n",
    "    # loss function and optimizer\n",
    "    loss_fn = nn.BCELoss()  # binary cross entropy\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "    n_epochs = 250   # number of epochs to run\n",
    "    batch_size = 10  # size of each batch\n",
    "    batch_start = torch.arange(0, len(X_train), batch_size)\n",
    "\n",
    "    # Hold the best model\n",
    "    best_acc = - np.inf   # init to negative infinity\n",
    "    best_weights = None\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "            bar.set_description(f\"Epoch {epoch}\")\n",
    "            for start in bar:\n",
    "                # take a batch\n",
    "                X_batch = X_train[start:start+batch_size]\n",
    "                y_batch = y_train[start:start+batch_size]\n",
    "                # forward pass\n",
    "                y_pred = model(X_batch)\n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "                # backward pass\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                # update weights\n",
    "                optimizer.step()\n",
    "                # print progress\n",
    "                acc = (y_pred.round() == y_batch).float().mean()\n",
    "                bar.set_postfix(\n",
    "                    loss=float(loss),\n",
    "                    acc=float(acc)\n",
    "                )\n",
    "        # evaluate accuracy at end of each epoch\n",
    "        model.eval()\n",
    "        y_pred = model(X_val)\n",
    "        acc = (y_pred.round() == y_val).float().mean()\n",
    "        acc = float(acc)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "    # restore model and return best accuracy\n",
    "    model.load_state_dict(best_weights)\n",
    "    return best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aab24f1a-6258-4213-8bab-76e2cbb983e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (wide): 0.79\n",
      "Accuracy (wide): 0.79\n",
      "Accuracy (wide): 0.66\n",
      "Accuracy (wide): 0.86\n",
      "Accuracy (wide): 0.62\n",
      "Accuracy (deep): 0.90\n",
      "Accuracy (deep): 0.72\n",
      "Accuracy (deep): 0.72\n",
      "Accuracy (deep): 0.83\n",
      "Accuracy (deep): 0.83\n",
      "Wide: 74.48% (+/- 9.15%)\n",
      "Deep: 80.00% (+/- 6.69%)\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "# Read data\n",
    "data = pd.read_csv(\"sonar.csv\", header=None)\n",
    "X = data.iloc[:, 0:60]\n",
    "y = data.iloc[:, 60]\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y)\n",
    "\n",
    "X = torch.tensor(X.values, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "class Wide(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(60, 180)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output = nn.Linear(180, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.hidden(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x\n",
    "\n",
    "class Deep(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(60, 60)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(60, 60)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.layer3 = nn.Linear(60, 60)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.output = nn.Linear(60, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.layer1(x))\n",
    "        x = self.act2(self.layer2(x))\n",
    "        x = self.act3(self.layer3(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x\n",
    "\n",
    "def model_train(model, X_train, y_train, X_val, y_val):\n",
    "    # loss function and optimizer\n",
    "    loss_fn = nn.BCELoss()  # binary cross entropy\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "    n_epochs = 250   # number of epochs to run\n",
    "    batch_size = 10  # size of each batch\n",
    "    batch_start = torch.arange(0, len(X_train), batch_size)\n",
    "\n",
    "    # Hold the best model\n",
    "    best_acc = - np.inf   # init to negative infinity\n",
    "    best_weights = None\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "            bar.set_description(f\"Epoch {epoch}\")\n",
    "            for start in bar:\n",
    "                # take a batch\n",
    "                X_batch = X_train[start:start+batch_size]\n",
    "                y_batch = y_train[start:start+batch_size]\n",
    "                # forward pass\n",
    "                y_pred = model(X_batch)\n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "                # backward pass\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                # update weights\n",
    "                optimizer.step()\n",
    "                # print progress\n",
    "                acc = (y_pred.round() == y_batch).float().mean()\n",
    "                bar.set_postfix(\n",
    "                    loss=float(loss),\n",
    "                    acc=float(acc)\n",
    "                )\n",
    "        # evaluate accuracy at end of each epoch\n",
    "        model.eval()\n",
    "        y_pred = model(X_val)\n",
    "        acc = (y_pred.round() == y_val).float().mean()\n",
    "        acc = float(acc)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "    # restore model and return best accuracy\n",
    "    model.load_state_dict(best_weights)\n",
    "    return best_acc\n",
    "\n",
    "# train-test split: Hold out the test set for final model evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
    "\n",
    "# define 5-fold cross validation test harness\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "cv_scores_wide = []\n",
    "for train, test in kfold.split(X_train, y_train):\n",
    "    # create model, train, and get accuracy\n",
    "    model = Wide()\n",
    "    acc = model_train(model, X_train[train], y_train[train], X_train[test], y_train[test])\n",
    "    print(\"Accuracy (wide): %.2f\" % acc)\n",
    "    cv_scores_wide.append(acc)\n",
    "cv_scores_deep = []\n",
    "for train, test in kfold.split(X_train, y_train):\n",
    "    # create model, train, and get accuracy\n",
    "    model = Deep()\n",
    "    acc = model_train(model, X_train[train], y_train[train], X_train[test], y_train[test])\n",
    "    print(\"Accuracy (deep): %.2f\" % acc)\n",
    "    cv_scores_deep.append(acc)\n",
    "\n",
    "# evaluate the model\n",
    "wide_acc = np.mean(cv_scores_wide)\n",
    "wide_std = np.std(cv_scores_wide)\n",
    "deep_acc = np.mean(cv_scores_deep)\n",
    "deep_std = np.std(cv_scores_deep)\n",
    "print(\"Wide: %.2f%% (+/- %.2f%%)\" % (wide_acc*100, wide_std*100))\n",
    "print(\"Deep: %.2f%% (+/- %.2f%%)\" % (deep_acc*100, deep_std*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f3ad02f-377a-4618-af85-fa4350420712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11161\n",
      "11041\n",
      "Accuracy (wide): 0.83\n",
      "Accuracy (wide): 0.79\n",
      "Accuracy (wide): 0.79\n",
      "Accuracy (wide): 0.79\n",
      "Accuracy (wide): 0.86\n",
      "Accuracy (deep): 0.79\n",
      "Accuracy (deep): 0.76\n",
      "Accuracy (deep): 0.97\n",
      "Accuracy (deep): 0.76\n",
      "Accuracy (deep): 0.93\n",
      "Wide: 81.38% (+/- 2.76%)\n",
      "Deep: 84.14% (+/- 8.89%)\n",
      "Retrain a deep model\n",
      "Final model accuracy: 85.71%\n",
      "[0.0209 0.0191 0.0411 0.0321 0.0698 0.1579 0.1438 0.1402 0.3048 0.3914\n",
      " 0.3504 0.3669 0.3943 0.3311 0.3331 0.3002 0.2324 0.1381 0.345  0.4428\n",
      " 0.489  0.3677 0.4379 0.4864 0.6207 0.7256 0.6624 0.7689 0.7981 0.8577\n",
      " 0.9273 0.7009 0.4851 0.3409 0.1406 0.1147 0.1433 0.182  0.3605 0.5529\n",
      " 0.5988 0.5077 0.5512 0.5027 0.7034 0.5904 0.4069 0.2761 0.1584 0.051\n",
      " 0.0054 0.0078 0.0201 0.0104 0.0039 0.0031 0.0062 0.0087 0.007  0.0042] -> [0.00065748] (expected [0.])\n",
      "[0.0228 0.0853 0.1    0.0428 0.1117 0.1651 0.1597 0.2116 0.3295 0.3517\n",
      " 0.333  0.3643 0.402  0.4731 0.5196 0.6573 0.8426 0.8476 0.8344 0.8453\n",
      " 0.7999 0.8537 0.9642 1.     0.9357 0.9409 0.907  0.7104 0.632  0.5667\n",
      " 0.3501 0.2447 0.1698 0.329  0.3674 0.2331 0.2413 0.2556 0.1892 0.194\n",
      " 0.3074 0.2785 0.0308 0.1238 0.1854 0.1753 0.1079 0.0728 0.0242 0.0191\n",
      " 0.0159 0.0172 0.0191 0.026  0.014  0.0125 0.0116 0.0093 0.0012 0.0036] -> [0.24708486] (expected [0.])\n",
      "[0.0181 0.0146 0.0026 0.0141 0.0421 0.0473 0.0361 0.0741 0.1398 0.1045\n",
      " 0.0904 0.0671 0.0997 0.1056 0.0346 0.1231 0.1626 0.3652 0.3262 0.2995\n",
      " 0.2109 0.2104 0.2085 0.2282 0.0747 0.1969 0.4086 0.6385 0.797  0.7508\n",
      " 0.5517 0.2214 0.4672 0.4479 0.2297 0.3235 0.448  0.5581 0.652  0.5354\n",
      " 0.2478 0.2268 0.1788 0.0898 0.0536 0.0374 0.099  0.0956 0.0317 0.0142\n",
      " 0.0076 0.0223 0.0255 0.0145 0.0233 0.0041 0.0018 0.0048 0.0089 0.0085] -> [0.95750135] (expected [1.])\n",
      "[0.0132 0.008  0.0188 0.0141 0.0436 0.0668 0.0609 0.0131 0.0899 0.0922\n",
      " 0.1445 0.1475 0.2087 0.2558 0.2603 0.1985 0.2394 0.3134 0.4077 0.4529\n",
      " 0.4893 0.5666 0.6234 0.6741 0.8282 0.8823 0.9196 0.8965 0.7549 0.6736\n",
      " 0.6463 0.5007 0.3663 0.2298 0.1362 0.2123 0.2395 0.2673 0.2865 0.206\n",
      " 0.1659 0.2633 0.2552 0.1696 0.1467 0.1286 0.0926 0.0716 0.0325 0.0258\n",
      " 0.0136 0.0044 0.0028 0.0021 0.0022 0.0048 0.0138 0.014  0.0028 0.0064] -> [0.6031275] (expected [1.])\n",
      "[0.01   0.0194 0.0155 0.0489 0.0839 0.1009 0.1627 0.2071 0.2696 0.299\n",
      " 0.3242 0.3565 0.3951 0.5201 0.6953 0.8468 1.     0.9278 0.851  0.801\n",
      " 0.8142 0.8825 0.7302 0.6107 0.7159 0.8458 0.6319 0.4808 0.6291 0.7152\n",
      " 0.6005 0.4235 0.4106 0.3992 0.173  0.1975 0.237  0.1339 0.1583 0.3151\n",
      " 0.1968 0.2054 0.1272 0.1129 0.1946 0.2195 0.193  0.1498 0.0773 0.0196\n",
      " 0.0122 0.013  0.0073 0.0077 0.0075 0.006  0.008  0.0019 0.0053 0.0019] -> [0.76774263] (expected [1.])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHFCAYAAAAOmtghAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABGo0lEQVR4nO3dd3xUVf7/8fekF0iQlhBKCGAoIoLJUsIighQBwbIsQZCOEoFFCGVF/NJEcBURUAELBPFLVYqs0qKggsBKCYqCLkoMLREDQpASUs7vD36Zr0MCZEKSIZfX8/GYx4M5c+69n3sSmDfnNpsxxggAAMAi3FxdAAAAQGEi3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3OCWs3DhQtlsNvvLw8NDlSpVUvfu3XXo0CFXlydJql69uvr27evqMnI5f/68XnrpJTVq1EilSpWSv7+/GjZsqKlTp+r8+fOuLi/fpk6dqjVr1uRq//zzz2Wz2fT5558Xe005Dh8+rKFDhyo8PFy+vr7y8/PTXXfdpeeff17Hjx+397v//vtVv359l9V5M5YsWaKZM2cW2foL8vdn+/btmjhxos6cOZPrs/vvv1/3339/odQGa7Dx+AXcahYuXKh+/fopLi5OderU0aVLl/TVV1/pxRdfVOnSpfXDDz/ojjvucGmNCQkJCggIUM2aNV1ax5/9+uuvatOmjX7++WcNGzZMDzzwgCRp8+bNmjVrlmrWrKlPP/1UQUFBLq70xkqVKqWuXbtq4cKFDu1paWk6cOCA6tWrp4CAgGKv6+OPP1b37t1Vvnx5DR06VI0aNZLNZtP+/fu1YMECubm5KSEhQdKVL9zU1FR99913xV7nzXrooYf03Xff6ZdffimS9Rfk78/06dM1evRoJSYmqnr16g6fHThwQJJUr169wiwTJZiHqwsArqV+/fqKjIyUdOWLIisrSxMmTNCaNWvUr18/l9bWqFGjYt9mVlaWMjMz5e3tnefnvXv31g8//KAtW7bor3/9q729bdu26tSpk1q1aqU+ffpow4YNxVWypBvX7YyAgAA1bdq0EKpyXmJiorp3767w8HBt2bJFgYGB9s9at26tYcOGafXq1cVakzFGly5dkq+vb7Fut6AuXrwoX1/fQv/7Q6jB1TgshRIjJ+j8+uuvDu27d+9Wly5dVLZsWfn4+KhRo0ZasWJFruWPHz+up556SlWrVpWXl5dCQkLUtWtXh/WlpaVp1KhRCgsLk5eXlypXrqzhw4fnOqTz52n13377TV5eXvqf//mfXNv84YcfZLPZNHv2bHtbSkqKBg0apCpVqsjLy0thYWGaNGmSMjMz7X1++eUX2Ww2vfzyy5oyZYrCwsLk7e2tLVu25Dk2u3fv1qZNmzRgwACHYJPjr3/9q/r376+NGzdqz5499nabzaahQ4fqrbfeUnh4uLy9vVWvXj0tW7Ys1zputu5Lly5p5MiRatiwoQIDA1W2bFk1a9ZMH330kcN2bDabzp8/r/fee89+aDLnkENeh6X69u2rUqVK6aefflLHjh1VqlQpVa1aVSNHjlR6errDuo8dO6auXbuqdOnSKlOmjHr27Kldu3bJZrPlmiW62owZM3T+/HnNmTPHIdj8ue7HHnssV/uuXbvUokUL+fn5qUaNGnrppZeUnZ1t/zy/45KzjaFDh2revHmqW7euvL299d5770mSJk2apCZNmqhs2bIKCAjQvffeq/nz5yuvyfklS5aoWbNmKlWqlEqVKqWGDRtq/vz5kq78R+KTTz5RUlKSw+HhHJcvX9aUKVNUp04deXt7q0KFCurXr59+++03h21Ur15dDz30kFatWqVGjRrJx8dHkyZNsn/258NS2dnZmjJlimrXri1fX1+VKVNGDRo00KxZsyRJEydO1OjRoyVJYWFh9ppyfg/yOiyVnp6uyZMnq27duvLx8VG5cuXUqlUrbd++3d7ngw8+UJMmTRQYGGj/+fTv3z/XeKHkYeYGJUZiYqIkKTw83N62ZcsWPfjgg2rSpInmzZunwMBALVu2TNHR0bpw4YL9H9Djx4/rL3/5izIyMvTcc8+pQYMGOnXqlDZu3Kjff/9dQUFBunDhglq2bKljx47Z+3z//fcaP3689u/fr08//dThH/kcFSpU0EMPPaT33ntPkyZNkpvb//2fIS4uTl5eXurZs6ekKwGhcePGcnNz0/jx41WzZk3t2LFDU6ZM0S+//KK4uDiHdc+ePVvh4eGaPn26AgICdOedd+Y5NvHx8ZKkRx555Jrj98gjj+jtt99WfHy8IiIi7O1r167Vli1bNHnyZPn7+2vOnDl6/PHH5eHhoa5duxZa3enp6Tp9+rRGjRqlypUr6/Lly/r000/12GOPKS4uTr1795Yk7dixQ61bt1arVq3sgfFGh6AyMjLUpUsXDRgwQCNHjtSXX36pF154QYGBgRo/frykK+cjtWrVSqdPn9a//vUv1apVSxs2bFB0dPR1151j06ZNCgoKcmrmKCUlRT179tTIkSM1YcIErV69WmPHjlVISIh9f/M7LjnWrFmjrVu3avz48QoODlbFihUlXQmWgwYNUrVq1SRJO3fu1D/+8Q8dP37cPgaSNH78eL3wwgt67LHHNHLkSAUGBuq7775TUlKSJGnOnDl66qmn9PPPP+eaicrOztbDDz+srVu3asyYMYqKilJSUpImTJig+++/X7t373aYRdq7d68OHjyo559/XmFhYfL3989znF5++WVNnDhRzz//vO677z5lZGTohx9+sJ9fM3DgQJ0+fVqvv/66Vq1apUqVKkm69oxNZmamOnTooK1bt2r48OFq3bq1MjMztXPnTh05ckRRUVHasWOHoqOjFR0drYkTJ8rHx0dJSUnavHlzvn62uMUZ4BYTFxdnJJmdO3eajIwMc+7cObNhwwYTHBxs7rvvPpORkWHvW6dOHdOoUSOHNmOMeeihh0ylSpVMVlaWMcaY/v37G09PT3PgwIFrbnfatGnGzc3N7Nq1y6H9ww8/NJLMunXr7G2hoaGmT58+9vdr1641ksymTZvsbZmZmSYkJMT87W9/s7cNGjTIlCpVyiQlJTlsY/r06UaS+f77740xxiQmJhpJpmbNmuby5cs3GjITExNjJJkffvjhmn0OHjxoJJmnn37a3ibJ+Pr6mpSUFIe669SpY2rVqlWkdWdmZpqMjAwzYMAA06hRI4fP/P39HcY3x5YtW4wks2XLFntbnz59jCSzYsUKh74dO3Y0tWvXtr9/8803jSSzfv16h36DBg0ykkxcXNx16/Xx8TFNmza9bp8/a9mypZFk/vOf/zi016tXz7Rv3/6ay11vXCSZwMBAc/r06etuOysry2RkZJjJkyebcuXKmezsbGOMMYcPHzbu7u6mZ8+e112+U6dOJjQ0NFf70qVLjSSzcuVKh/Zdu3YZSWbOnDn2ttDQUOPu7m5+/PHHXOu5+u/PQw89ZBo2bHjdml555RUjySQmJub6rGXLlqZly5b294sWLTKSzDvvvHPN9eX87p45c+a620XJxGEp3LKaNm0qT09PlS5dWg8++KDuuOMOffTRR/LwuDLh+NNPP+mHH36wz4pkZmbaXx07dlRycrJ+/PFHSdL69evVqlUr1a1b95rb+/jjj1W/fn01bNjQYV3t27e/4RU6HTp0UHBwsMMMxsaNG3XixAmHae6PP/5YrVq1UkhIiMM2OnToIEn64osvHNbbpUsXeXp6Ojdw12D+/+GJq2efHnjgAYeTjN3d3RUdHa2ffvpJx44dK9S6P/jgAzVv3lylSpWSh4eHPD09NX/+fB08ePCm9s1ms6lz584ObQ0aNLDPRuTUmPO79GePP/74TW37eoKDg9W4cePr1iU5Ny6tW7fO84T6zZs3q02bNgoMDJS7u7s8PT01fvx4nTp1SidPnpR0ZYYvKytLQ4YMKdD+fPzxxypTpow6d+7s8HvQsGFDBQcH5/o70qBBA4eZ1mtp3LixvvnmGw0ePFgbN25UWlpagerLsX79evn4+Fz3ENNf/vIXSVK3bt20YsUKhyvdUPIRbnDLWrRokXbt2qXNmzdr0KBBOnjwoMMXUc65MqNGjZKnp6fDa/DgwZKk1NRUSVfOi6lSpcp1t/frr7/q22+/zbWu0qVLyxhjX1dePDw81KtXL61evdo+lb5w4UJVqlRJ7du3d9jGv//971zbuOuuuxzqzZEz/X4jOYcicg7d5SXnypeqVas6tAcHB+fqm9N26tSpQqt71apV6tatmypXrqz//d//1Y4dO7Rr1y71799fly5dytd+Xoufn598fHwc2ry9vR3We+rUqTyvFMvv1WPVqlW77vjmpVy5crnavL29dfHiRft7Z8clr7H9+uuv1a5dO0nSO++8o6+++kq7du3SuHHjJMm+vZzzYm70d+Fafv31V505c0ZeXl65fhdSUlIK/Ps7duxYTZ8+XTt37lSHDh1Urlw5PfDAA9q9e3eB6vztt98UEhLicIj4avfdd5/WrFmjzMxM9e7dW1WqVFH9+vW1dOnSAm0TtxbOucEtq27duvaTiFu1aqWsrCy9++67+vDDD9W1a1eVL19e0pV/GPM6kVOSateuLenKeTE5sxDXUr58efn6+mrBggXX/Px6+vXrp1deecV+zs/atWs1fPhwubu7O6yjQYMGevHFF/NcR0hIiMP7vM7xyUvbtm313HPPac2aNblmJnLk3Dembdu2Du0pKSm5+ua05Xw5F0bd//u//6uwsDAtX77c4fOrT/otKuXKldPXX3+dqz2v/c9L+/bt9frrr2vnzp2FesWWs+OS19guW7ZMnp6e+vjjjx1C3tX3CqpQoYKkKydWXx1y86N8+fIqV67cNa+4K1269A1rzYuHh4diY2MVGxurM2fO6NNPP9Vzzz2n9u3b6+jRo/Lz83OqzgoVKmjbtm3Kzs6+bsB5+OGH9fDDDys9PV07d+7UtGnT1KNHD1WvXl3NmjVzapu4tRBuUGK8/PLLWrlypcaPH6/HHntMtWvX1p133qlvvvlGU6dOve6yHTp00Pvvv68ff/zRHniu9tBDD2nq1KkqV66cwsLCnK6vbt26atKkieLi4pSVlaX09PRcl6w/9NBDWrdunWrWrFmo9+qJjIxUu3btNH/+fPXq1UvNmzd3+Hzbtm1asGCBHnzwQYeTiSXps88+06+//mqfwcjKytLy5ctVs2ZN+//wC6Num80mLy8vhy+8lJSUPK8Kunp2ozC0bNlSK1as0Pr16+2H0yTleWVYXkaMGKEFCxZo8ODBuS4Fl64c9luzZo0effRRp+pyZlyutw4PDw+HIH3x4kW9//77Dv3atWsnd3d3zZ0797pf3tca/4ceekjLli1TVlaWmjRpku/6nFGmTBl17dpVx48f1/Dhw/XLL7+oXr169lsJ5Of3okOHDlq6dKkWLlyYr6ufvL291bJlS5UpU0YbN25UQkIC4aaEI9ygxLjjjjs0duxYjRkzRkuWLNETTzyht956Sx06dFD79u3Vt29fVa5cWadPn9bBgwe1d+9effDBB5KkyZMna/369brvvvv03HPP6e6779aZM2e0YcMGxcbGqk6dOho+fLhWrlyp++67TyNGjFCDBg2UnZ2tI0eOaNOmTRo5cuQN/0Hv37+/Bg0apBMnTigqKipXkJo8ebLi4+MVFRWlYcOGqXbt2rp06ZJ++eUXrVu3TvPmzSvwIYNFixapTZs2ateuXZ438atTp06elzuXL19erVu31v/8z//Yr5b64YcfHL70C6PunMuCBw8erK5du+ro0aN64YUXVKlSpVx3nr777rv1+eef69///rcqVaqk0qVLXzOU5lefPn302muv6YknntCUKVNUq1YtrV+/Xhs3bpSk6/4PX7pyCXLOrFzDhg3tN/GTrtxEbsGCBTLGOB1unBmXa+nUqZNmzJihHj166KmnntKpU6c0ffr0XPcWql69up577jm98MILunjxoh5//HEFBgbqwIEDSk1NtV+qfffdd2vVqlWaO3euIiIi5ObmpsjISHXv3l2LFy9Wx44d9cwzz6hx48by9PTUsWPHtGXLFj388MNO778kde7c2X5fqwoVKigpKUkzZ85UaGio/QrBu+++W5I0a9Ys9enTR56enqpdu3au2SLpynlUcXFxiomJ0Y8//qhWrVopOztb//nPf1S3bl11795d48eP17Fjx/TAAw+oSpUqOnPmjGbNmiVPT0+1bNnS6X3ALca15zMDueVcLXX1VUvGGHPx4kVTrVo1c+edd5rMzExjjDHffPON6datm6lYsaLx9PQ0wcHBpnXr1mbevHkOyx49etT079/fBAcHG09PTxMSEmK6detmfv31V3ufP/74wzz//POmdu3axsvLywQGBpq7777bjBgxwuGKoquv9shx9uxZ4+vre90rNX777TczbNgwExYWZjw9PU3ZsmVNRESEGTdunPnjjz+MMf931dErr7zi1Nj98ccfZurUqaZhw4bGz8/P+Pn5mQYNGpgpU6bY1/1nksyQIUPMnDlzTM2aNY2np6epU6eOWbx4cZHU/dJLL5nq1asbb29vU7duXfPOO++YCRMmmKv/Kdq3b59p3ry58fPzM5LsV8Jc62opf3//XNvKa71Hjhwxjz32mClVqpQpXbq0+dvf/mbWrVtnJJmPPvroumOb4+effzaDBw82tWrVMt7e3sbX19fUq1fPxMbGOlzJ07JlS3PXXXflWr5Pnz65rkTK77jk/LzysmDBAlO7dm3j7e1tatSoYaZNm2bmz5+f5xVGixYtMn/5y1+Mj4+PKVWqlGnUqJHD1WKnT582Xbt2NWXKlDE2m82hjoyMDDN9+nRzzz332JevU6eOGTRokDl06JC9X2hoqOnUqVOetV799+fVV181UVFRpnz58sbLy8tUq1bNDBgwwPzyyy8Oy40dO9aEhIQYNzc3h9+Dq6+WMubKvxXjx483d955p/Hy8jLlypUzrVu3Ntu3bzfGGPPxxx+bDh06mMqVKxsvLy9TsWJF07FjR7N169Y8a0bJwuMXgNuYzWbTkCFD9MYbb7i6FJeZOnWqnn/+eR05cqTAs2YAbi0clgJw28gJcXXq1FFGRoY2b96s2bNn64knniDYABZCuAFw2/Dz89Nrr72mX375Renp6apWrZr++c9/6vnnn3d1aQAKEYelAACApXATPwAAYCmEGwAAYCmEGwAAYCm33QnF2dnZOnHihEqXLp3vW4MDAADXMsbo3LlzN3xumHQbhpsTJ04U6JkqAADA9Y4ePXrDWzfcduEm51bdR48eVUBAgIurAQAA+ZGWlqaqVavm+ciNq9124SbnUFRAQADhBgCAEiY/p5RwQjEAALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUl4abL7/8Up07d1ZISIhsNpvWrFlzw2W++OILRUREyMfHRzVq1NC8efOKvlAAAFBiuDTcnD9/Xvfcc4/eeOONfPVPTExUx44d1aJFCyUkJOi5557TsGHDtHLlyiKuFAAAlBQufXBmhw4d1KFDh3z3nzdvnqpVq6aZM2dKkurWravdu3dr+vTp+tvf/lZEVQK43RljdDEjy9VlACWKr6d7vh5yWRRK1FPBd+zYoXbt2jm0tW/fXvPnz1dGRoY8PT1zLZOenq709HT7+7S0tCKvE4B1GGPUdd4O7Un63dWlACXKgcnt5eflmphRok4oTklJUVBQkENbUFCQMjMzlZqamucy06ZNU2BgoP1VtWrV4igVgEVczMgi2AAlTImauZGUa4rLGJNne46xY8cqNjbW/j4tLY2AA6BAdj/fRn5e7q4uAygRfD1d93elRIWb4OBgpaSkOLSdPHlSHh4eKleuXJ7LeHt7y9vbuzjKA2Bxfl7uLptmB5B/JeqwVLNmzRQfH+/QtmnTJkVGRuZ5vg0AALj9uDTc/PHHH9q3b5/27dsn6cql3vv27dORI0ckXTmk1Lt3b3v/mJgYJSUlKTY2VgcPHtSCBQs0f/58jRo1yhXlAwCAW5BL51d3796tVq1a2d/nnBvTp08fLVy4UMnJyfagI0lhYWFat26dRowYoTfffFMhISGaPXs2l4EDAAA7l4ab+++/335CcF4WLlyYq61ly5bau3dvEVYFAABKshJ1zg0AAMCNcNo/gAK7He7ce+GytfcPsCLCDYAC4c69AG5VHJYCUCC32517I0PvcOlNyQDkHzM3AG7a7XDnXlc+BBCAcwg3AG4ad+4FcCvhsBQAALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUrt0ELKK4H4XAYwkA3KoIN4AF8CgEAPg/HJYCLMCVj0LgsQQAbjXM3AAWU9yPQuCxBABuNYQbwGJ4FAKA2x2HpQAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKVwSQVQBLhbMAC4DuEGKGTcLRgAXIvDUkAh427BAOBazNwARYi7BQNA8SPcAEWIuwUDQPHjsBQAALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUwg0AALAUD1cXABQ1Y4wuZmQV2/YuXC6+bQEAciPcwNKMMeo6b4f2JP3u6lIAAMWEw1KwtIsZWS4LNpGhd8jX090l2waA2xkzN7ht7H6+jfy8ii9s+Hq6y2azFdv2AABXEG5w2/DzcpefF7/yAGB1HJYCAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWwnWxKBEK+ggFHoUAALcfwg1ueTxCAQDgDJcflpozZ47CwsLk4+OjiIgIbd269br9Fy9erHvuuUd+fn6qVKmS+vXrp1OnThVTtXCFwniEAo9CAIDbh0tnbpYvX67hw4drzpw5at68ud566y116NBBBw4cULVq1XL137Ztm3r37q3XXntNnTt31vHjxxUTE6OBAwdq9erVLtgDFLeCPkKBRyEAwO3DpTM3M2bM0IABAzRw4EDVrVtXM2fOVNWqVTV37tw8++/cuVPVq1fXsGHDFBYWpr/+9a8aNGiQdu/eXcyVw1VyHqHg7ItgAwC3D5eFm8uXL2vPnj1q166dQ3u7du20ffv2PJeJiorSsWPHtG7dOhlj9Ouvv+rDDz9Up06drrmd9PR0paWlObwAAIB1uSzcpKamKisrS0FBQQ7tQUFBSklJyXOZqKgoLV68WNHR0fLy8lJwcLDKlCmj119//ZrbmTZtmgIDA+2vqlWrFup+AACAW4vLTyi++nCBMeaahxAOHDigYcOGafz48dqzZ482bNigxMRExcTEXHP9Y8eO1dmzZ+2vo0ePFmr9AADg1uKyE4rLly8vd3f3XLM0J0+ezDWbk2PatGlq3ry5Ro8eLUlq0KCB/P391aJFC02ZMkWVKlXKtYy3t7e8vb0LfwcAAMAtyWUzN15eXoqIiFB8fLxDe3x8vKKiovJc5sKFC3JzcyzZ3f3KlTPGmKIpFAAAlCguvRQ8NjZWvXr1UmRkpJo1a6a3335bR44csR9mGjt2rI4fP65FixZJkjp37qwnn3xSc+fOVfv27ZWcnKzhw4ercePGCgkJceWuuExB79xbknCXYQCAM1wabqKjo3Xq1ClNnjxZycnJql+/vtatW6fQ0FBJUnJyso4cOWLv37dvX507d05vvPGGRo4cqTJlyqh169b617/+5apdcCnu3AsAQG42c5sdz0lLS1NgYKDOnj2rgIAAV5dzUy5czlS98RtdXUaxiQy9Qx/ENOOeNQBwG3Lm+5tnS1lEQe/cW5Jwl2EAQH4Qbiwi5869AADc7lx+nxsAAIDCRLgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWwrXDt4CCPkKBxxIAAJAb4cbFeIQCAACFi8NSLnYxI+umg01k6B3y9bT23YkBAMgvZm5uIQV9hAKPJQAA4P8Qbm4hPEIBAICbx2EpAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKQUKN5mZmfr000/11ltv6dy5c5KkEydO6I8//ijU4gAAAJzl4ewCSUlJevDBB3XkyBGlp6erbdu2Kl26tF5++WVdunRJ8+bNK4o6AQAA8sXpmZtnnnlGkZGR+v333+Xr62tvf/TRR/XZZ58VanEAAADOcnrmZtu2bfrqq6/k5eXl0B4aGqrjx48XWmEAAAAF4fTMTXZ2trKysnK1Hzt2TKVLly6UogAAAArK6XDTtm1bzZw50/7eZrPpjz/+0IQJE9SxY8fCrA0AAMBpTh+Weu2119SqVSvVq1dPly5dUo8ePXTo0CGVL19eS5cuLYoaAQAA8s3pcBMSEqJ9+/Zp2bJl2rNnj7KzszVgwAD17NnT4QRjAAAAV3A63Hz55ZeKiopSv3791K9fP3t7ZmamvvzyS913332FWiAAAIAznD7nplWrVjp9+nSu9rNnz6pVq1aFUhQAAEBBOR1ujDGy2Wy52k+dOiV/f/9CKQoAAKCg8n1Y6rHHHpN05eqovn37ytvb2/5ZVlaWvv32W0VFRRV+hQAAAE7Id7gJDAyUdGXmpnTp0g4nD3t5ealp06Z68sknC79CAAAAJ+Q73MTFxUmSqlevrlGjRnEICgAA3JKcvlpqwoQJRVEHAABAoXA63EjShx9+qBUrVujIkSO6fPmyw2d79+4tlMIAAAAKwumrpWbPnq1+/fqpYsWKSkhIUOPGjVWuXDkdPnxYHTp0KIoaAQAA8s3pcDNnzhy9/fbbeuONN+Tl5aUxY8YoPj5ew4YN09mzZ4uiRgAAgHxzOtwcOXLEfsm3r6+vzp07J0nq1asXz5YCAAAu53S4CQ4O1qlTpyRJoaGh2rlzpyQpMTFRxpjCrQ4AAMBJToeb1q1b69///rckacCAARoxYoTatm2r6OhoPfroo4VeIAAAgDOcvlrq7bffVnZ2tiQpJiZGZcuW1bZt29S5c2fFxMQUeoEAAADOcDrcuLm5yc3t/yZ8unXrpm7dukmSjh8/rsqVKxdedQAAAE5y+rBUXlJSUvSPf/xDtWrVcnrZOXPmKCwsTD4+PoqIiNDWrVuv2z89PV3jxo1TaGiovL29VbNmTS1YsKCgpQMAAIvJd7g5c+aMevbsqQoVKigkJESzZ89Wdna2xo8frxo1amjnzp1Oh4zly5dr+PDhGjdunBISEtSiRQt16NBBR44cueYy3bp102effab58+frxx9/1NKlS1WnTh2ntgsAAKzLZvJ5idPgwYP173//W9HR0dqwYYMOHjyo9u3b69KlS5owYYJatmzp9MabNGmie++9V3PnzrW31a1bV4888oimTZuWq/+GDRvUvXt3HT58WGXLlnV6e5KUlpamwMBAnT17VgEBAQVaR2G6cDlT9cZvlCQdmNxefl4Fumk0AACW5sz3d75nbj755BPFxcVp+vTpWrt2rYwxCg8P1+bNmwsUbC5fvqw9e/aoXbt2Du3t2rXT9u3b81xm7dq1ioyM1Msvv6zKlSsrPDxco0aN0sWLF6+5nfT0dKWlpTm8AACAdeV7muDEiROqV6+eJKlGjRry8fHRwIEDC7zh1NRUZWVlKSgoyKE9KChIKSkpeS5z+PBhbdu2TT4+Plq9erVSU1M1ePBgnT59+pqHxKZNm6ZJkyYVuE4AAFCy5HvmJjs7W56envb37u7u8vf3v+kCbDabw3tjTK62P9dgs9m0ePFiNW7cWB07dtSMGTO0cOHCa87ejB07VmfPnrW/jh49etM1AwCAW1e+Z26MMerbt6+8vb0lSZcuXVJMTEyugLNq1ap8ra98+fJyd3fPNUtz8uTJXLM5OSpVqqTKlSsrMDDQ3la3bl0ZY3Ts2DHdeeeduZbx9va21wwAAKwv3zM3ffr0UcWKFRUYGKjAwEA98cQTCgkJsb/PeeWXl5eXIiIiFB8f79AeHx9vf3bV1Zo3b64TJ07ojz/+sLf997//lZubm6pUqZLvbQMAAOvK98xNXFxcoW88NjZWvXr1UmRkpJo1a6a3335bR44csd/peOzYsTp+/LgWLVokSerRo4deeOEF9evXT5MmTVJqaqpGjx6t/v37y9fXt9DrAwAAJY9LrzuOjo7WqVOnNHnyZCUnJ6t+/fpat26dQkNDJUnJyckO97wpVaqU4uPj9Y9//EORkZEqV66cunXrpilTprhqFwAAwC0m3/e5sQrucwMAQMlTJPe5AQAAKAkINwAAwFIINwAAwFIKFG7ef/99NW/eXCEhIUpKSpIkzZw5Ux999FGhFgcAAOAsp8PN3LlzFRsbq44dO+rMmTPKysqSJJUpU0YzZ84s7PoAAACc4nS4ef311/XOO+9o3Lhxcnd3t7dHRkZq//79hVocAACAs5wON4mJiWrUqFGudm9vb50/f75QigIAACgop8NNWFiY9u3bl6t9/fr19qeGAwAAuIrTd4wbPXq0hgwZokuXLskYo6+//lpLly7VtGnT9O677xZFjQAAAPnmdLjp16+fMjMzNWbMGF24cEE9evRQ5cqVNWvWLHXv3r0oagQAAMi3At3r/8knn9STTz6p1NRUZWdnq2LFioVdFwAAQIE4fc7NpEmT9PPPP0uSypcvT7ABAAC3FKfDzcqVKxUeHq6mTZvqjTfe0G+//VYUdQEAABSI0+Hm22+/1bfffqvWrVtrxowZqly5sjp27KglS5bowoULRVEjAABAvhXo8Qt33XWXpk6dqsOHD2vLli0KCwvT8OHDFRwcXNj1AQAAOOWmH5zp7+8vX19feXl5KSMjozBqAgAAKLAChZvExES9+OKLqlevniIjI7V3715NnDhRKSkphV0fAACAU5y+FLxZs2b6+uuvdffdd6tfv372+9wAAADcCpwON61atdK7776ru+66qyjqAQAAuClOh5upU6cWRR0AAACFIl/hJjY2Vi+88IL8/f0VGxt73b4zZswolMIAAAAKIl/hJiEhwX4lVEJCQpEWBAAAcDPyFW62bNmS558BAABuNU5fCt6/f3+dO3cuV/v58+fVv3//QikKAACgoJwON++9954uXryYq/3ixYtatGhRoRQFAABQUPm+WiotLU3GGBljdO7cOfn4+Ng/y8rK0rp163hCOAAAcLl8h5syZcrIZrPJZrMpPDw81+c2m02TJk0q1OIAAACcle9ws2XLFhlj1Lp1a61cuVJly5a1f+bl5aXQ0FCFhIQUSZEAAAD5le9w07JlS0lXnitVrVo12Wy2IisKAACgoPIVbr799lvVr19fbm5uOnv2rPbv33/Nvg0aNCi04gAAAJyVr3DTsGFDpaSkqGLFimrYsKFsNpuMMbn62Ww2ZWVlFXqRAAAA+ZWvcJOYmKgKFSrY/wwAAHCryle4CQ0NzfPPAAAAt5oC3cTvk08+sb8fM2aMypQpo6ioKCUlJRVqcQAAAM5yOtxMnTpVvr6+kqQdO3bojTfe0Msvv6zy5ctrxIgRhV4gAACAM/J9KXiOo0ePqlatWpKkNWvWqGvXrnrqqafUvHlz3X///YVdHwAAgFOcnrkpVaqUTp06JUnatGmT2rRpI0ny8fHJ85lTAAAAxcnpmZu2bdtq4MCBatSokf773/+qU6dOkqTvv/9e1atXL+z6AAAAnOL0zM2bb76pZs2a6bffftPKlStVrlw5SdKePXv0+OOPF3qBAAAAznB65qZMmTJ64403crXz0EwAAHArcDrcSNKZM2c0f/58HTx4UDabTXXr1tWAAQMUGBhY2PUBAAA4xenDUrt371bNmjX12muv6fTp00pNTdVrr72mmjVrau/evUVRIwAAQL45PXMzYsQIdenSRe+88448PK4snpmZqYEDB2r48OH68ssvC71IAACA/HI63Ozevdsh2EiSh4eHxowZo8jIyEItDgAAwFlOH5YKCAjQkSNHcrUfPXpUpUuXLpSiAAAACsrpcBMdHa0BAwZo+fLlOnr0qI4dO6Zly5Zp4MCBXAoOAABczunDUtOnT5fNZlPv3r2VmZkpSfL09NTTTz+tl156qdALBAAAcIbT4cbLy0uzZs3StGnT9PPPP8sYo1q1asnPz68o6gMAAHBKvg9LXbhwQUOGDFHlypVVsWJFDRw4UJUqVVKDBg0INgAA4JaR73AzYcIELVy4UJ06dVL37t0VHx+vp59+uihrAwAAcFq+D0utWrVK8+fPV/fu3SVJTzzxhJo3b66srCy5u7sXWYEAAADOyPfMzdGjR9WiRQv7+8aNG8vDw0MnTpwoksIAAAAKIt/hJisrS15eXg5tHh4e9iumAAAAbgX5PixljFHfvn3l7e1tb7t06ZJiYmLk7+9vb1u1alXhVggAAOCEfIebPn365Gp74oknCrUYAACAm5XvcBMXF1eUdQAAABQKpx+/UNjmzJmjsLAw+fj4KCIiQlu3bs3Xcl999ZU8PDzUsGHDoi0QAACUKC4NN8uXL9fw4cM1btw4JSQkqEWLFurQoUOeD+b8s7Nnz6p379564IEHiqlSAABQUrg03MyYMUMDBgzQwIEDVbduXc2cOVNVq1bV3Llzr7vcoEGD1KNHDzVr1qyYKgUAACWFy8LN5cuXtWfPHrVr186hvV27dtq+ffs1l4uLi9PPP/+sCRMmFHWJAACgBHL6wZmFJTU1VVlZWQoKCnJoDwoKUkpKSp7LHDp0SM8++6y2bt0qD4/8lZ6enq709HT7+7S0tIIXDQAAbnkFmrl5//331bx5c4WEhCgpKUmSNHPmTH300UdOr8tmszm8N8bkapOu3ESwR48emjRpksLDw/O9/mnTpikwMND+qlq1qtM1AgCAksPpcDN37lzFxsaqY8eOOnPmjLKysiRJZcqU0cyZM/O9nvLly8vd3T3XLM3JkydzzeZI0rlz57R7924NHTpUHh4e8vDw0OTJk/XNN9/Iw8NDmzdvznM7Y8eO1dmzZ+2vo0eP5n9nAQBAieN0uHn99df1zjvvaNy4cQ4PzIyMjNT+/fvzvR4vLy9FREQoPj7eoT0+Pl5RUVG5+gcEBGj//v3at2+f/RUTE6PatWtr3759atKkSZ7b8fb2VkBAgMMLAABYl9Pn3CQmJqpRo0a52r29vXX+/Hmn1hUbG6tevXopMjJSzZo109tvv60jR44oJiZG0pVZl+PHj2vRokVyc3NT/fr1HZavWLGifHx8crUDAIDbl9PhJiwsTPv27VNoaKhD+/r161WvXj2n1hUdHa1Tp05p8uTJSk5OVv369bVu3Tr7upOTk294zxsAAIA/czrcjB49WkOGDNGlS5dkjNHXX3+tpUuXatq0aXr33XedLmDw4MEaPHhwnp8tXLjwustOnDhREydOdHqbAADAupwON/369VNmZqbGjBmjCxcuqEePHqpcubJmzZql7t27F0WNAAAA+Vag+9w8+eSTevLJJ5Wamqrs7GxVrFixsOsCAAAokJu6iV/58uULqw4AAIBCUaATivO6yV6Ow4cP31RBAAAAN8PpcDN8+HCH9xkZGUpISNCGDRs0evTowqoLAACgQJwON88880ye7W+++aZ279590wUBAADcjEJ7KniHDh20cuXKwlodAABAgRRauPnwww9VtmzZwlodAABAgTh9WKpRo0YOJxQbY5SSkqLffvtNc+bMKdTiAAAAnOV0uHnkkUcc3ru5ualChQq6//77VadOncKqCwAAoECcCjeZmZmqXr262rdvr+Dg4KKqCQAAoMCcOufGw8NDTz/9tNLT04uqHgAAgJvi9AnFTZo0UUJCQlHUAgAAcNOcPudm8ODBGjlypI4dO6aIiAj5+/s7fN6gQYNCKw4AAMBZ+Q43/fv318yZMxUdHS1JGjZsmP0zm80mY4xsNpuysrIKv0oAAIB8yne4ee+99/TSSy8pMTGxKOsBAAC4KfkON8YYSVJoaGiRFQMAAHCznDqh+HpPAwcAALgVOHVCcXh4+A0DzunTp2+qIAAAgJvhVLiZNGmSAgMDi6oWAACAm+ZUuOnevbsqVqxYVLUAAADctHyHG863uTFjjC5mOHcp/IXLXDoPAEBhcvpqKeTNGKOu83ZoT9Lvri4FAIDbWr7DTXZ2dlHWUeJdzMi6qWATGXqHfD3dC7EiAABuT04/fgE3tvv5NvLzci6o+Hq6c+gPAIBCQLgpAn5e7vLzYmgBAHAFp58KDgAAcCsj3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEtxebiZM2eOwsLC5OPjo4iICG3duvWafVetWqW2bduqQoUKCggIULNmzbRx48ZirBYAANzqXBpuli9fruHDh2vcuHFKSEhQixYt1KFDBx05ciTP/l9++aXatm2rdevWac+ePWrVqpU6d+6shISEYq4cAADcqmzGGOOqjTdp0kT33nuv5s6da2+rW7euHnnkEU2bNi1f67jrrrsUHR2t8ePH56t/WlqaAgMDdfbsWQUEBBSo7rxcuJypeuOvzCIdmNxefl4ehbZuAABud858f7ts5uby5cvas2eP2rVr59Derl07bd++PV/ryM7O1rlz51S2bNmiKBEAAJRALpteSE1NVVZWloKCghzag4KClJKSkq91vPrqqzp//ry6det2zT7p6elKT0+3v09LSytYwQAAoERw+QnFNpvN4b0xJldbXpYuXaqJEydq+fLlqlix4jX7TZs2TYGBgfZX1apVb7pmAABw63JZuClfvrzc3d1zzdKcPHky12zO1ZYvX64BAwZoxYoVatOmzXX7jh07VmfPnrW/jh49etO1AwCAW5fLwo2Xl5ciIiIUHx/v0B4fH6+oqKhrLrd06VL17dtXS5YsUadOnW64HW9vbwUEBDi8AACAdbn0kp7Y2Fj16tVLkZGRatasmd5++20dOXJEMTExkq7Muhw/flyLFi2SdCXY9O7dW7NmzVLTpk3tsz6+vr4KDAx02X4AAIBbh0vDTXR0tE6dOqXJkycrOTlZ9evX17p16xQaGipJSk5OdrjnzVtvvaXMzEwNGTJEQ4YMsbf36dNHCxcuLO7yAQDALcil97lxBe5zAwBAyVMi7nMDAABQFAg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUlwebubMmaOwsDD5+PgoIiJCW7duvW7/L774QhEREfLx8VGNGjU0b968YqoUAACUBC4NN8uXL9fw4cM1btw4JSQkqEWLFurQoYOOHDmSZ//ExER17NhRLVq0UEJCgp577jkNGzZMK1euLObKAQDArcpmjDGu2niTJk107733au7cufa2unXr6pFHHtG0adNy9f/nP/+ptWvX6uDBg/a2mJgYffPNN9qxY0e+tpmWlqbAwECdPXtWAQEBN78T/9+Fy5mqN36jJOnA5Pby8/IotHUDAHC7c+b722UzN5cvX9aePXvUrl07h/Z27dpp+/bteS6zY8eOXP3bt2+v3bt3KyMjI89l0tPTlZaW5vACAADW5bJwk5qaqqysLAUFBTm0BwUFKSUlJc9lUlJS8uyfmZmp1NTUPJeZNm2aAgMD7a+qVasWzg4AAIBbkstPKLbZbA7vjTG52m7UP6/2HGPHjtXZs2ftr6NHj95kxXnz9XTXgcntdWBye/l6uhfJNgAAwI257MSQ8uXLy93dPdcszcmTJ3PNzuQIDg7Os7+Hh4fKlSuX5zLe3t7y9vYunKKvw2azcZ4NAAC3AJfN3Hh5eSkiIkLx8fEO7fHx8YqKispzmWbNmuXqv2nTJkVGRsrT07PIagUAACWHSw9LxcbG6t1339WCBQt08OBBjRgxQkeOHFFMTIykK4eUevfube8fExOjpKQkxcbG6uDBg1qwYIHmz5+vUaNGuWoXAADALcalx1Gio6N16tQpTZ48WcnJyapfv77WrVun0NBQSVJycrLDPW/CwsK0bt06jRgxQm+++aZCQkI0e/Zs/e1vf3PVLgAAgFuMS+9z4wpFdZ8bAABQdErEfW4AAACKAuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYym33GOucGzKnpaW5uBIAAJBfOd/b+Xmwwm0Xbs6dOydJqlq1qosrAQAAzjp37pwCAwOv2+e2e7ZUdna2Tpw4odKlS8tmsxXqutPS0lS1alUdPXqU51YVIca5eDDOxYNxLj6MdfEoqnE2xujcuXMKCQmRm9v1z6q57WZu3NzcVKVKlSLdRkBAAH9xigHjXDwY5+LBOBcfxrp4FMU432jGJgcnFAMAAEsh3AAAAEsh3BQib29vTZgwQd7e3q4uxdIY5+LBOBcPxrn4MNbF41YY59vuhGIAAGBtzNwAAABLIdwAAABLIdwAAABLIdwAAABLIdw4ac6cOQoLC5OPj48iIiK0devW6/b/4osvFBERIR8fH9WoUUPz5s0rpkpLNmfGedWqVWrbtq0qVKiggIAANWvWTBs3bizGaksuZ3+fc3z11Vfy8PBQw4YNi7ZAi3B2nNPT0zVu3DiFhobK29tbNWvW1IIFC4qp2pLL2XFevHix7rnnHvn5+alSpUrq16+fTp06VUzVlkxffvmlOnfurJCQENlsNq1Zs+aGy7jke9Ag35YtW2Y8PT3NO++8Yw4cOGCeeeYZ4+/vb5KSkvLsf/jwYePn52eeeeYZc+DAAfPOO+8YT09P8+GHHxZz5SWLs+P8zDPPmH/961/m66+/Nv/973/N2LFjjaenp9m7d28xV16yODvOOc6cOWNq1Khh2rVrZ+65557iKbYEK8g4d+nSxTRp0sTEx8ebxMRE85///Md89dVXxVh1yePsOG/dutW4ubmZWbNmmcOHD5utW7eau+66yzzyyCPFXHnJsm7dOjNu3DizcuVKI8msXr36uv1d9T1IuHFC48aNTUxMjENbnTp1zLPPPptn/zFjxpg6deo4tA0aNMg0bdq0yGq0AmfHOS/16tUzkyZNKuzSLKWg4xwdHW2ef/55M2HCBMJNPjg7zuvXrzeBgYHm1KlTxVGeZTg7zq+88oqpUaOGQ9vs2bNNlSpViqxGq8lPuHHV9yCHpfLp8uXL2rNnj9q1a+fQ3q5dO23fvj3PZXbs2JGrf/v27bV7925lZGQUWa0lWUHG+WrZ2dk6d+6cypYtWxQlWkJBxzkuLk4///yzJkyYUNQlWkJBxnnt2rWKjIzUyy+/rMqVKys8PFyjRo3SxYsXi6PkEqkg4xwVFaVjx45p3bp1Msbo119/1YcffqhOnToVR8m3DVd9D952D84sqNTUVGVlZSkoKMihPSgoSCkpKXkuk5KSkmf/zMxMpaamqlKlSkVWb0lVkHG+2quvvqrz58+rW7duRVGiJRRknA8dOqRnn31WW7dulYcH/3TkR0HG+fDhw9q2bZt8fHy0evVqpaamavDgwTp9+jTn3VxDQcY5KipKixcvVnR0tC5duqTMzEx16dJFr7/+enGUfNtw1fcgMzdOstlsDu+NMbnabtQ/r3Y4cnaccyxdulQTJ07U8uXLVbFixaIqzzLyO85ZWVnq0aOHJk2apPDw8OIqzzKc+X3Ozs6WzWbT4sWL1bhxY3Xs2FEzZszQwoULmb25AWfG+cCBAxo2bJjGjx+vPXv2aMOGDUpMTFRMTExxlHpbccX3IP/9yqfy5cvL3d091/8CTp48mSuV5ggODs6zv4eHh8qVK1dktZZkBRnnHMuXL9eAAQP0wQcfqE2bNkVZZonn7DifO3dOu3fvVkJCgoYOHSrpypewMUYeHh7atGmTWrduXSy1lyQF+X2uVKmSKleurMDAQHtb3bp1ZYzRsWPHdOeddxZpzSVRQcZ52rRpat68uUaPHi1JatCggfz9/dWiRQtNmTKFmfVC4qrvQWZu8snLy0sRERGKj493aI+Pj1dUVFSeyzRr1ixX/02bNikyMlKenp5FVmtJVpBxlq7M2PTt21dLlizhmHk+ODvOAQEB2r9/v/bt22d/xcTEqHbt2tq3b5+aNGlSXKWXKAX5fW7evLlOnDihP/74w9723//+V25ubqpSpUqR1ltSFWScL1y4IDc3x69Ad3d3Sf83s4Cb57LvwSI9Xdlici41nD9/vjlw4IAZPny48ff3N7/88osxxphnn33W9OrVy94/5xK4ESNGmAMHDpj58+dzKXg+ODvOS5YsMR4eHubNN980ycnJ9teZM2dctQslgrPjfDWulsofZ8f53LlzpkqVKqZr167m+++/N1988YW58847zcCBA121CyWCs+McFxdnPDw8zJw5c8zPP/9stm3bZiIjI03jxo1dtQslwrlz50xCQoJJSEgwksyMGTNMQkKC/ZL7W+V7kHDjpDfffNOEhoYaLy8vc++995ovvvjC/lmfPn1My5YtHfp//vnnplGjRsbLy8tUr17dzJ07t5grLpmcGeeWLVsaSbleffr0Kf7CSxhnf5//jHCTf86O88GDB02bNm2Mr6+vqVKliomNjTUXLlwo5qpLHmfHefbs2aZevXrG19fXVKpUyfTs2dMcO3asmKsuWbZs2XLdf29vle9BmzHMvwEAAOvgnBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsADhYuXKgyZcq4uowCq169umbOnHndPhMnTlTDhg2LpR4AxY9wA1hQ3759ZbPZcr1++uknV5emhQsXOtRUqVIldevWTYmJiYWy/l27dumpp56yv7fZbFqzZo1Dn1GjRumzzz4rlO1dy9X7GRQUpM6dO+v77793ej0lOWwCrkC4ASzqwQcfVHJyssMrLCzM1WVJuvIgzuTkZJ04cUJLlizRvn371KVLF2VlZd30uitUqCA/P7/r9ilVqlSRPpE4x5/385NPPtH58+fVqVMnXb58uci3DdzOCDeARXl7eys4ONjh5e7urhkzZujuu++Wv7+/qlatqsGDBzs8gfpq33zzjVq1aqXSpUsrICBAERER2r17t/3z7du367777pOvr6+qVq2qYcOG6fz589etzWazKTg4WJUqVVKrVq00YcIEfffdd/aZpblz56pmzZry8vJS7dq19f777zssP3HiRFWrVk3e3t4KCQnRsGHD7J/9+bBU9erVJUmPPvqobDab/f2fD0tt3LhRPj4+OnPmjMM2hg0bppYtWxbafkZGRmrEiBFKSkrSjz/+aO9zvZ/H559/rn79+uns2bP2GaCJEydKki5fvqwxY8aocuXK8vf3V5MmTfT5559ftx7gdkG4AW4zbm5umj17tr777ju999572rx5s8aMGXPN/j179lSVKlW0a9cu7dmzR88++6w8PT0lSfv371f79u312GOP6dtvv9Xy5cu1bds2DR061KmafH19JUkZGRlavXq1nnnmGY0cOVLfffedBg0apH79+mnLli2SpA8//FCvvfaa3nrrLR06dEhr1qzR3Xffned6d+3aJUmKi4tTcnKy/f2ftWnTRmXKlNHKlSvtbVlZWVqxYoV69uxZaPt55swZLVmyRJLs4ydd/+cRFRWlmTNn2meAkpOTNWrUKElSv3799NVXX2nZsmX69ttv9fe//10PPvigDh06lO+aAMsq8kdzAih2ffr0Me7u7sbf39/+6tq1a559V6xYYcqVK2d/HxcXZwIDA+3vS5cubRYuXJjnsr169TJPPfWUQ9vWrVuNm5ubuXjxYp7LXL3+o0ePmqZNm5oqVaqY9PR0ExUVZZ588kmHZf7+97+bjh07GmOMefXVV014eLi5fPlynusPDQ01r732mv29JLN69WqHPlc/0XzYsGGmdevW9vcbN240Xl5e5vTp0ze1n5KMv7+/8fPzsz89uUuXLnn2z3Gjn4cxxvz000/GZrOZ48ePO7Q/8MADZuzYsdddP3A78HBttAJQVFq1aqW5c+fa3/v7+0uStmzZoqlTp+rAgQNKS0tTZmamLl26pPPnz9v7/FlsbKwGDhyo999/X23atNHf//531axZU5K0Z88e/fTTT1q8eLG9vzFG2dnZSkxMVN26dfOs7ezZsypVqpSMMbpw4YLuvfderVq1Sl5eXjp48KDDCcGS1Lx5c82aNUuS9Pe//10zZ85UjRo19OCDD6pjx47q3LmzPDwK/s9Zz5491axZM504cUIhISFavHixOnbsqDvuuOOm9rN06dLau3evMjMz9cUXX+iVV17RvHnzHPo4+/OQpL1798oYo/DwcIf29PT0YjmXCLjVEW4Ai/L391etWrUc2pKSktSxY0fFxMTohRdeUNmyZbVt2zYNGDBAGRkZea5n4sSJ6tGjhz755BOtX79eEyZM0LJly/Too48qOztbgwYNcjjnJUe1atWuWVvOl76bm5uCgoJyfYnbbDaH98YYe1vVqlX1448/Kj4+Xp9++qkGDx6sV155RV988YXD4R5nNG7cWDVr1tSyZcv09NNPa/Xq1YqLi7N/XtD9dHNzs/8M6tSpo5SUFEVHR+vLL7+UVLCfR0497u7u2rNnj9zd3R0+K1WqlFP7DlgR4Qa4jezevVuZmZl69dVX5eZ25ZS7FStW3HC58PBwhYeHa8SIEXr88ccVFxenRx99VPfee6++//77XCHqRv78pX+1unXratu2berdu7e9bfv27Q6zI76+vurSpYu6dOmiIUOGqE6dOtq/f7/uvffeXOvz9PTM11VYPXr00OLFi1WlShW5ubmpU6dO9s8Kup9XGzFihGbMmKHVq1fr0UcfzdfPw8vLK1f9jRo1UlZWlk6ePKkWLVrcVE2AFXFCMXAbqVmzpjIzM/X666/r8OHDev/993MdJvmzixcvaujQofr888+VlJSkr776Srt27bIHjX/+85/asWOHhgwZon379unQoUNau3at/vGPfxS4xtGjR2vhwoWaN2+eDh06pBkzZmjVqlX2E2kXLlyo+fPn67vvvrPvg6+vr0JDQ/NcX/Xq1fXZZ58pJSVFv//++zW327NnT+3du1cvvviiunbtKh8fH/tnhbWfAQEBGjhwoCZMmCBjTL5+HtWrV9cff/yhzz77TKmpqbpw4YLCw8PVs2dP9e7dW6tWrVJiYqJ27dqlf/3rX1q3bp1TNQGW5MoTfgAUjT59+piHH344z89mzJhhKlWqZHx9fU379u3NokWLjCTz+++/G2McT2BNT0833bt3N1WrVjVeXl4mJCTEDB061OEk2q+//tq0bdvWlCpVyvj7+5sGDRqYF1988Zq15XWC7NXmzJljatSoYTw9PU14eLhZtGiR/bPVq1ebJk2amICAAOPv72+aNm1qPv30U/vnV59QvHbtWlOrVi3j4eFhQkNDjTG5TyjO8Ze//MVIMps3b871WWHtZ1JSkvHw8DDLly83xtz452GMMTExMaZcuXJGkpkwYYIxxpjLly+b8ePHm+rVqxtPT08THBxsHn30UfPtt99esybgdmEzxhjXxisAAIDCw2EpAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKf8PmH3qshtPAVwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Read data\n",
    "data = pd.read_csv(\"sonar.csv\", header=None)\n",
    "X = data.iloc[:, 0:60]\n",
    "y = data.iloc[:, 60]\n",
    "\n",
    "# Binary encoding of labels\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y)\n",
    "\n",
    "# Convert to 2D PyTorch tensors\n",
    "X = torch.tensor(X.values, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "# Define two models\n",
    "class Wide(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(60, 180)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output = nn.Linear(180, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.hidden(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x\n",
    "\n",
    "class Deep(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(60, 60)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(60, 60)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.layer3 = nn.Linear(60, 60)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.output = nn.Linear(60, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.layer1(x))\n",
    "        x = self.act2(self.layer2(x))\n",
    "        x = self.act3(self.layer3(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x\n",
    "\n",
    "# Compare model sizes\n",
    "model1 = Wide()\n",
    "model2 = Deep()\n",
    "print(sum([x.reshape(-1).shape[0] for x in model1.parameters()]))  # 11161\n",
    "print(sum([x.reshape(-1).shape[0] for x in model2.parameters()]))  # 11041\n",
    "\n",
    "# Helper function to train one model\n",
    "def model_train(model, X_train, y_train, X_val, y_val):\n",
    "    # loss function and optimizer\n",
    "    loss_fn = nn.BCELoss()  # binary cross entropy\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "    n_epochs = 300   # number of epochs to run\n",
    "    batch_size = 10  # size of each batch\n",
    "    batch_start = torch.arange(0, len(X_train), batch_size)\n",
    "\n",
    "    # Hold the best model\n",
    "    best_acc = - np.inf   # init to negative infinity\n",
    "    best_weights = None\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "            bar.set_description(f\"Epoch {epoch}\")\n",
    "            for start in bar:\n",
    "                # take a batch\n",
    "                X_batch = X_train[start:start+batch_size]\n",
    "                y_batch = y_train[start:start+batch_size]\n",
    "                # forward pass\n",
    "                y_pred = model(X_batch)\n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "                # backward pass\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                # update weights\n",
    "                optimizer.step()\n",
    "                # print progress\n",
    "                acc = (y_pred.round() == y_batch).float().mean()\n",
    "                bar.set_postfix(\n",
    "                    loss=float(loss),\n",
    "                    acc=float(acc)\n",
    "                )\n",
    "        # evaluate accuracy at end of each epoch\n",
    "        model.eval()\n",
    "        y_pred = model(X_val)\n",
    "        acc = (y_pred.round() == y_val).float().mean()\n",
    "        acc = float(acc)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "    # restore model and return best accuracy\n",
    "    model.load_state_dict(best_weights)\n",
    "    return best_acc\n",
    "\n",
    "# train-test split: Hold out the test set for final model evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
    "\n",
    "# define 5-fold cross validation test harness\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "cv_scores_wide = []\n",
    "for train, test in kfold.split(X_train, y_train):\n",
    "    # create model, train, and get accuracy\n",
    "    model = Wide()\n",
    "    acc = model_train(model, X_train[train], y_train[train], X_train[test], y_train[test])\n",
    "    print(\"Accuracy (wide): %.2f\" % acc)\n",
    "    cv_scores_wide.append(acc)\n",
    "cv_scores_deep = []\n",
    "for train, test in kfold.split(X_train, y_train):\n",
    "    # create model, train, and get accuracy\n",
    "    model = Deep()\n",
    "    acc = model_train(model, X_train[train], y_train[train], X_train[test], y_train[test])\n",
    "    print(\"Accuracy (deep): %.2f\" % acc)\n",
    "    cv_scores_deep.append(acc)\n",
    "\n",
    "# evaluate the model\n",
    "wide_acc = np.mean(cv_scores_wide)\n",
    "wide_std = np.std(cv_scores_wide)\n",
    "deep_acc = np.mean(cv_scores_deep)\n",
    "deep_std = np.std(cv_scores_deep)\n",
    "print(\"Wide: %.2f%% (+/- %.2f%%)\" % (wide_acc*100, wide_std*100))\n",
    "print(\"Deep: %.2f%% (+/- %.2f%%)\" % (deep_acc*100, deep_std*100))\n",
    "\n",
    "# rebuild model with full set of training data\n",
    "if wide_acc > deep_acc:\n",
    "    print(\"Retrain a wide model\")\n",
    "    model = Wide()\n",
    "else:\n",
    "    print(\"Retrain a deep model\")\n",
    "    model = Deep()\n",
    "acc = model_train(model, X_train, y_train, X_test, y_test)\n",
    "print(f\"Final model accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Test out inference with 5 samples\n",
    "    for i in range(5):\n",
    "        y_pred = model(X_test[i:i+1])\n",
    "        print(f\"{X_test[i].numpy()} -> {y_pred[0].numpy()} \" +\n",
    "              f\"(expected {y_test[i].numpy()})\")\n",
    "\n",
    "    # Plot the ROC curve\n",
    "    y_pred = model(X_test)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "    plt.plot(fpr, tpr) # ROC curve = TPR vs FPR\n",
    "    plt.title(\"Receiver Operating Characteristics\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
