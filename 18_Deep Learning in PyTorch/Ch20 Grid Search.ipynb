{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29c42353-d1a2-48be-8816-6a295799bfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from skorch import NeuralNetClassifier\n",
    "\n",
    "class SonarClassifier(nn.Module):\n",
    "    def __init__(self, n_layers=3):\n",
    "        super().__init__()\n",
    "        self.layers = []\n",
    "        self.acts = []\n",
    "        for i in range(n_layers):\n",
    "            self.layers.append(nn.Linear(60, 60))\n",
    "            self.acts.append(nn.ReLU())\n",
    "            self.add_module(f\"layer{i}\", self.layers[-1])\n",
    "            self.add_module(f\"act{i}\", self.acts[-1])\n",
    "        self.output = nn.Linear(60, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer, act in zip(self.layers, self.acts):\n",
    "            x = act(layer(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "model = NeuralNetClassifier(\n",
    "    module=SonarClassifier,\n",
    "    max_epochs=150,\n",
    "    batch_size=10,\n",
    "    module__n_layers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee5fa85d-6aea-4c4e-939f-7c311ae2bd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
      "  module_=SonarClassifier(\n",
      "    (layer0): Linear(in_features=60, out_features=60, bias=True)\n",
      "    (act0): ReLU()\n",
      "    (layer1): Linear(in_features=60, out_features=60, bias=True)\n",
      "    (act1): ReLU()\n",
      "    (output): Linear(in_features=60, out_features=1, bias=True)\n",
      "  ),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from skorch import NeuralNetClassifier\n",
    "\n",
    "class SonarClassifier(nn.Module):\n",
    "    def __init__(self, n_layers=3):\n",
    "        super().__init__()\n",
    "        self.layers = []\n",
    "        self.acts = []\n",
    "        for i in range(n_layers):\n",
    "            self.layers.append(nn.Linear(60, 60))\n",
    "            self.acts.append(nn.ReLU())\n",
    "            self.add_module(f\"layer{i}\", self.layers[-1])\n",
    "            self.add_module(f\"act{i}\", self.acts[-1])\n",
    "        self.output = nn.Linear(60, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer, act in zip(self.layers, self.acts):\n",
    "            x = act(layer(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "model = NeuralNetClassifier(\n",
    "    module=SonarClassifier,\n",
    "    max_epochs=150,\n",
    "    batch_size=10,\n",
    "    module__n_layers=2\n",
    ")\n",
    "print(model.initialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3de32858-3396-46f1-b80b-77185b06a4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.714844 using {'batch_size': 20, 'max_epochs': 100}\n",
      "0.638021 (0.024360) with: {'batch_size': 10, 'max_epochs': 10}\n",
      "0.690104 (0.023073) with: {'batch_size': 10, 'max_epochs': 50}\n",
      "0.709635 (0.017566) with: {'batch_size': 10, 'max_epochs': 100}\n",
      "0.662760 (0.026557) with: {'batch_size': 20, 'max_epochs': 10}\n",
      "0.710938 (0.024910) with: {'batch_size': 20, 'max_epochs': 50}\n",
      "0.714844 (0.019918) with: {'batch_size': 20, 'max_epochs': 100}\n",
      "0.677083 (0.019225) with: {'batch_size': 40, 'max_epochs': 10}\n",
      "0.694010 (0.018136) with: {'batch_size': 40, 'max_epochs': 50}\n",
      "0.684896 (0.024774) with: {'batch_size': 40, 'max_epochs': 100}\n",
      "0.664062 (0.008438) with: {'batch_size': 60, 'max_epochs': 10}\n",
      "0.680990 (0.032578) with: {'batch_size': 60, 'max_epochs': 50}\n",
      "0.697917 (0.021236) with: {'batch_size': 60, 'max_epochs': 100}\n",
      "0.664062 (0.012758) with: {'batch_size': 80, 'max_epochs': 10}\n",
      "0.678385 (0.009744) with: {'batch_size': 80, 'max_epochs': 50}\n",
      "0.690104 (0.034104) with: {'batch_size': 80, 'max_epochs': 100}\n",
      "0.658854 (0.023073) with: {'batch_size': 100, 'max_epochs': 10}\n",
      "0.666667 (0.030978) with: {'batch_size': 100, 'max_epochs': 50}\n",
      "0.687500 (0.006379) with: {'batch_size': 100, 'max_epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from skorch import NeuralNetClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# load the dataset, split into input (X) and output (y) variables\n",
    "dataset = np.loadtxt('pima-indians-diabetes.csv', delimiter=',')\n",
    "X = dataset[:,0:8]\n",
    "y = dataset[:,8]\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "# PyTorch classifier\n",
    "class PimaClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Linear(8, 12)\n",
    "        self.act = nn.ReLU()\n",
    "        self.output = nn.Linear(12, 1)\n",
    "        self.prob = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.layer(x))\n",
    "        x = self.prob(self.output(x))\n",
    "        return x\n",
    "\n",
    "# create model with skorch\n",
    "model = NeuralNetClassifier(\n",
    "    PimaClassifier,\n",
    "    criterion=nn.BCELoss,\n",
    "    optimizer=optim.Adam,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# define the grid search parameters\n",
    "param_grid = {\n",
    "    'batch_size': [10, 20, 40, 60, 80, 100],\n",
    "    'max_epochs': [10, 50, 100]\n",
    "}\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X, y)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56fa2915-417c-4029-ba54-a9e5e01c08be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.730469 using {'optimizer': <class 'torch.optim.adamax.Adamax'>}\n",
      "0.673177 (0.034104) with: {'optimizer': <class 'torch.optim.sgd.SGD'>}\n",
      "0.695312 (0.036782) with: {'optimizer': <class 'torch.optim.rmsprop.RMSprop'>}\n",
      "0.674479 (0.003683) with: {'optimizer': <class 'torch.optim.adagrad.Adagrad'>}\n",
      "0.555990 (0.031466) with: {'optimizer': <class 'torch.optim.adadelta.Adadelta'>}\n",
      "0.699219 (0.039836) with: {'optimizer': <class 'torch.optim.adam.Adam'>}\n",
      "0.730469 (0.019401) with: {'optimizer': <class 'torch.optim.adamax.Adamax'>}\n",
      "0.712240 (0.029463) with: {'optimizer': <class 'torch.optim.nadam.NAdam'>}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from skorch import NeuralNetClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# load the dataset, split into input (X) and output (y) variables\n",
    "dataset = np.loadtxt('pima-indians-diabetes.csv', delimiter=',')\n",
    "X = dataset[:,0:8]\n",
    "y = dataset[:,8]\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "# PyTorch classifier\n",
    "class PimaClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Linear(8, 12)\n",
    "        self.act = nn.ReLU()\n",
    "        self.output = nn.Linear(12, 1)\n",
    "        self.prob = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.layer(x))\n",
    "        x = self.prob(self.output(x))\n",
    "        return x\n",
    "\n",
    "# create model with skorch\n",
    "model = NeuralNetClassifier(\n",
    "    PimaClassifier,\n",
    "    criterion=nn.BCELoss,\n",
    "    max_epochs=100,\n",
    "    batch_size=10,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# define the grid search parameters\n",
    "param_grid = {\n",
    "    'optimizer': [optim.SGD, optim.RMSprop, optim.Adagrad, optim.Adadelta,\n",
    "                  optim.Adam, optim.Adamax, optim.NAdam],\n",
    "}\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X, y)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24267675-9688-4f78-a1aa-e9975c329494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.687500 using {'optimizer__lr': 0.001, 'optimizer__momentum': 0.9}\n",
      "0.674479 (0.014731) with: {'optimizer__lr': 0.001, 'optimizer__momentum': 0.0}\n",
      "0.645833 (0.029635) with: {'optimizer__lr': 0.001, 'optimizer__momentum': 0.2}\n",
      "0.658854 (0.018414) with: {'optimizer__lr': 0.001, 'optimizer__momentum': 0.4}\n",
      "0.661458 (0.024360) with: {'optimizer__lr': 0.001, 'optimizer__momentum': 0.6}\n",
      "0.666667 (0.018688) with: {'optimizer__lr': 0.001, 'optimizer__momentum': 0.8}\n",
      "0.687500 (0.031894) with: {'optimizer__lr': 0.001, 'optimizer__momentum': 0.9}\n",
      "0.652344 (0.022326) with: {'optimizer__lr': 0.01, 'optimizer__momentum': 0.0}\n",
      "0.555990 (0.144631) with: {'optimizer__lr': 0.01, 'optimizer__momentum': 0.2}\n",
      "0.656250 (0.042910) with: {'optimizer__lr': 0.01, 'optimizer__momentum': 0.4}\n",
      "0.545573 (0.140094) with: {'optimizer__lr': 0.01, 'optimizer__momentum': 0.6}\n",
      "0.652344 (0.003189) with: {'optimizer__lr': 0.01, 'optimizer__momentum': 0.8}\n",
      "0.552083 (0.141790) with: {'optimizer__lr': 0.01, 'optimizer__momentum': 0.9}\n",
      "0.348958 (0.001841) with: {'optimizer__lr': 0.1, 'optimizer__momentum': 0.0}\n",
      "0.545573 (0.140094) with: {'optimizer__lr': 0.1, 'optimizer__momentum': 0.2}\n",
      "0.552083 (0.141790) with: {'optimizer__lr': 0.1, 'optimizer__momentum': 0.4}\n",
      "0.450521 (0.142719) with: {'optimizer__lr': 0.1, 'optimizer__momentum': 0.6}\n",
      "0.348958 (0.001841) with: {'optimizer__lr': 0.1, 'optimizer__momentum': 0.8}\n",
      "0.450521 (0.142719) with: {'optimizer__lr': 0.1, 'optimizer__momentum': 0.9}\n",
      "0.348958 (0.001841) with: {'optimizer__lr': 0.2, 'optimizer__momentum': 0.0}\n",
      "0.450521 (0.142719) with: {'optimizer__lr': 0.2, 'optimizer__momentum': 0.2}\n",
      "0.651042 (0.001841) with: {'optimizer__lr': 0.2, 'optimizer__momentum': 0.4}\n",
      "0.549479 (0.142719) with: {'optimizer__lr': 0.2, 'optimizer__momentum': 0.6}\n",
      "0.552083 (0.141790) with: {'optimizer__lr': 0.2, 'optimizer__momentum': 0.8}\n",
      "0.450521 (0.142719) with: {'optimizer__lr': 0.2, 'optimizer__momentum': 0.9}\n",
      "0.450521 (0.142719) with: {'optimizer__lr': 0.3, 'optimizer__momentum': 0.0}\n",
      "0.450521 (0.142719) with: {'optimizer__lr': 0.3, 'optimizer__momentum': 0.2}\n",
      "0.348958 (0.001841) with: {'optimizer__lr': 0.3, 'optimizer__momentum': 0.4}\n",
      "0.348958 (0.001841) with: {'optimizer__lr': 0.3, 'optimizer__momentum': 0.6}\n",
      "0.348958 (0.001841) with: {'optimizer__lr': 0.3, 'optimizer__momentum': 0.8}\n",
      "0.552083 (0.141790) with: {'optimizer__lr': 0.3, 'optimizer__momentum': 0.9}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from skorch import NeuralNetClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# load the dataset, split into input (X) and output (y) variables\n",
    "dataset = np.loadtxt('pima-indians-diabetes.csv', delimiter=',')\n",
    "X = dataset[:,0:8]\n",
    "y = dataset[:,8]\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "# PyTorch classifier\n",
    "class PimaClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Linear(8, 12)\n",
    "        self.act = nn.ReLU()\n",
    "        self.output = nn.Linear(12, 1)\n",
    "        self.prob = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.layer(x))\n",
    "        x = self.prob(self.output(x))\n",
    "        return x\n",
    "\n",
    "# create model with skorch\n",
    "model = NeuralNetClassifier(\n",
    "    PimaClassifier,\n",
    "    criterion=nn.BCELoss,\n",
    "    optimizer=optim.SGD,\n",
    "    max_epochs=100,\n",
    "    batch_size=10,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# define the grid search parameters\n",
    "param_grid = {\n",
    "    'optimizer__lr': [0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "    'optimizer__momentum': [0.0, 0.2, 0.4, 0.6, 0.8, 0.9],\n",
    "}\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X, y)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9e161ab-915e-42ac-85c0-34d9fe677b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# PyTorch classifier\n",
    "class PimaClassifier(nn.Module):\n",
    "    def __init__(self, weight_init=nn.init.xavier_uniform_):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Linear(8, 12)\n",
    "        self.act = nn.ReLU()\n",
    "        self.output = nn.Linear(12, 1)\n",
    "        self.prob = nn.Sigmoid()\n",
    "        # manually init weights\n",
    "        weight_init(self.layer.weight)\n",
    "        weight_init(self.output.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.layer(x))\n",
    "        x = self.prob(self.output(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b13788a-8d8a-4bdb-acb1-ed3dd1cb5823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.708333 using {'module__weight_init': <function xavier_normal_ at 0x0000024A1D37BB00>}\n",
      "0.348958 (0.001841) with: {'module__weight_init': <function uniform_ at 0x0000024A1D37B420>}\n",
      "0.669271 (0.026748) with: {'module__weight_init': <function normal_ at 0x0000024A1D37B4C0>}\n",
      "0.652344 (0.003189) with: {'module__weight_init': <function zeros_ at 0x0000024A1D37B7E0>}\n",
      "0.708333 (0.036690) with: {'module__weight_init': <function xavier_normal_ at 0x0000024A1D37BB00>}\n",
      "0.705729 (0.021236) with: {'module__weight_init': <function xavier_uniform_ at 0x0000024A1D37BA60>}\n",
      "0.688802 (0.008027) with: {'module__weight_init': <function kaiming_normal_ at 0x0000024A1D37BCE0>}\n",
      "0.555990 (0.148552) with: {'module__weight_init': <function kaiming_uniform_ at 0x0000024A1D37BC40>}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "from skorch import NeuralNetClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# load the dataset, split into input (X) and output (y) variables\n",
    "dataset = np.loadtxt('pima-indians-diabetes.csv', delimiter=',')\n",
    "X = dataset[:,0:8]\n",
    "y = dataset[:,8]\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "# PyTorch classifier\n",
    "class PimaClassifier(nn.Module):\n",
    "    def __init__(self, weight_init=init.xavier_uniform_):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Linear(8, 12)\n",
    "        self.act = nn.ReLU()\n",
    "        self.output = nn.Linear(12, 1)\n",
    "        self.prob = nn.Sigmoid()\n",
    "        # manually init weights\n",
    "        weight_init(self.layer.weight)\n",
    "        weight_init(self.output.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.layer(x))\n",
    "        x = self.prob(self.output(x))\n",
    "        return x\n",
    "\n",
    "# create model with skorch\n",
    "model = NeuralNetClassifier(\n",
    "    PimaClassifier,\n",
    "    criterion=nn.BCELoss,\n",
    "    optimizer=optim.Adamax,\n",
    "    max_epochs=100,\n",
    "    batch_size=10,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# define the grid search parameters\n",
    "param_grid = {\n",
    "    'module__weight_init': [init.uniform_, init.normal_, init.zeros_,\n",
    "                           init.xavier_normal_, init.xavier_uniform_,\n",
    "                           init.kaiming_normal_, init.kaiming_uniform_]\n",
    "}\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X, y)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b14a58c-d506-4772-a508-b21f7ca91b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.690104 using {'module__activation': <class 'torch.nn.modules.activation.Softplus'>}\n",
      "0.657552 (0.035277) with: {'module__activation': <class 'torch.nn.modules.linear.Identity'>}\n",
      "0.677083 (0.019225) with: {'module__activation': <class 'torch.nn.modules.activation.ReLU'>}\n",
      "0.575521 (0.158395) with: {'module__activation': <class 'torch.nn.modules.activation.ELU'>}\n",
      "0.643229 (0.032106) with: {'module__activation': <class 'torch.nn.modules.activation.ReLU6'>}\n",
      "0.572917 (0.161920) with: {'module__activation': <class 'torch.nn.modules.activation.GELU'>}\n",
      "0.690104 (0.024360) with: {'module__activation': <class 'torch.nn.modules.activation.Softplus'>}\n",
      "0.631510 (0.051064) with: {'module__activation': <class 'torch.nn.modules.activation.Softsign'>}\n",
      "0.627604 (0.024774) with: {'module__activation': <class 'torch.nn.modules.activation.Tanh'>}\n",
      "0.640625 (0.013902) with: {'module__activation': <class 'torch.nn.modules.activation.Sigmoid'>}\n",
      "0.652344 (0.008438) with: {'module__activation': <class 'torch.nn.modules.activation.Hardsigmoid'>}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "from skorch import NeuralNetClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# load the dataset, split into input (X) and output (y) variables\n",
    "dataset = np.loadtxt('pima-indians-diabetes.csv', delimiter=',')\n",
    "X = dataset[:,0:8]\n",
    "y = dataset[:,8]\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "# PyTorch classifier\n",
    "class PimaClassifier(nn.Module):\n",
    "    def __init__(self, activation=nn.ReLU):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Linear(8, 12)\n",
    "        self.act = activation()\n",
    "        self.output = nn.Linear(12, 1)\n",
    "        self.prob = nn.Sigmoid()\n",
    "        # manually init weights\n",
    "        init.kaiming_uniform_(self.layer.weight)\n",
    "        init.kaiming_uniform_(self.output.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.layer(x))\n",
    "        x = self.prob(self.output(x))\n",
    "        return x\n",
    "\n",
    "# create model with skorch\n",
    "model = NeuralNetClassifier(\n",
    "    PimaClassifier,\n",
    "    criterion=nn.BCELoss,\n",
    "    optimizer=optim.Adamax,\n",
    "    max_epochs=100,\n",
    "    batch_size=10,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# define the grid search parameters\n",
    "param_grid = {\n",
    "    'module__activation': [nn.Identity, nn.ReLU, nn.ELU, nn.ReLU6,\n",
    "                           nn.GELU, nn.Softplus, nn.Softsign, nn.Tanh,\n",
    "                           nn.Sigmoid, nn.Hardsigmoid]\n",
    "}\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X, y)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "647b99c8-1ef6-466d-8994-a0a2bc89d87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.705729 using {'module__dropout_rate': 0.1, 'module__weight_constraint': 1.0}\n",
      "0.694010 (0.020752) with: {'module__dropout_rate': 0.0, 'module__weight_constraint': 1.0}\n",
      "0.566406 (0.155499) with: {'module__dropout_rate': 0.0, 'module__weight_constraint': 2.0}\n",
      "0.562500 (0.151926) with: {'module__dropout_rate': 0.0, 'module__weight_constraint': 3.0}\n",
      "0.569010 (0.157040) with: {'module__dropout_rate': 0.0, 'module__weight_constraint': 4.0}\n",
      "0.675781 (0.024910) with: {'module__dropout_rate': 0.0, 'module__weight_constraint': 5.0}\n",
      "0.705729 (0.042112) with: {'module__dropout_rate': 0.1, 'module__weight_constraint': 1.0}\n",
      "0.701823 (0.018688) with: {'module__dropout_rate': 0.1, 'module__weight_constraint': 2.0}\n",
      "0.683594 (0.016877) with: {'module__dropout_rate': 0.1, 'module__weight_constraint': 3.0}\n",
      "0.677083 (0.017566) with: {'module__dropout_rate': 0.1, 'module__weight_constraint': 4.0}\n",
      "0.692708 (0.012890) with: {'module__dropout_rate': 0.1, 'module__weight_constraint': 5.0}\n",
      "0.704427 (0.012890) with: {'module__dropout_rate': 0.2, 'module__weight_constraint': 1.0}\n",
      "0.691406 (0.014616) with: {'module__dropout_rate': 0.2, 'module__weight_constraint': 2.0}\n",
      "0.697917 (0.012890) with: {'module__dropout_rate': 0.2, 'module__weight_constraint': 3.0}\n",
      "0.675781 (0.016877) with: {'module__dropout_rate': 0.2, 'module__weight_constraint': 4.0}\n",
      "0.697917 (0.025976) with: {'module__dropout_rate': 0.2, 'module__weight_constraint': 5.0}\n",
      "0.690104 (0.036690) with: {'module__dropout_rate': 0.3, 'module__weight_constraint': 1.0}\n",
      "0.687500 (0.016877) with: {'module__dropout_rate': 0.3, 'module__weight_constraint': 2.0}\n",
      "0.558594 (0.150005) with: {'module__dropout_rate': 0.3, 'module__weight_constraint': 3.0}\n",
      "0.670573 (0.031466) with: {'module__dropout_rate': 0.3, 'module__weight_constraint': 4.0}\n",
      "0.683594 (0.029232) with: {'module__dropout_rate': 0.3, 'module__weight_constraint': 5.0}\n",
      "0.576823 (0.160627) with: {'module__dropout_rate': 0.4, 'module__weight_constraint': 1.0}\n",
      "0.696615 (0.015073) with: {'module__dropout_rate': 0.4, 'module__weight_constraint': 2.0}\n",
      "0.554688 (0.146471) with: {'module__dropout_rate': 0.4, 'module__weight_constraint': 3.0}\n",
      "0.661458 (0.008027) with: {'module__dropout_rate': 0.4, 'module__weight_constraint': 4.0}\n",
      "0.667969 (0.014616) with: {'module__dropout_rate': 0.4, 'module__weight_constraint': 5.0}\n",
      "0.549479 (0.142719) with: {'module__dropout_rate': 0.5, 'module__weight_constraint': 1.0}\n",
      "0.654948 (0.015733) with: {'module__dropout_rate': 0.5, 'module__weight_constraint': 2.0}\n",
      "0.656250 (0.020915) with: {'module__dropout_rate': 0.5, 'module__weight_constraint': 3.0}\n",
      "0.660156 (0.012758) with: {'module__dropout_rate': 0.5, 'module__weight_constraint': 4.0}\n",
      "0.658854 (0.008027) with: {'module__dropout_rate': 0.5, 'module__weight_constraint': 5.0}\n",
      "0.688802 (0.016367) with: {'module__dropout_rate': 0.6, 'module__weight_constraint': 1.0}\n",
      "0.660156 (0.030425) with: {'module__dropout_rate': 0.6, 'module__weight_constraint': 2.0}\n",
      "0.654948 (0.009744) with: {'module__dropout_rate': 0.6, 'module__weight_constraint': 3.0}\n",
      "0.651042 (0.004872) with: {'module__dropout_rate': 0.6, 'module__weight_constraint': 4.0}\n",
      "0.651042 (0.014382) with: {'module__dropout_rate': 0.6, 'module__weight_constraint': 5.0}\n",
      "0.548177 (0.141826) with: {'module__dropout_rate': 0.7, 'module__weight_constraint': 1.0}\n",
      "0.458333 (0.153767) with: {'module__dropout_rate': 0.7, 'module__weight_constraint': 2.0}\n",
      "0.553385 (0.142719) with: {'module__dropout_rate': 0.7, 'module__weight_constraint': 3.0}\n",
      "0.648438 (0.008438) with: {'module__dropout_rate': 0.7, 'module__weight_constraint': 4.0}\n",
      "0.647135 (0.007366) with: {'module__dropout_rate': 0.7, 'module__weight_constraint': 5.0}\n",
      "0.356771 (0.010253) with: {'module__dropout_rate': 0.8, 'module__weight_constraint': 1.0}\n",
      "0.649740 (0.001841) with: {'module__dropout_rate': 0.8, 'module__weight_constraint': 2.0}\n",
      "0.545573 (0.129529) with: {'module__dropout_rate': 0.8, 'module__weight_constraint': 3.0}\n",
      "0.550781 (0.140878) with: {'module__dropout_rate': 0.8, 'module__weight_constraint': 4.0}\n",
      "0.545573 (0.140094) with: {'module__dropout_rate': 0.8, 'module__weight_constraint': 5.0}\n",
      "0.552083 (0.141790) with: {'module__dropout_rate': 0.9, 'module__weight_constraint': 1.0}\n",
      "0.652344 (0.003189) with: {'module__dropout_rate': 0.9, 'module__weight_constraint': 2.0}\n",
      "0.494792 (0.101729) with: {'module__dropout_rate': 0.9, 'module__weight_constraint': 3.0}\n",
      "0.634115 (0.037377) with: {'module__dropout_rate': 0.9, 'module__weight_constraint': 4.0}\n",
      "0.351562 (0.003189) with: {'module__dropout_rate': 0.9, 'module__weight_constraint': 5.0}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "from skorch import NeuralNetClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# load the dataset, split into input (X) and output (y) variables\n",
    "dataset = np.loadtxt('pima-indians-diabetes.csv', delimiter=',')\n",
    "X = dataset[:,0:8]\n",
    "y = dataset[:,8]\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "# PyTorch classifier\n",
    "class PimaClassifier(nn.Module):\n",
    "    def __init__(self, dropout_rate=0.5, weight_constraint=1.0):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Linear(8, 12)\n",
    "        self.act = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.output = nn.Linear(12, 1)\n",
    "        self.prob = nn.Sigmoid()\n",
    "        self.weight_constraint = weight_constraint\n",
    "        # manually init weights\n",
    "        init.kaiming_uniform_(self.layer.weight)\n",
    "        init.kaiming_uniform_(self.output.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # maxnorm weight before actual forward pass\n",
    "        with torch.no_grad():\n",
    "            norm = self.layer.weight.norm(2, dim=0, keepdim=True) \\\n",
    "                                    .clamp(min=self.weight_constraint / 2)\n",
    "            desired = torch.clamp(norm, max=self.weight_constraint)\n",
    "            self.layer.weight *= (desired / norm)\n",
    "        # actual forward pass\n",
    "        x = self.act(self.layer(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.prob(self.output(x))\n",
    "        return x\n",
    "\n",
    "# create model with skorch\n",
    "model = NeuralNetClassifier(\n",
    "    PimaClassifier,\n",
    "    criterion=nn.BCELoss,\n",
    "    optimizer=optim.Adamax,\n",
    "    max_epochs=100,\n",
    "    batch_size=10,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# define the grid search parameters\n",
    "param_grid = {\n",
    "    'module__weight_constraint': [1.0, 2.0, 3.0, 4.0, 5.0],\n",
    "    'module__dropout_rate': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "}\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X, y)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc706336-44b2-4775-bff2-965968c4d34a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.708333 using {'module__n_neurons': 10}\n",
      "0.651042 (0.001841) with: {'module__n_neurons': 1}\n",
      "0.653646 (0.010253) with: {'module__n_neurons': 5}\n",
      "0.708333 (0.023939) with: {'module__n_neurons': 10}\n",
      "0.704427 (0.016053) with: {'module__n_neurons': 15}\n",
      "0.707031 (0.027805) with: {'module__n_neurons': 20}\n",
      "0.699219 (0.030425) with: {'module__n_neurons': 25}\n",
      "0.694010 (0.027498) with: {'module__n_neurons': 30}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "from skorch import NeuralNetClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# load the dataset, split into input (X) and output (y) variables\n",
    "dataset = np.loadtxt('pima-indians-diabetes.csv', delimiter=',')\n",
    "X = dataset[:,0:8]\n",
    "y = dataset[:,8]\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "class PimaClassifier(nn.Module):\n",
    "    def __init__(self, n_neurons=12):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Linear(8, n_neurons)\n",
    "        self.act = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.output = nn.Linear(n_neurons, 1)\n",
    "        self.prob = nn.Sigmoid()\n",
    "        self.weight_constraint = 2.0\n",
    "        # manually init weights\n",
    "        init.kaiming_uniform_(self.layer.weight)\n",
    "        init.kaiming_uniform_(self.output.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # maxnorm weight before actual forward pass\n",
    "        with torch.no_grad():\n",
    "            norm = self.layer.weight.norm(2, dim=0, keepdim=True) \\\n",
    "                                    .clamp(min=self.weight_constraint / 2)\n",
    "            desired = torch.clamp(norm, max=self.weight_constraint)\n",
    "            self.layer.weight *= (desired / norm)\n",
    "        # actual forward pass\n",
    "        x = self.act(self.layer(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.prob(self.output(x))\n",
    "        return x\n",
    "\n",
    "# create model with skorch\n",
    "model = NeuralNetClassifier(\n",
    "    PimaClassifier,\n",
    "    criterion=nn.BCELoss,\n",
    "    optimizer=optim.Adamax,\n",
    "    max_epochs=100,\n",
    "    batch_size=10,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# define the grid search parameters\n",
    "param_grid = {\n",
    "    'module__n_neurons': [1, 5, 10, 15, 20, 25, 30]\n",
    "}\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X, y)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
