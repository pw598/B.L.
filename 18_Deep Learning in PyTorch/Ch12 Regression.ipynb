{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be3540fe-64b4-41cf-a5c6-f076d4de97c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "data = fetch_california_housing()\n",
    "print(data.feature_names)\n",
    "\n",
    "X, y = data.data, data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87c643d2-678a-4f7d-afec-8bdc63f39cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Define the model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(8, 24),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(24, 12),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(12, 6),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(6, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbd9235f-9c4c-490a-b7f1-4556581186fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(8, 24),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(24, 12),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(12, 6),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(6, 1)\n",
    ")\n",
    "\n",
    "# loss function and optimizer\n",
    "loss_fn = nn.MSELoss()  # mean square error\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d60d5194-7dd9-4a79-b73b-2813b45b7fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = fetch_california_housing()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# train-test split of the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "# training parameters\n",
    "n_epochs = 100   # number of epochs to run\n",
    "batch_size = 10  # size of each batch\n",
    "batch_start = torch.arange(0, len(X_train), batch_size)\n",
    "\n",
    "# Hold the best model\n",
    "best_mse = np.inf   # init to infinity\n",
    "best_weights = None\n",
    "history = []\n",
    "\n",
    "# Define the model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(8, 24),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(24, 12),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(12, 6),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(6, 1)\n",
    ")\n",
    "\n",
    "# loss function and optimizer\n",
    "loss_fn = nn.MSELoss()  # mean square error\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "# training loop\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "        bar.set_description(f\"Epoch {epoch}\")\n",
    "        for start in bar:\n",
    "            # take a batch\n",
    "            X_batch = X_train[start:start+batch_size]\n",
    "            y_batch = y_train[start:start+batch_size]\n",
    "            # forward pass\n",
    "            y_pred = model(X_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            # backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "            # print progress\n",
    "            bar.set_postfix(mse=float(loss))\n",
    "    # evaluate accuracy at end of each epoch\n",
    "    model.eval()\n",
    "    y_pred = model(X_test)\n",
    "    mse = loss_fn(y_pred, y_test)\n",
    "    mse = float(mse)\n",
    "    history.append(mse)\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "# restore model and return best accuracy\n",
    "model.load_state_dict(best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b6a04e6-9eaf-48b8-ade8-14f788db5689",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 62\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# backward pass\u001b[39;00m\n\u001b[0;32m     61\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 62\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# update weights\u001b[39;00m\n\u001b[0;32m     64\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    493\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    494\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    252\u001b[0m     tensors,\n\u001b[0;32m    253\u001b[0m     grad_tensors_,\n\u001b[0;32m    254\u001b[0m     retain_graph,\n\u001b[0;32m    255\u001b[0m     create_graph,\n\u001b[0;32m    256\u001b[0m     inputs,\n\u001b[0;32m    257\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    258\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    259\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Read data\n",
    "data = fetch_california_housing()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# train-test split for model evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
    "\n",
    "# Convert to 2D PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "# Define the model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(8, 24),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(24, 12),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(12, 6),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(6, 1)\n",
    ")\n",
    "\n",
    "# loss function and optimizer\n",
    "loss_fn = nn.MSELoss()  # mean square error\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "n_epochs = 100   # number of epochs to run\n",
    "batch_size = 10  # size of each batch\n",
    "batch_start = torch.arange(0, len(X_train), batch_size)\n",
    "\n",
    "# Hold the best model\n",
    "best_mse = np.inf   # init to infinity\n",
    "best_weights = None\n",
    "history = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "        bar.set_description(f\"Epoch {epoch}\")\n",
    "        for start in bar:\n",
    "            # take a batch\n",
    "            X_batch = X_train[start:start+batch_size]\n",
    "            y_batch = y_train[start:start+batch_size]\n",
    "            # forward pass\n",
    "            y_pred = model(X_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            # backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "            # print progress\n",
    "            bar.set_postfix(mse=float(loss))\n",
    "    # evaluate accuracy at end of each epoch\n",
    "    model.eval()\n",
    "    y_pred = model(X_test)\n",
    "    mse = loss_fn(y_pred, y_test)\n",
    "    mse = float(mse)\n",
    "    history.append(mse)\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "# restore model and return best accuracy\n",
    "model.load_state_dict(best_weights)\n",
    "print(\"MSE: %.2f\" % best_mse)\n",
    "print(\"RMSE: %.2f\" % np.sqrt(best_mse))\n",
    "plt.plot(history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a81ff14-80b4-4e89-a76b-51c97ae98653",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Read data\n",
    "data = fetch_california_housing()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# train-test split for model evaluation\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, train_size=0.7,\n",
    "                                                            shuffle=True)\n",
    "\n",
    "# Standardizing data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_raw)\n",
    "X_train = scaler.transform(X_train_raw)\n",
    "X_test = scaler.transform(X_test_raw)\n",
    "\n",
    "# Convert to 2D PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eae0f9e7-0328-4968-a635-16f2c263a42c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.31\n",
      "RMSE: 0.56\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAwnElEQVR4nO3de3zU9Z3v8ffcJ9chBJIQkmBQXFAUIXhDvFZx0bV1t11vrWhrz1m6KiBbt1L39OKxjduzdW3Xgm29rQ9ReaiUtXs4arTKRW2RQCqCBQQkgSQEAsnkOpPM/M4fc0kCBDLJzPySzOv5eMxjJr/5/jKffB/ovB/f7/f3/VkMwzAEAABgEqvZBQAAgNRGGAEAAKYijAAAAFMRRgAAgKkIIwAAwFSEEQAAYCrCCAAAMBVhBAAAmMpudgEDEQwGVVtbq6ysLFksFrPLAQAAA2AYhlpaWlRYWCirtf/xjxERRmpra1VcXGx2GQAAYBBqampUVFTU7/sjIoxkZWVJCv0x2dnZJlcDAAAGwuv1qri4OPo93p8REUYiUzPZ2dmEEQAARpjTLbFgASsAADAVYQQAAJiKMAIAAExFGAEAAKYijAAAAFMRRgAAgKkIIwAAwFSEEQAAYCrCCAAAMBVhBAAAmIowAgAATEUYAQAAphoRN8pLlNcrD2jbwWb99fQCXTI51+xyAABISSk9MvL+rsN6/sMvtL3Wa3YpAACkrJQOI05b6M/3dwdNrgQAgNSV0mHE5SCMAABgtpQOI9GRkUDA5EoAAEhdKR1GXHZGRgAAMFtKhxEnYQQAANOldhiJTtMQRgAAMEtqh5HwyIiPkREAAExDGBHTNAAAmIkwIsIIAABmSu0wwpoRAABMl9phJLJmpIswAgCAWVI6jET3GWFkBAAA06R0GGHNCAAA5kvtMGKzSSKMAABgppQOI9Eb5TFNAwCAaVI6jESvpmFkBAAA06R2GGEHVgAATEcYkeTvDphcCQAAqSu1wwibngEAYLqUDiMuLu0FAMB0KR1GItM0QUPqZnQEAABTEEbCmKoBAMAcqR1GbD1/PvenAQDAHCkdRuw2q6yW0GtGRgAAMEdKhxGJ+9MAAGA2woiNjc8AADATYcTOzfIAADBTyoeR6F4jrBkBAMAUhBHWjAAAYKqUDyMsYAUAwFyEkeg0DTfLAwDADIQRGyMjAACYiTBi59JeAADMRBhhzQgAAKYijNi4tBcAADMRRiLTNNwoDwAAUxBG2PQMAABTpXwYYdMzAADMlfJhhEt7AQAwF2GEaRoAAExFGGGaBgAAU6V8GHHZbZLY9AwAALOkfBhhZAQAAHPFHEbWr1+vm266SYWFhbJYLFqzZs0p269evVrXXXedxo8fr+zsbF166aV66623Bltv3LHpGQAA5oo5jLS1tWnGjBl68sknB9R+/fr1uu6667R27VpVVlbq6quv1k033aStW7fGXGwi9IyMcNdeAADMYI/1hPnz52v+/PkDbv/EE0/0+fmnP/2p/uu//ku///3vNXPmzFg/Pu6YpgEAwFwxh5GhCgaDamlp0dixY/tt4/P55PP5oj97vd6E1ePi0l4AAEyV9AWsP//5z9XW1qZbbrml3zbl5eXyeDzRR3FxccLqYdMzAADMldQw8vLLL+tHP/qRVq1apby8vH7bLVu2TM3NzdFHTU1NwmqK3iiPMAIAgCmSNk2zatUq3XPPPXr11Vd17bXXnrKty+WSy+VKSl2sGQEAwFxJGRl5+eWXdffdd+ull17SjTfemIyPHDCmaQAAMFfMIyOtra36/PPPoz/v27dPVVVVGjt2rEpKSrRs2TIdPHhQL7zwgqRQEFmwYIF+8Ytf6JJLLlF9fb0kKS0tTR6PJ05/xuAxTQMAgLliHhnZvHmzZs6cGb0sd+nSpZo5c6Z+8IMfSJLq6upUXV0dbf/rX/9a3d3duvfeezVhwoToY/HixXH6E4aGG+UBAGCumEdGrrrqKhmG0e/7zz//fJ+f33///Vg/IqlcrBkBAMBUKX9vmsiN8ggjAACYI+XDCNM0AACYizASvpomEDQUCPY//QQAABKDMGLv6QKmagAASD7CCGEEAABTpXwYsVstslhCr32BgLnFAACQglI+jFgslui6EV8XIyMAACRbyocRiStqAAAwE2FEbHwGAICZCCPiZnkAAJiJMCKmaQAAMBNhRL3CCCMjAAAkHWFEhBEAAMxEGFHPzfJ8hBEAAJKOMKJeC1hZMwIAQNIRRsQ0DQAAZiKMiDACAICZCCPqHUa4Nw0AAMlGGJHkYs0IAACmIYyoZ2SEG+UBAJB8hBGxAysAAGYijIh70wAAYCbCiHpN0xBGAABIOsKImKYBAMBMhBGxzwgAAGYijIg1IwAAmIkwIsnlCN0ojzACAEDyEUbEpmcAAJiJMCLWjAAAYCbCiAgjAACYiTCingWsPqZpAABIOsKIGBkBAMBMhBH13oE1YHIlAACkHsKIGBkBAMBMhBGx6RkAAGYijEhycW8aAABMQxgR0zQAAJiJMCLCCAAAZiKMqGfNSHfQUDBomFwNAACphTCinhvlSawbAQAg2Qgj6hkZkSQfUzUAACQVYUSSw2aJvmbdCAAAyUUYkWSxWHoWsTJNAwBAUhFGwlxsfAYAgCkII2HcnwYAAHMQRsLYawQAAHMQRsIIIwAAmIMwEsbN8gAAMAdhJCy6ZoSraQAASCrCSBjTNAAAmIMwEsY0DQAA5iCMhDEyAgCAOQgjYS576GZ57MAKAEByEUbCXIyMAABgipjDyPr163XTTTepsLBQFotFa9asOe0569atU1lZmdxutyZPnqynnnpqMLUmFNM0AACYI+Yw0tbWphkzZujJJ58cUPt9+/bphhtu0OWXX66tW7fq+9//vhYtWqTXX3895mITKbqAlWkaAACSyh7rCfPnz9f8+fMH3P6pp55SSUmJnnjiCUnStGnTtHnzZv3bv/2bvvrVr8b68QnTc28awggAAMmU8DUjH330kebNm9fn2PXXX6/Nmzerq6vrpOf4fD55vd4+j0TjRnkAAJgj4WGkvr5e+fn5fY7l5+eru7tbR44cOek55eXl8ng80UdxcXGiy2TNCAAAJknK1TQWi6XPz4ZhnPR4xLJly9Tc3Bx91NTUJLxGNj0DAMAcMa8ZiVVBQYHq6+v7HGtoaJDdbldubu5Jz3G5XHK5XIkurQ9GRgAAMEfCR0YuvfRSVVRU9Dn29ttva/bs2XI4HIn++AGL7jPC1TQAACRVzGGktbVVVVVVqqqqkhS6dLeqqkrV1dWSQlMsCxYsiLZfuHCh9u/fr6VLl+qzzz7Ts88+q2eeeUbf/e534/MXxAkjIwAAmCPmaZrNmzfr6quvjv68dOlSSdJdd92l559/XnV1ddFgIkmlpaVau3atHnjgAf3qV79SYWGhfvnLXw6ry3ol1owAAGCWmMPIVVddFV2AejLPP//8CceuvPJKbdmyJdaPSion0zQAAJiCe9OERW6Ux6ZnAAAkF2EkjDUjAACYgzASRhgBAMAchJEwbpQHAIA5CCNhjIwAAGAOwkiYixvlAQBgCsJIGCMjAACYgzASxqZnAACYgzASxqZnAACYgzASFgkjXQFDwWD/O8wCAID4IoyERcKIxOgIAADJRBgJi6wZkQgjAAAkE2EkrE8YYRErAABJQxgJs1otXFEDAIAJCCO9sNcIAADJRxjphct7AQBIPsJIL0zTAACQfISRXpzR+9MQRgAASBbCSC9ObpYHAEDSEUZ6YZoGAIDkI4z0wtU0AAAkH2GkF66mAQAg+QgjvbgYGQEAIOkII72wZgQAgOQjjPTCNA0AAMlHGOmFBawAACQfYaQXF5ueAQCQdISRXhgZAQAg+QgjvThtNkmsGQEAIJkII70wMgIAQPIRRnrh3jQAACQfYaQXNj0DACD5CCO9sOkZAADJRxjphU3PAABIPsJILyxgBQAg+QgjvUSmadj0DACA5CGM9MLICAAAyUcY6YU1IwAAJB9hpBdGRgAASD7CSC/sMwIAQPIRRnpxMU0DAEDSEUZ6id4oj5ERAACShjDSC2tGAABIPsJILz03yiOMAACQLISRXhgZAQAg+QgjvWS67JJCC1jb/d0mVwMAQGogjPTiSXMoyx0KJAeOdZhcDQAAqYEwcpzinHRJUs3RdpMrAQAgNRBGjlM8Nk0SYQQAgGQhjBynZGxoZKT6KNM0AAAkA2HkOMXhMFJzjJERAACSgTByHNaMAACQXISR40TWjBw41iHDMEyuBgCA0Y8wcpyi8MhIq69bx9q7TK4GAIDRb1BhZPny5SotLZXb7VZZWZk2bNhwyvYrV67UjBkzlJ6ergkTJuib3/ymGhsbB1VworkdNuVluSQxVQMAQDLEHEZWrVqlJUuW6OGHH9bWrVt1+eWXa/78+aqurj5p+40bN2rBggW65557tH37dr366qv6+OOP9e1vf3vIxScKi1gBAEiemMPI448/rnvuuUff/va3NW3aND3xxBMqLi7WihUrTtr+j3/8o8444wwtWrRIpaWlmjt3rv7hH/5BmzdvHnLxiVKcE9lrhMt7AQBItJjCiN/vV2VlpebNm9fn+Lx58/Thhx+e9Jw5c+bowIEDWrt2rQzD0KFDh/Taa6/pxhtv7PdzfD6fvF5vn0cy9ew1wsgIAACJFlMYOXLkiAKBgPLz8/scz8/PV319/UnPmTNnjlauXKlbb71VTqdTBQUFGjNmjP7jP/6j388pLy+Xx+OJPoqLi2Mpc8iKwmHkANM0AAAk3KAWsFoslj4/G4ZxwrGIHTt2aNGiRfrBD36gyspKvfnmm9q3b58WLlzY7+9ftmyZmpubo4+amprBlDlo7DUCAEDy2GNpPG7cONlsthNGQRoaGk4YLYkoLy/XZZddpgcffFCSdP755ysjI0OXX365Hn30UU2YMOGEc1wul1wuVyylxVVkr5GDTR0KBA3ZrCcPWgAAYOhiGhlxOp0qKytTRUVFn+MVFRWaM2fOSc9pb2+X1dr3Y2w2myQN203FJnjSZLda1BUwVO/tNLscAABGtZinaZYuXaqnn35azz77rD777DM98MADqq6ujk67LFu2TAsWLIi2v+mmm7R69WqtWLFCe/fu1QcffKBFixbpoosuUmFhYfz+kjiyWS2amMPdewEASIaYpmkk6dZbb1VjY6MeeeQR1dXVafr06Vq7dq0mTZokSaqrq+uz58jdd9+tlpYWPfnkk/qnf/onjRkzRtdcc43+9V//NX5/RQIU56Rrf2O7ao6265LJuWaXAwDAqGUxhutcSS9er1cej0fNzc3Kzs5OymcuW/2JXt5Uo0VfmqKl152dlM8EAGA0Gej3N/em6Ud0F1amaQAASCjCSD+4vBcAgOQgjPSD+9MAAJAchJF+RO5Pc8jrU2dXwORqAAAYvQgj/Rib4VSGM7QfyoFj3DAPAIBEIYz0w2KxMFUDAEASEEZOoSi8iPUAi1gBAEgYwsgpRO5RU8M0DQAACUMYOYWS8DRNdSMjIwAAJAph5BSie42wZgQAgIQhjJwCu7ACAJB4hJFTKArvNeLt7FZze5fJ1QAAMDoRRk4hw2VXboZTElM1AAAkCmHkNJiqAQAgsQgjp8HGZwAAJBZh5DTOyA2Fkd2HWk2uBACA0YkwchrTJ3okSdsONptcCQAAoxNh5DRmFI2RJO061KIOP3fvBQAg3ggjp5Gf7dL4LJeChrS9ltERAADijTByGhaLRTOKQlM1nxwgjAAAEG+EkQE4b+IYSdInB5pMrQMAgNGIMDIA5xeHR0ZYxAoAQNwRRgbg/PAVNXsPt8nbybbwAADEE2FkAHIzXZo4JnSfmk8ZHQEAIK4IIwN0fngR6zYWsQIAEFeEkQE6P7zfCFfUAAAQX4SRAYqMjHxysMncQgAAGGUIIwMU2Ra+5miHjrb5Ta4GAIDRgzAyQJ40hyaPy5DEfWoAAIgnwkgMzotM1dQ0mVsIAACjCGEkBtFFrIyMAAAQN4SRGEQXsbItPAAAcUMYicG5hdmyWqRDXp8OeTvNLgcAgFGBMBKDdKddU/KyJLHfCAAA8UIYiVHPTqxN5hYCAMAoQRiJUSSM/JmREQAA4oIwEqPIFTXbDjbLMAxziwEAYBQgjMRo6oQsOW1WHW3z64vGdrPLAQBgxCOMxMhlt2nWpDGSpI2fHzG3GAAARgHCyCDMPWucJGnj7sMmVwIAwMhHGBmEuVPGS5I+3NOoQJB1IwAADAVhZBDOm+hRttuuls5udmMFAGCICCODYLNaNOfMyFQN60YAABgKwsggzZ0SCiMbWMQKAMCQEEYGKbKIdWv1MbX5uk2uBgCAkYswMkiTctNVlJOmroChTfuOml0OAAAjFmFkkCwWiy6PTNWwbgQAgEEjjAzBZeGpmg9YNwIAwKARRoZgzpnjZLFIOw+1qMHbaXY5AACMSISRIRib4dS5hdmS2BoeAIDBIowM0dyzQruxEkYAABgcwsgQRRaxbtx9RIbB1vAAAMSKMDJEZZNy5LJb1dDi0+6GVrPLAQBgxCGMDJHbYdNFpWMlsTU8AACDMagwsnz5cpWWlsrtdqusrEwbNmw4ZXufz6eHH35YkyZNksvl0plnnqlnn312UAUPR5HdWN/b2WByJQAAjDwxh5FVq1ZpyZIlevjhh7V161Zdfvnlmj9/vqqrq/s955ZbbtG7776rZ555Rjt37tTLL7+sqVOnDqnw4eRL0/IlSX/c2yhvZ5fJ1QAAMLJYjBhXXV588cWaNWuWVqxYET02bdo03XzzzSovLz+h/ZtvvqnbbrtNe/fu1dixYwdVpNfrlcfjUXNzs7Kzswf1OxLtmp+/r72H2/TL22fqyzMKzS4HAADTDfT7O6aREb/fr8rKSs2bN6/P8Xnz5unDDz886TlvvPGGZs+erZ/97GeaOHGizj77bH33u99VR0dHv5/j8/nk9Xr7PIa7eecUSJLe3l5vciUAAIwsMYWRI0eOKBAIKD8/v8/x/Px81def/Et479692rhxoz799FP97ne/0xNPPKHXXntN9957b7+fU15eLo/HE30UFxfHUqYprj831Cfv7zwsX3fA5GoAABg5BrWA1WKx9PnZMIwTjkUEg0FZLBatXLlSF110kW644QY9/vjjev755/sdHVm2bJmam5ujj5qamsGUmVQzisYoL8ulVl+3PtrTaHY5AACMGDGFkXHjxslms50wCtLQ0HDCaEnEhAkTNHHiRHk8nuixadOmyTAMHThw4KTnuFwuZWdn93kMd1arRdedE+qDt3ccMrkaAABGjpjCiNPpVFlZmSoqKvocr6io0Jw5c056zmWXXaba2lq1tvZsCLZr1y5ZrVYVFRUNouTha965oXUjFTsOKRhkN1YAAAYi5mmapUuX6umnn9azzz6rzz77TA888ICqq6u1cOFCSaEplgULFkTb33HHHcrNzdU3v/lN7dixQ+vXr9eDDz6ob33rW0pLS4vfXzIMXDo5V1kuuw63+LS1psnscgAAGBHssZ5w6623qrGxUY888ojq6uo0ffp0rV27VpMmTZIk1dXV9dlzJDMzUxUVFbr//vs1e/Zs5ebm6pZbbtGjjz4av79imHDarbpqap5+/+davb2jXmWTcswuCQCAYS/mfUbMMBL2GYn4709qdd9LW1U6LkN/+Kcr+13YCwDAaJeQfUZweleePV5Om1X7jrRpz2FunAcAwOkQRuIsy+3QnLNyJUlvbeeqGgAATocwkgDR3Vi5xBcAgNMijCTAtefkyWKR/lzTpNqm/re9BwAAhJGEyMty68IzQjcFfK3y5Bu7AQCAEMJIgtxxUYkk6ZVN1QqwARoAAP0ijCTIX08vUE66Q7XNnXp/Z4PZ5QAAMGwRRhLE7bDpq7NC292/9Kfq07QGACB1EUYS6PaLQ1M17+1sYCErAAD9IIwk0JnjM3XJ5LEKGtIrH9eYXQ4AAMMSYSTBvn5x6J49qz6uVncgaHI1AAAMP4SRBLv+3ALlZjh1yOvTH/7CQlYAAI5HGEkwp92qr80OL2TdxEJWAACORxhJgtsvDC1kXbfrsGqOtptcDQAAwwthJAnOGJehy6eMk2FIr3zM6AgAAL0RRpLk6+HLfFf+qVqtvm6TqwEAYPggjCTJdecUaPL4DDW1d+nFP+43uxwAAIYNwkiS2KwW3XvVWZKkpzfsVYc/YHJFAAAMD4SRJPryBYUqHpumI61+rqwBACCMMJJEDptV/xgeHfn1uj3q7GJ0BAAAwkiSfXVWkQo9bjW0+PTqZraIBwCAMJJkTrtVC686U5K04v098nezRTwAILURRkxwy+xi5WW5VNvcqdVbDphdDgAApiKMmMDtsOl/XjFZkrT8/T3cQA8AkNIIIyb5+sWTlJvhVPXRdr3MlTUAgBRGGDFJmtOmRV+aIkn6P2/t1JFWn8kVAQBgDsKIib5xySSdW5gtb2e3ytf+xexyAAAwBWHERDarRf/75umSpNe3HNCmfUdNrggAgOQjjJhsVkmObr+oWJL0v9Z8qi4WswIAUgxhZBj45+unKifdoZ2HWvT8B1+YXQ4AAElFGBkGcjKcemj+VEnSE+/sUn1zp8kVAQCQPISRYeLvy4o1q2SM2vwB/fCNT2UYhtklAQCQFISRYcIaXsxqt1r01vZDeuGj/WaXBABAUhBGhpFzCz3R6ZpH/+8Oba0+ZnJFAAAkHmFkmLlnbqnmTy9QV8DQvSu36Fib3+ySAABIKMLIMGOxWPSzr52v0nEZqm3u1JJVVQoGWT8CABi9CCPDUJbboeVfnyW3w6p1uw7ryfc+N7skAAAShjAyTE2bkK1Hbz5PkvTv7+zSu58dMrkiAAASgzAyjH2trEi3X1Qsw5D+ceUW/XFvo9klAQAQd4SRYe6Rr0zXtdPy5OsO6tv/uVmfHGgyuyQAAOKKMDLMOWxWPXnHLF06OVetvm7d9ewm7T7UYnZZAADEDWFkBHA7bPrtXbM1o8ijY+1d+sYzf1LN0XazywIAIC4IIyNEpsuu5795kabkZeqQ16fbfvNHfVbnNbssAACGjDAyguRkOPXity9W6bgMHWzq0FdXfKg3P60zuywAAIaEMDLC5Ge79bt/nKO5Z41Tuz+ghS9u0b9X7GJjNADAiEUYGYHGpDv1/Dcv1LcuK5Uk/eLd3frOykq1dHaZXBkAALEjjIxQdptVP7jpHP3sa+fLabPqre2HNO/f16tiB5ujAQBGFsLICHfL7GK98g+XaFJuuuqaO/U/Xtis77xYqQZvp9mlAQAwIISRUWBWSY7eWnKFvnPVmbJZLfp/n9brSz9fp//88Av5ugNmlwcAwClZDMMY9isfvV6vPB6PmpublZ2dbXY5w9qOWq+Wrf5Efz7QLEnKy3LpnrmluuPiEmW5HSZXBwBIJQP9/iaMjEKBoKGX/rRfy9/fo7rm0HRNttuuBZeeoQWXTlJettvkCgEAqYAwAvm7g1pTdVBPrdujvYfbJEl2q0XXTsvXHReXaO5Z42S1WkyuEgAwWhFGEBUMGnp7xyE9vWGvNu8/Fj1eMjZdt15YrK+VFSmf0RIAQJwRRnBSO+tb9PKmar2+5YBaOrslSVaLdMXZ4/W1siJdd06+XHabyVUCAEaDgX5/D+pqmuXLl6u0tFRut1tlZWXasGHDgM774IMPZLfbdcEFFwzmYxEHf1WQpR99+Vxt+v61+tnXzteFZ+QoaEjv7zys+17aqot+8q7+Zc02Ve4/qhGQUwEAo0DMIyOrVq3SnXfeqeXLl+uyyy7Tr3/9az399NPasWOHSkpK+j2vublZs2bN0llnnaVDhw6pqqpqwJ/JyEhi7TvSptcqa/R65UHV99qfpGRsur5yQaG+csFEnZWXaWKFAICRKGHTNBdffLFmzZqlFStWRI9NmzZNN998s8rLy/s977bbbtOUKVNks9m0Zs0awsgwFAga+uDzI1pTdVBvfVqvNn/PHiVn5Kbr6ql5uvqv8nTx5LFM5QAATmug39/2WH6p3+9XZWWlHnrooT7H582bpw8//LDf85577jnt2bNHL774oh599NHTfo7P55PP54v+7PV6YykTg2SzWnTF2eN1xdnj1XFzQBWfHdKarQe1YfdhfdHYruc++ELPffCF0p02zTkzV1eG207KzTC7dADACBZTGDly5IgCgYDy8/P7HM/Pz1d9ff1Jz9m9e7ceeughbdiwQXb7wD6uvLxcP/7xj2MpDXGW5rTpyzMK9eUZhWr1dWvj7iN67y8Nem9ngxpafHrnswa981mDpNCoyRVnj9ecM3N1cWmucjKcJlcPABhJYgojERZL370pDMM44ZgkBQIB3XHHHfrxj3+ss88+e8C/f9myZVq6dGn0Z6/Xq+Li4sGUijjIdNn119ML9NfTC2QYhrbXerVu12Gt33VYlfuP6YvGdn3x0X698NF+WSzStIJsXXpmri6ZnKsLz8jRmHTCCQCgfzGtGfH7/UpPT9err76qv/3bv40eX7x4saqqqrRu3bo+7ZuampSTkyObrWd9QTAYlGEYstlsevvtt3XNNdec9nNZMzJ8tXR26aM9jdr4+RF9tKdRuxtaT2hzdn6mLjxjrC4qHatZJTkqykk7aXgFAIwuCVkz4nQ6VVZWpoqKij5hpKKiQl/5yldOaJ+dna1t27b1ObZ8+XL94Q9/0GuvvabS0tJYPh7DUJbboXnnFmjeuQWSpIaWTv1x71F9tKdRm/Y1as/hNu061Kpdh1q18k/VkqRxmS7NKhmjmSU5mlkyRucXeZTuHNQgHQBgFIj5G2Dp0qW68847NXv2bF166aX6zW9+o+rqai1cuFBSaIrl4MGDeuGFF2S1WjV9+vQ+5+fl5cntdp9wHKNDXpY7utZEkhpbffr4i2P6+Iuj2vzFUW2v9epIq09v7zikt3cckhTadO3s/CzNLBmjC4rH6LyJYzQlP1MOGzeVBoBUEHMYufXWW9XY2KhHHnlEdXV1mj59utauXatJkyZJkurq6lRdXR33QjEy5Wa6outNJKmzK6BPDzZra3WTtlQf09bqJtV7O/WX+hb9pb5FL2+qkSQ5bVadXZCp6YUenVuYrb8qyNZfFWTJk8adhwFgtGE7eJiuvrlTVTXHtLWmSX+uadL2Wm90q/rjFXrcmjohW1PyM3XW+ExNyc/SmeMzlOUmpADAcMO9aTBiGYahmqMd2l7brO21Xn1W59Vf6lt0sKmj33MKst06My9DZ47P1ORxGTozL1Nn5GZogsctO9M9AGAKwghGneaOLu2sb9HOeq92N7Tq84ZW7W5o1eEWX7/n2K0WFeWkqSQ3QyVj0zRxTLoKx7g1cUyaJuakKS/LLZuVK3sAIBEII0gZze1d+vxwq/YebtWew23aE35dc7RD/kDwlOfarBblZ7k0YUyaJnjcmuBxq3BMmiZ40lQ4xq0JnjSNy3RyKTIADEJCLu0FhiNPukNlk3JUNimnz/FA0FC9t1PVje2qPtqm6qPtqm3q1MGmDtU2dai+uVPdQUO1zZ2qbe7s57eHFtPme1wqyHarwBMKLfnZ7j7P47NcXP0DAIPEyAhSViBo6HCLT7XNoWBS29ShuuZO1TV3qLYp9PPhVp8G8l+IxSLlZriUn+1SfrZb+dkujc8KPef1es7NdBJaAKQMRkaA07BZLSrwuFXgcffbxt8dVENLpw55O1XX3Kn65vCzN/S6vjn0XnfQ0JFWn460+rS99tQ3dhyT7tC4TJfGZTo1PssdfnZpfKZL47JcGpfh0thMp3IznHI7uDsygNGPMAKcgtNuVVFOuopy0vttEwwaOtLmU4PXp8MtPh3yhsJKQ0voWENLZ+i9Vp8CQUNN7V1qau/S5w2n//wMp025mS7lZjqVmxEKMJHXfZ4znRqb7uTKIQAjEmEEGCKr1aK8LLfysvofYZFCoaWpo0tHWkOhJfJ8uNWnIy3+8LNPR9v8amzzqStgqM0fUNvRdlUfbR9QLWPSHRqb4QyNrmQ4lZMRGmEZmxEKLDnpodeRByMvAIYDwgiQJFarJRoCzs7POmVbwzDk7exWY2sonBxpDQWUxla/Glt9amzzq7HVH37Pp2PtfgUNRUdd9h5uG1BNaQ6bctIdyskIBZUx6Q7lpDuVk+7QmHSncjLCz+lOjUkLvZfltsvK5dAA4ogwAgxDFotFnjSHPGkOTR5/+vah6R9/n+BytFdgOdru19FWv46F2xxr96srYKijK6CO5sApryY6ntUiedJCIcWT5lBOuiNaqyfNoezwc+T9MekOjQkfZyQGwMkQRoBRwGa1hNeWuDQl//TtDcNQi69bTW1dOtoeCifH2vw61t6lpsjP4deR0ZZj7X61+wMKGtKx9i4da++KuU6X3RoNK9luezSwRELLyUJNqK1DboeV/V6AUYowAqQgi8WibHfoS74kt//FucfzdQfU3N6lpo6ucEgJhZXmjv4fTe1+NXd0KWhIvu5gaJ3MKXbN7Y/TFgoy2Wn2aEDJDoea7DSHstz26LHQa7uy3KHXWW6HMpw2wgwwTBFGAAyYy25TXrZNedmnXqx7vGDQUKu/W95wQPF2dIfDSnjkJRxumjv88nZ0y9vZ1dO2s1uBoCF/IBi9fHowbFZLr8ASes46LrBku3uOR0JNpiv8cNuV5iDQAIlAGAGQcFZrz0hMUc7p2/dmGIZafd19RltaOrvV0tkTblo6ewJM6LlbLb6edoGg0eey6kH/HRYpIxxOIs+h1zZlOEPH0l02ZUUDjEOZrtAoTaa7J9RkuZh2AnojjAAY1iwWS3j0IvYgI4XCTGdXUC2doaDS3NE7uHSrpTMSWrqiAScadjq71OrrVquvW4YhBQ1F3xsqm9WiDKdNWeHAkuGyKcNlV5bbHg02kfCSGT7eOwT1DkMEG4x0hBEAo5rFYlGa06Y0Z+zTSxGGEbryqLWzWy2+brWFA0qbL9DrdfjhD7Vr9YXatoZDTpsvFGJa/aFgEwiGLt/2xiHYWC3qMzKT4bQrzWlTurPv6zSnTemOUPBxO0IPl90aejhsSnOE2oUeod+V7rCxmR4SjjACAKdhsVhCX85Ou/KG+LuCQUPtXT2BpdXXHX7dpdbjwk3f93sebZEg5O81YhMOP4ngtFmjgSbdGRrBSXOEn52hwBIKO5Hjtl7t7aH3HD0ByO2w9glDdquFkZ0URxgBgCSyWi3R6ZWhCgZDIzaREZlIgGn3d6vdH1C7P6AOfyi0dIR/Dh0Lve8PBOXrCqqzO6DOrqA6uwJ9zg0EQ3eJ9AeC8ncE1dwx+PU2p2K1hBZHuxxWue09YcXlsMltt0ZDizs8epMWHeUJPfc+7nZYle7smcrKcNlCU1l2G5v1DWOEEQAYoaxWS/gLN/7/KzcMQ77uYCjEdPUEmNAjNDITCTqR0NPR1RN22sLHIuGmsyv0fiT0+LqD0c8KGgptwNcVkJSYwCOpJ8j0Gp0JTVOFfnbZjxu1cViV7rArzWmNjvq47FY5ww+XzSpX9LyecyOjQDbCz4ARRgAAJ7BYLNEv5UGsGz6tYPhybV93UL7uQGiEJhJWugPR177uvs+9R28iASgUdILqDP/c5j9xKkvqHXiSw2GzhEZ6wiM2aeGg4uoVgiLhpvfanchrt6PXNFd42stps8pht8ppC4ei8BRaJGQ5Ruj6HsIIACDprFaL3FZb+BYBjoR9TmTx8fGjN53hEBMKQz2jNb7wc2dXoNeoUE8A8ncHQ9NW3UF1BXrO7ewKqqMr9H5EV8BQVyBxa3lOxma1yGmzym7reXbZ+673SXfa5LTb5Ai3cYTb/d3MIp1X5Elarb0RRgAAo1bvxcfJEAwaPWGmq+/0lC/8uqMrNBIUCTX+yOhQOBj5eo0Qtfv7jgT5A6EQ1NVtqCvQ8znh5T0KBA11BAODmu2aWZJDGAEAYKSzWnsuJU/E9NbJGIbRc+NLfyAUVgLB8MhMKOgcv94nMrLTu92UvMwkVXwiwggAACOYxWKR026R026VJy1xU16JNDJXugAAgFGDMAIAAExFGAEAAKYijAAAAFMRRgAAgKkIIwAAwFSEEQAAYCrCCAAAMBVhBAAAmIowAgAATEUYAQAApiKMAAAAUxFGAACAqUbEXXsNw5Akeb1ekysBAAADFfnejnyP92dEhJGWlhZJUnFxscmVAACAWLW0tMjj8fT7vsU4XVwZBoLBoGpra5WVlSWLxRK33+v1elVcXKyamhplZ2fH7ffiRPR1ctHfyUNfJw99nTzx6mvDMNTS0qLCwkJZrf2vDBkRIyNWq1VFRUUJ+/3Z2dn8w04S+jq56O/koa+Th75Onnj09alGRCJYwAoAAExFGAEAAKZK6TDicrn0wx/+UC6Xy+xSRj36Orno7+Shr5OHvk6eZPf1iFjACgAARq+UHhkBAADmI4wAAABTEUYAAICpCCMAAMBUKR1Gli9frtLSUrndbpWVlWnDhg1mlzTilZeX68ILL1RWVpby8vJ08803a+fOnX3aGIahH/3oRyosLFRaWpquuuoqbd++3aSKR4fy8nJZLBYtWbIkeox+jq+DBw/qG9/4hnJzc5Wenq4LLrhAlZWV0ffp7/jo7u7Wv/zLv6i0tFRpaWmaPHmyHnnkEQWDwWgb+npw1q9fr5tuukmFhYWyWCxas2ZNn/cH0q8+n0/333+/xo0bp4yMDH35y1/WgQMHhl6ckaJeeeUVw+FwGL/97W+NHTt2GIsXLzYyMjKM/fv3m13aiHb99dcbzz33nPHpp58aVVVVxo033miUlJQYra2t0TaPPfaYkZWVZbz++uvGtm3bjFtvvdWYMGGC4fV6Tax85Nq0aZNxxhlnGOeff76xePHi6HH6OX6OHj1qTJo0ybj77ruNP/3pT8a+ffuMd955x/j888+jbejv+Hj00UeN3Nxc47//+7+Nffv2Ga+++qqRmZlpPPHEE9E29PXgrF271nj44YeN119/3ZBk/O53v+vz/kD6deHChcbEiRONiooKY8uWLcbVV19tzJgxw+ju7h5SbSkbRi666CJj4cKFfY5NnTrVeOihh0yqaHRqaGgwJBnr1q0zDMMwgsGgUVBQYDz22GPRNp2dnYbH4zGeeuops8ocsVpaWowpU6YYFRUVxpVXXhkNI/RzfH3ve98z5s6d2+/79Hf83Hjjjca3vvWtPsf+7u/+zvjGN75hGAZ9HS/Hh5GB9GtTU5PhcDiMV155Jdrm4MGDhtVqNd58880h1ZOS0zR+v1+VlZWaN29en+Pz5s3Thx9+aFJVo1Nzc7MkaezYsZKkffv2qb6+vk/fu1wuXXnllfT9INx777268cYbde211/Y5Tj/H1xtvvKHZs2fr7//+75WXl6eZM2fqt7/9bfR9+jt+5s6dq3fffVe7du2SJP35z3/Wxo0bdcMNN0iirxNlIP1aWVmprq6uPm0KCws1ffr0Iff9iLhRXrwdOXJEgUBA+fn5fY7n5+ervr7epKpGH8MwtHTpUs2dO1fTp0+XpGj/nqzv9+/fn/QaR7JXXnlFW7Zs0ccff3zCe/RzfO3du1crVqzQ0qVL9f3vf1+bNm3SokWL5HK5tGDBAvo7jr73ve+publZU6dOlc1mUyAQ0E9+8hPdfvvtkvi3nSgD6df6+no5nU7l5OSc0Gao350pGUYiLBZLn58NwzjhGAbvvvvu0yeffKKNGzee8B59PzQ1NTVavHix3n77bbnd7n7b0c/xEQwGNXv2bP30pz+VJM2cOVPbt2/XihUrtGDBgmg7+nvoVq1apRdffFEvvfSSzj33XFVVVWnJkiUqLCzUXXfdFW1HXyfGYPo1Hn2fktM048aNk81mOyHJNTQ0nJAKMTj333+/3njjDb333nsqKiqKHi8oKJAk+n6IKisr1dDQoLKyMtntdtntdq1bt06//OUvZbfbo31JP8fHhAkTdM455/Q5Nm3aNFVXV0vi33U8Pfjgg3rooYd022236bzzztOdd96pBx54QOXl5ZLo60QZSL8WFBTI7/fr2LFj/bYZrJQMI06nU2VlZaqoqOhzvKKiQnPmzDGpqtHBMAzdd999Wr16tf7whz+otLS0z/ulpaUqKCjo0/d+v1/r1q2j72PwpS99Sdu2bVNVVVX0MXv2bH39619XVVWVJk+eTD/H0WWXXXbCJeq7du3SpEmTJPHvOp7a29tltfb9arLZbNFLe+nrxBhIv5aVlcnhcPRpU1dXp08//XTofT+k5a8jWOTS3meeecbYsWOHsWTJEiMjI8P44osvzC5tRPvOd75jeDwe4/333zfq6uqij/b29mibxx57zPB4PMbq1auNbdu2GbfffjuX5cVB76tpDIN+jqdNmzYZdrvd+MlPfmLs3r3bWLlypZGenm68+OKL0Tb0d3zcddddxsSJE6OX9q5evdoYN26c8c///M/RNvT14LS0tBhbt241tm7dakgyHn/8cWPr1q3RLS0G0q8LFy40ioqKjHfeecfYsmWLcc0113Bp71D96le/MiZNmmQ4nU5j1qxZ0ctPMXiSTvp47rnnom2CwaDxwx/+0CgoKDBcLpdxxRVXGNu2bTOv6FHi+DBCP8fX73//e2P69OmGy+Uypk6davzmN7/p8z79HR9er9dYvHixUVJSYrjdbmPy5MnGww8/bPh8vmgb+npw3nvvvZP+//muu+4yDGNg/drR0WHcd999xtixY420tDTjb/7mb4zq6uoh12YxDMMY2tgKAADA4KXkmhEAADB8EEYAAICpCCMAAMBUhBEAAGAqwggAADAVYQQAAJiKMAIAAExFGAEAAKYijAAAAFMRRgAAgKkIIwAAwFSEEQAAYKr/DyN9DQpfeExVAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.64540000e+00  3.30000000e+01  5.64229765e+00  1.00000000e+00\n",
      "  1.23500000e+03  3.22454308e+00  3.39000000e+01 -1.17990000e+02] -> [2.307659] (expected [2.028])\n",
      "[   5.5737       35.            5.43037975    0.98734177  914.\n",
      "    2.89240506   37.56       -122.02      ] -> [2.7775247] (expected [2.145])\n",
      "[   5.7654       35.            5.75547445    1.01824818  743.\n",
      "    2.71167883   33.84       -118.36      ] -> [3.326081] (expected [3.43])\n",
      "[   2.5742       32.            3.35238095    1.25714286  313.\n",
      "    2.98095238   37.78       -122.4       ] -> [1.7203534] (expected [3.5])\n",
      "[ 5.91710000e+00  1.40000000e+01  6.01724138e+00  1.02068966e+00\n",
      "  1.71000000e+03  2.94827586e+00  3.45200000e+01 -1.18350000e+02] -> [2.3911636] (expected [3.333])\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Read data\n",
    "data = fetch_california_housing()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# train-test split for model evaluation\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, train_size=0.7,\n",
    "                                                            shuffle=True)\n",
    "\n",
    "# Standardizing data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_raw)\n",
    "X_train = scaler.transform(X_train_raw)\n",
    "X_test = scaler.transform(X_test_raw)\n",
    "\n",
    "# Convert to 2D PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "# Define the model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(8, 24),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(24, 12),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(12, 6),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(6, 1)\n",
    ")\n",
    "\n",
    "# loss function and optimizer\n",
    "loss_fn = nn.MSELoss()  # mean square error\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "n_epochs = 100   # number of epochs to run\n",
    "batch_size = 10  # size of each batch\n",
    "batch_start = torch.arange(0, len(X_train), batch_size)\n",
    "\n",
    "# Hold the best model\n",
    "best_mse = np.inf   # init to infinity\n",
    "best_weights = None\n",
    "history = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "        bar.set_description(f\"Epoch {epoch}\")\n",
    "        for start in bar:\n",
    "            # take a batch\n",
    "            X_batch = X_train[start:start+batch_size]\n",
    "            y_batch = y_train[start:start+batch_size]\n",
    "            # forward pass\n",
    "            y_pred = model(X_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            # backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "            # print progress\n",
    "            bar.set_postfix(mse=float(loss))\n",
    "    # evaluate accuracy at end of each epoch\n",
    "    model.eval()\n",
    "    y_pred = model(X_test)\n",
    "    mse = loss_fn(y_pred, y_test)\n",
    "    mse = float(mse)\n",
    "    history.append(mse)\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "# restore model and return best accuracy\n",
    "model.load_state_dict(best_weights)\n",
    "print(\"MSE: %.2f\" % best_mse)\n",
    "print(\"RMSE: %.2f\" % np.sqrt(best_mse))\n",
    "plt.plot(history)\n",
    "plt.show()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Test out inference with 5 samples\n",
    "    for i in range(5):\n",
    "        X_sample = X_test_raw[i: i+1]\n",
    "        X_sample = scaler.transform(X_sample)\n",
    "        X_sample = torch.tensor(X_sample, dtype=torch.float32)\n",
    "        y_pred = model(X_sample)\n",
    "        print(f\"{X_test_raw[i]} -> {y_pred[0].numpy()} (expected {y_test[i].numpy()})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
