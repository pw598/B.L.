{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e1a82b0-c112-459f-a1fe-39491effd8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7034\u001b[0m       \u001b[32m0.4762\u001b[0m        \u001b[35m0.7000\u001b[0m  0.0475\n",
      "      2        \u001b[36m0.7012\u001b[0m       0.4762        \u001b[35m0.6997\u001b[0m  0.0566\n",
      "      3        \u001b[36m0.7006\u001b[0m       0.4762        \u001b[35m0.6994\u001b[0m  0.0452\n",
      "      4        \u001b[36m0.7001\u001b[0m       0.4762        \u001b[35m0.6992\u001b[0m  0.0381\n",
      "      5        \u001b[36m0.6996\u001b[0m       0.4762        \u001b[35m0.6990\u001b[0m  0.0368\n",
      "      6        \u001b[36m0.6991\u001b[0m       0.4762        \u001b[35m0.6988\u001b[0m  0.0397\n",
      "      7        \u001b[36m0.6987\u001b[0m       0.4762        \u001b[35m0.6985\u001b[0m  0.0513\n",
      "      8        \u001b[36m0.6982\u001b[0m       0.4762        \u001b[35m0.6983\u001b[0m  0.0422\n",
      "      9        \u001b[36m0.6977\u001b[0m       0.4762        \u001b[35m0.6980\u001b[0m  0.0486\n",
      "     10        \u001b[36m0.6972\u001b[0m       0.4762        \u001b[35m0.6977\u001b[0m  0.0409\n",
      "     11        \u001b[36m0.6966\u001b[0m       0.4762        \u001b[35m0.6974\u001b[0m  0.0440\n",
      "     12        \u001b[36m0.6959\u001b[0m       0.4762        \u001b[35m0.6971\u001b[0m  0.0500\n",
      "     13        \u001b[36m0.6953\u001b[0m       0.4762        \u001b[35m0.6968\u001b[0m  0.0498\n",
      "     14        \u001b[36m0.6947\u001b[0m       0.4762        \u001b[35m0.6965\u001b[0m  0.0516\n",
      "     15        \u001b[36m0.6940\u001b[0m       0.4762        \u001b[35m0.6962\u001b[0m  0.0502\n",
      "     16        \u001b[36m0.6934\u001b[0m       0.4762        \u001b[35m0.6959\u001b[0m  0.0399\n",
      "     17        \u001b[36m0.6927\u001b[0m       0.4762        \u001b[35m0.6956\u001b[0m  0.0440\n",
      "     18        \u001b[36m0.6920\u001b[0m       0.4762        \u001b[35m0.6954\u001b[0m  0.0402\n",
      "     19        \u001b[36m0.6912\u001b[0m       0.4762        \u001b[35m0.6951\u001b[0m  0.0430\n",
      "     20        \u001b[36m0.6904\u001b[0m       0.4762        \u001b[35m0.6948\u001b[0m  0.0443\n",
      "     21        \u001b[36m0.6895\u001b[0m       0.4762        \u001b[35m0.6945\u001b[0m  0.0406\n",
      "     22        \u001b[36m0.6886\u001b[0m       0.4762        \u001b[35m0.6942\u001b[0m  0.0455\n",
      "     23        \u001b[36m0.6876\u001b[0m       0.4762        \u001b[35m0.6939\u001b[0m  0.0396\n",
      "     24        \u001b[36m0.6867\u001b[0m       0.4762        \u001b[35m0.6936\u001b[0m  0.0433\n",
      "     25        \u001b[36m0.6857\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6934\u001b[0m  0.0493\n",
      "     26        \u001b[36m0.6846\u001b[0m       0.5000        \u001b[35m0.6932\u001b[0m  0.0429\n",
      "     27        \u001b[36m0.6836\u001b[0m       0.4762        \u001b[35m0.6930\u001b[0m  0.0398\n",
      "     28        \u001b[36m0.6824\u001b[0m       0.5000        \u001b[35m0.6927\u001b[0m  0.0486\n",
      "     29        \u001b[36m0.6811\u001b[0m       0.5000        \u001b[35m0.6926\u001b[0m  0.0414\n",
      "     30        \u001b[36m0.6797\u001b[0m       \u001b[32m0.5476\u001b[0m        \u001b[35m0.6925\u001b[0m  0.0399\n",
      "     31        \u001b[36m0.6783\u001b[0m       0.5000        \u001b[35m0.6923\u001b[0m  0.0388\n",
      "     32        \u001b[36m0.6765\u001b[0m       0.5000        \u001b[35m0.6920\u001b[0m  0.0480\n",
      "     33        \u001b[36m0.6748\u001b[0m       0.5476        \u001b[35m0.6918\u001b[0m  0.0426\n",
      "     34        \u001b[36m0.6730\u001b[0m       \u001b[32m0.5714\u001b[0m        \u001b[35m0.6915\u001b[0m  0.0513\n",
      "     35        \u001b[36m0.6709\u001b[0m       0.5476        \u001b[35m0.6911\u001b[0m  0.0498\n",
      "     36        \u001b[36m0.6688\u001b[0m       \u001b[32m0.5952\u001b[0m        \u001b[35m0.6908\u001b[0m  0.0845\n",
      "     37        \u001b[36m0.6668\u001b[0m       0.5952        \u001b[35m0.6906\u001b[0m  0.0420\n",
      "     38        \u001b[36m0.6648\u001b[0m       0.5952        \u001b[35m0.6904\u001b[0m  0.0429\n",
      "     39        \u001b[36m0.6626\u001b[0m       0.5952        \u001b[35m0.6904\u001b[0m  0.0579\n",
      "     40        \u001b[36m0.6604\u001b[0m       0.5952        \u001b[35m0.6904\u001b[0m  0.0505\n",
      "     41        \u001b[36m0.6580\u001b[0m       0.5952        \u001b[35m0.6904\u001b[0m  0.0419\n",
      "     42        \u001b[36m0.6556\u001b[0m       0.5952        0.6904  0.0503\n",
      "     43        \u001b[36m0.6530\u001b[0m       0.5952        0.6904  0.0434\n",
      "     44        \u001b[36m0.6504\u001b[0m       0.5952        0.6904  0.0418\n",
      "     45        \u001b[36m0.6476\u001b[0m       0.5714        0.6904  0.0394\n",
      "     46        \u001b[36m0.6447\u001b[0m       0.5714        0.6904  0.0460\n",
      "     47        \u001b[36m0.6418\u001b[0m       0.5714        0.6904  0.0501\n",
      "     48        \u001b[36m0.6387\u001b[0m       0.5714        0.6904  0.0501\n",
      "     49        \u001b[36m0.6353\u001b[0m       0.5714        0.6905  0.0496\n",
      "     50        \u001b[36m0.6317\u001b[0m       0.5476        0.6907  0.0401\n",
      "     51        \u001b[36m0.6280\u001b[0m       0.5476        0.6909  0.0498\n",
      "     52        \u001b[36m0.6242\u001b[0m       0.5476        0.6912  0.0499\n",
      "     53        \u001b[36m0.6202\u001b[0m       0.5714        0.6914  0.0346\n",
      "     54        \u001b[36m0.6163\u001b[0m       0.5476        0.6916  0.0332\n",
      "     55        \u001b[36m0.6122\u001b[0m       0.5476        0.6919  0.0403\n",
      "     56        \u001b[36m0.6080\u001b[0m       0.5476        0.6923  0.0466\n",
      "     57        \u001b[36m0.6037\u001b[0m       0.5476        0.6927  0.0570\n",
      "     58        \u001b[36m0.5993\u001b[0m       0.5476        0.6931  0.0467\n",
      "     59        \u001b[36m0.5947\u001b[0m       0.5476        0.6935  0.0404\n",
      "     60        \u001b[36m0.5901\u001b[0m       0.5238        0.6941  0.1105\n",
      "     61        \u001b[36m0.5852\u001b[0m       0.5238        0.6947  0.0493\n",
      "     62        \u001b[36m0.5804\u001b[0m       0.5238        0.6954  0.0509\n",
      "     63        \u001b[36m0.5754\u001b[0m       0.5238        0.6963  0.0540\n",
      "     64        \u001b[36m0.5703\u001b[0m       0.5238        0.6973  0.0449\n",
      "     65        \u001b[36m0.5651\u001b[0m       0.5238        0.6985  0.0501\n",
      "     66        \u001b[36m0.5598\u001b[0m       0.5238        0.6997  0.0387\n",
      "     67        \u001b[36m0.5545\u001b[0m       0.5476        0.7010  0.0445\n",
      "     68        \u001b[36m0.5491\u001b[0m       0.5476        0.7024  0.0506\n",
      "     69        \u001b[36m0.5437\u001b[0m       0.5476        0.7039  0.0383\n",
      "     70        \u001b[36m0.5381\u001b[0m       0.5238        0.7055  0.0406\n",
      "     71        \u001b[36m0.5326\u001b[0m       0.5238        0.7072  0.0464\n",
      "     72        \u001b[36m0.5271\u001b[0m       0.5238        0.7090  0.0398\n",
      "     73        \u001b[36m0.5215\u001b[0m       0.5238        0.7108  0.0437\n",
      "     74        \u001b[36m0.5158\u001b[0m       0.5238        0.7126  0.0500\n",
      "     75        \u001b[36m0.5100\u001b[0m       0.5238        0.7148  0.0498\n",
      "     76        \u001b[36m0.5039\u001b[0m       0.5000        0.7174  0.0446\n",
      "     77        \u001b[36m0.4977\u001b[0m       0.5000        0.7203  0.0501\n",
      "     78        \u001b[36m0.4911\u001b[0m       0.5000        0.7229  0.0380\n",
      "     79        \u001b[36m0.4848\u001b[0m       0.5238        0.7256  0.0453\n",
      "     80        \u001b[36m0.4785\u001b[0m       0.5238        0.7283  0.0483\n",
      "     81        \u001b[36m0.4725\u001b[0m       0.5238        0.7310  0.0461\n",
      "     82        \u001b[36m0.4667\u001b[0m       0.5238        0.7339  0.0499\n",
      "     83        \u001b[36m0.4609\u001b[0m       0.5238        0.7369  0.0376\n",
      "     84        \u001b[36m0.4552\u001b[0m       0.5000        0.7399  0.0419\n",
      "     85        \u001b[36m0.4495\u001b[0m       0.5000        0.7432  0.0348\n",
      "     86        \u001b[36m0.4440\u001b[0m       0.4762        0.7466  0.0334\n",
      "     87        \u001b[36m0.4385\u001b[0m       0.4762        0.7503  0.0326\n",
      "     88        \u001b[36m0.4333\u001b[0m       0.4762        0.7540  0.0386\n",
      "     89        \u001b[36m0.4280\u001b[0m       0.4762        0.7579  0.0361\n",
      "     90        \u001b[36m0.4230\u001b[0m       0.4762        0.7619  0.0421\n",
      "     91        \u001b[36m0.4180\u001b[0m       0.4762        0.7660  0.0405\n",
      "     92        \u001b[36m0.4131\u001b[0m       0.4762        0.7705  0.0428\n",
      "     93        \u001b[36m0.4083\u001b[0m       0.4762        0.7749  0.0393\n",
      "     94        \u001b[36m0.4036\u001b[0m       0.4762        0.7795  0.0441\n",
      "     95        \u001b[36m0.3989\u001b[0m       0.4762        0.7842  0.0398\n",
      "     96        \u001b[36m0.3942\u001b[0m       0.4762        0.7889  0.0437\n",
      "     97        \u001b[36m0.3897\u001b[0m       0.4762        0.7939  0.0504\n",
      "     98        \u001b[36m0.3852\u001b[0m       0.4762        0.7989  0.0588\n",
      "     99        \u001b[36m0.3809\u001b[0m       0.4524        0.8038  0.0400\n",
      "    100        \u001b[36m0.3766\u001b[0m       0.4524        0.8089  0.0353\n",
      "    101        \u001b[36m0.3726\u001b[0m       0.4524        0.8139  0.0357\n",
      "    102        \u001b[36m0.3687\u001b[0m       0.4524        0.8191  0.0405\n",
      "    103        \u001b[36m0.3648\u001b[0m       0.4524        0.8242  0.0438\n",
      "    104        \u001b[36m0.3611\u001b[0m       0.4524        0.8294  0.0397\n",
      "    105        \u001b[36m0.3574\u001b[0m       0.4524        0.8346  0.0385\n",
      "    106        \u001b[36m0.3538\u001b[0m       0.4524        0.8398  0.0449\n",
      "    107        \u001b[36m0.3501\u001b[0m       0.4524        0.8449  0.0564\n",
      "    108        \u001b[36m0.3468\u001b[0m       0.4524        0.8501  0.0437\n",
      "    109        \u001b[36m0.3436\u001b[0m       0.4524        0.8554  0.0426\n",
      "    110        \u001b[36m0.3403\u001b[0m       0.4524        0.8607  0.0401\n",
      "    111        \u001b[36m0.3370\u001b[0m       0.4524        0.8659  0.0432\n",
      "    112        \u001b[36m0.3339\u001b[0m       0.4524        0.8712  0.0398\n",
      "    113        \u001b[36m0.3309\u001b[0m       0.4524        0.8765  0.0437\n",
      "    114        \u001b[36m0.3279\u001b[0m       0.4524        0.8816  0.0406\n",
      "    115        \u001b[36m0.3249\u001b[0m       0.4524        0.8869  0.0427\n",
      "    116        \u001b[36m0.3221\u001b[0m       0.4524        0.8923  0.0509\n",
      "    117        \u001b[36m0.3193\u001b[0m       0.4524        0.8975  0.1099\n",
      "    118        \u001b[36m0.3166\u001b[0m       0.4524        0.9026  0.0582\n",
      "    119        \u001b[36m0.3140\u001b[0m       0.4286        0.9076  0.0636\n",
      "    120        \u001b[36m0.3114\u001b[0m       0.4286        0.9126  0.0572\n",
      "    121        \u001b[36m0.3089\u001b[0m       0.4286        0.9174  0.0605\n",
      "    122        \u001b[36m0.3065\u001b[0m       0.4286        0.9224  0.0518\n",
      "    123        \u001b[36m0.3041\u001b[0m       0.4286        0.9276  0.0501\n",
      "    124        \u001b[36m0.3017\u001b[0m       0.4286        0.9327  0.0479\n",
      "    125        \u001b[36m0.2994\u001b[0m       0.4286        0.9376  0.0389\n",
      "    126        \u001b[36m0.2972\u001b[0m       0.4286        0.9428  0.0405\n",
      "    127        \u001b[36m0.2950\u001b[0m       0.4286        0.9477  0.0410\n",
      "    128        \u001b[36m0.2927\u001b[0m       0.4286        0.9526  0.0376\n",
      "    129        \u001b[36m0.2906\u001b[0m       0.4286        0.9573  0.0422\n",
      "    130        \u001b[36m0.2885\u001b[0m       0.4286        0.9623  0.0392\n",
      "    131        \u001b[36m0.2864\u001b[0m       0.4286        0.9671  0.0440\n",
      "    132        \u001b[36m0.2844\u001b[0m       0.4286        0.9717  0.0397\n",
      "    133        \u001b[36m0.2824\u001b[0m       0.4286        0.9762  0.0435\n",
      "    134        \u001b[36m0.2805\u001b[0m       0.4286        0.9810  0.0398\n",
      "    135        \u001b[36m0.2786\u001b[0m       0.4286        0.9857  0.0437\n",
      "    136        \u001b[36m0.2766\u001b[0m       0.4286        0.9903  0.0400\n",
      "    137        \u001b[36m0.2748\u001b[0m       0.4286        0.9950  0.0447\n",
      "    138        \u001b[36m0.2730\u001b[0m       0.4286        0.9993  0.0387\n",
      "    139        \u001b[36m0.2712\u001b[0m       0.4286        1.0038  0.0432\n",
      "    140        \u001b[36m0.2695\u001b[0m       0.4286        1.0081  0.0401\n",
      "    141        \u001b[36m0.2676\u001b[0m       0.4286        1.0120  0.0568\n",
      "    142        \u001b[36m0.2660\u001b[0m       0.4286        1.0160  0.0479\n",
      "    143        \u001b[36m0.2644\u001b[0m       0.4286        1.0202  0.0412\n",
      "    144        \u001b[36m0.2627\u001b[0m       0.4286        1.0244  0.0326\n",
      "    145        \u001b[36m0.2610\u001b[0m       0.4286        1.0285  0.0332\n",
      "    146        \u001b[36m0.2594\u001b[0m       0.4286        1.0329  0.0355\n",
      "    147        \u001b[36m0.2579\u001b[0m       0.4286        1.0370  0.0344\n",
      "    148        \u001b[36m0.2564\u001b[0m       0.4286        1.0411  0.0330\n",
      "    149        \u001b[36m0.2548\u001b[0m       0.4286        1.0453  0.0346\n",
      "    150        \u001b[36m0.2534\u001b[0m       0.4286        1.0496  0.0406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetBinaryClassifier'>[initialized](\n",
       "  module_=SonarClassifier(\n",
       "    (layer1): Linear(in_features=60, out_features=60, bias=True)\n",
       "    (act1): ReLU()\n",
       "    (layer2): Linear(in_features=60, out_features=60, bias=True)\n",
       "    (act2): ReLU()\n",
       "    (layer3): Linear(in_features=60, out_features=60, bias=True)\n",
       "    (act3): ReLU()\n",
       "    (output): Linear(in_features=60, out_features=1, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from skorch import NeuralNetBinaryClassifier\n",
    "\n",
    "# Read data\n",
    "data = pd.read_csv(\"sonar.csv\", header=None)\n",
    "X = data.iloc[:, 0:60]\n",
    "y = data.iloc[:, 60]\n",
    "\n",
    "# Binary encoding of labels\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y)\n",
    "\n",
    "# Convert to 2D PyTorch tensors\n",
    "X = torch.tensor(X.values, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# Define the model\n",
    "class SonarClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(60, 60)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(60, 60)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.layer3 = nn.Linear(60, 60)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.output = nn.Linear(60, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.layer1(x))\n",
    "        x = self.act2(self.layer2(x))\n",
    "        x = self.act3(self.layer3(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# create the skorch wrapper\n",
    "model = NeuralNetBinaryClassifier(\n",
    "    SonarClassifier,\n",
    "    criterion=torch.nn.BCEWithLogitsLoss,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    lr=0.0001,\n",
    "    max_epochs=150,\n",
    "    batch_size=10\n",
    ")\n",
    "\n",
    "# run\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85200a36-fd6f-427d-b785-04d655fa8aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80952381 0.61904762 0.76190476 0.75609756 0.82926829]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from skorch import NeuralNetBinaryClassifier\n",
    "\n",
    "# Read data\n",
    "data = pd.read_csv(\"sonar.csv\", header=None)\n",
    "X = data.iloc[:, 0:60]\n",
    "y = data.iloc[:, 60]\n",
    "\n",
    "# Binary encoding of labels\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y)\n",
    "\n",
    "# Convert to 2D PyTorch tensors\n",
    "X = torch.tensor(X.values, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# Define the model\n",
    "class SonarClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(60, 60)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(60, 60)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.layer3 = nn.Linear(60, 60)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.output = nn.Linear(60, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.layer1(x))\n",
    "        x = self.act2(self.layer2(x))\n",
    "        x = self.act3(self.layer3(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = NeuralNetBinaryClassifier(\n",
    "    SonarClassifier,\n",
    "    criterion=torch.nn.BCEWithLogitsLoss,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    lr=0.0001,\n",
    "    max_epochs=150,\n",
    "    batch_size=10,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "results = cross_val_score(model, X, y, cv=kfold)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a355b03b-4657-497d-a5a7-ee6634d42657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean = 0.721; std = 0.050\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from skorch import NeuralNetBinaryClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "# Read data\n",
    "data = pd.read_csv(\"sonar.csv\", header=None)\n",
    "X = data.iloc[:, 0:60]\n",
    "y = data.iloc[:, 60]\n",
    "\n",
    "# Binary encoding of labels\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y)\n",
    "\n",
    "# Convert to 2D PyTorch tensors\n",
    "X = torch.tensor(X.values, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# Define the model\n",
    "class SonarClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(60, 60)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(60, 60)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.layer3 = nn.Linear(60, 60)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.output = nn.Linear(60, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.layer1(x))\n",
    "        x = self.act2(self.layer2(x))\n",
    "        x = self.act3(self.layer3(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# create the skorch wrapper\n",
    "model = NeuralNetBinaryClassifier(\n",
    "    SonarClassifier,\n",
    "    criterion=torch.nn.BCEWithLogitsLoss,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    lr=0.0001,\n",
    "    max_epochs=150,\n",
    "    batch_size=10,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# k-fold\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "results = cross_val_score(model, X, y, cv=kfold)\n",
    "print(\"mean = %.3f; std = %.3f\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3427da8c-37a0-46bc-844c-84c23a567a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean = 0.860; std = 0.050\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# load dataset\n",
    "data = pd.read_csv(\"sonar.csv\", header=None)\n",
    "# split into input (X) and output (Y) variables, in numpy arrays\n",
    "X = data.iloc[:, 0:60].values\n",
    "y = data.iloc[:, 60].values\n",
    "\n",
    "# binary encoding of labels\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y)\n",
    "\n",
    "# create model\n",
    "model = MLPClassifier(hidden_layer_sizes=(60,60,60), activation='relu',\n",
    "                      max_iter=150, batch_size=10, verbose=False)\n",
    "\n",
    "# evaluate using 10-fold cross validation\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "results = cross_val_score(model, X, y, cv=kfold)\n",
    "print(\"mean = %.3f; std = %.3f\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32250dcd-23eb-4a51-8475-a89c3751fa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SonarClassifier(nn.Module):\n",
    "    def __init__(self, n_layers=3):\n",
    "        super().__init__()\n",
    "        self.layers = []\n",
    "        self.acts = []\n",
    "        for i in range(n_layers):\n",
    "            self.layers.append(nn.Linear(60, 60))\n",
    "            self.acts.append(nn.ReLU())\n",
    "            self.add_module(f\"layer{i}\", self.layers[-1])\n",
    "            self.add_module(f\"act{i}\", self.acts[-1])\n",
    "        self.output = nn.Linear(60, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer, act in zip(self.layers, self.acts):\n",
    "            x = act(layer(x))\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60b39ca3-c720-4507-bc0b-5b00cf73985a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "Best: 0.630090 using {'lr': 0.01, 'max_epochs': 100, 'module__n_layers': 1}\n",
      "0.533678 (0.003611) with: {'lr': 0.1, 'max_epochs': 100, 'module__n_layers': 1}\n",
      "0.533678 (0.003611) with: {'lr': 0.1, 'max_epochs': 100, 'module__n_layers': 3}\n",
      "0.533678 (0.003611) with: {'lr': 0.1, 'max_epochs': 100, 'module__n_layers': 5}\n",
      "0.533678 (0.003611) with: {'lr': 0.1, 'max_epochs': 150, 'module__n_layers': 1}\n",
      "0.533678 (0.003611) with: {'lr': 0.1, 'max_epochs': 150, 'module__n_layers': 3}\n",
      "0.533678 (0.003611) with: {'lr': 0.1, 'max_epochs': 150, 'module__n_layers': 5}\n",
      "0.630090 (0.041900) with: {'lr': 0.01, 'max_epochs': 100, 'module__n_layers': 1}\n",
      "0.562664 (0.042911) with: {'lr': 0.01, 'max_epochs': 100, 'module__n_layers': 3}\n",
      "0.533678 (0.003611) with: {'lr': 0.01, 'max_epochs': 100, 'module__n_layers': 5}\n",
      "0.610973 (0.059456) with: {'lr': 0.01, 'max_epochs': 150, 'module__n_layers': 1}\n",
      "0.557488 (0.030061) with: {'lr': 0.01, 'max_epochs': 150, 'module__n_layers': 3}\n",
      "0.533678 (0.003611) with: {'lr': 0.01, 'max_epochs': 150, 'module__n_layers': 5}\n",
      "0.616149 (0.114898) with: {'lr': 0.001, 'max_epochs': 100, 'module__n_layers': 1}\n",
      "0.563147 (0.095343) with: {'lr': 0.001, 'max_epochs': 100, 'module__n_layers': 3}\n",
      "0.582195 (0.070493) with: {'lr': 0.001, 'max_epochs': 100, 'module__n_layers': 5}\n",
      "0.625535 (0.079550) with: {'lr': 0.001, 'max_epochs': 150, 'module__n_layers': 1}\n",
      "0.601104 (0.021802) with: {'lr': 0.001, 'max_epochs': 150, 'module__n_layers': 3}\n",
      "0.586888 (0.062416) with: {'lr': 0.001, 'max_epochs': 150, 'module__n_layers': 5}\n",
      "0.562526 (0.023971) with: {'lr': 0.0001, 'max_epochs': 100, 'module__n_layers': 1}\n",
      "0.558109 (0.089401) with: {'lr': 0.0001, 'max_epochs': 100, 'module__n_layers': 3}\n",
      "0.562802 (0.045957) with: {'lr': 0.0001, 'max_epochs': 100, 'module__n_layers': 5}\n",
      "0.529262 (0.067882) with: {'lr': 0.0001, 'max_epochs': 150, 'module__n_layers': 1}\n",
      "0.591856 (0.080674) with: {'lr': 0.0001, 'max_epochs': 150, 'module__n_layers': 3}\n",
      "0.557902 (0.033034) with: {'lr': 0.0001, 'max_epochs': 150, 'module__n_layers': 5}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from skorch import NeuralNetBinaryClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Read data\n",
    "data = pd.read_csv(\"sonar.csv\", header=None)\n",
    "X = data.iloc[:, 0:60]\n",
    "y = data.iloc[:, 60]\n",
    "\n",
    "# Binary encoding of labels\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y)\n",
    "\n",
    "# Convert to 2D PyTorch tensors\n",
    "X = torch.tensor(X.values, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# Define the model\n",
    "class SonarClassifier(nn.Module):\n",
    "    def __init__(self, n_layers=3):\n",
    "        super().__init__()\n",
    "        self.layers = []\n",
    "        self.acts = []\n",
    "        for i in range(n_layers):\n",
    "            self.layers.append(nn.Linear(60, 60))\n",
    "            self.acts.append(nn.ReLU())\n",
    "            self.add_module(f\"layer{i}\", self.layers[-1])\n",
    "            self.add_module(f\"act{i}\", self.acts[-1])\n",
    "        self.output = nn.Linear(60, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer, act in zip(self.layers, self.acts):\n",
    "            x = act(layer(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "model = NeuralNetBinaryClassifier(\n",
    "    SonarClassifier,\n",
    "    criterion=torch.nn.BCEWithLogitsLoss,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    lr=0.0001,\n",
    "    max_epochs=150,\n",
    "    batch_size=10,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'module__n_layers': [1, 3, 5],\n",
    "    'lr': [0.1, 0.01, 0.001, 0.0001],\n",
    "    'max_epochs': [100, 150],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, scoring='accuracy', verbose=1, cv=3)\n",
    "result = grid_search.fit(X, y)\n",
    "\n",
    "print(\"Best: %f using %s\" % (result.best_score_, result.best_params_))\n",
    "means = result.cv_results_['mean_test_score']\n",
    "stds = result.cv_results_['std_test_score']\n",
    "params = result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91c9f346-58b6-4a3d-bd6b-d6a56018fb66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "Best: 0.577502 using {'sonarmodel__lr': 0.0001, 'sonarmodel__max_epochs': 100, 'sonarmodel__module__n_layers': 1}\n",
      "0.543892 (0.092407) with: {'sonarmodel__lr': 0.1, 'sonarmodel__max_epochs': 100, 'sonarmodel__module__n_layers': 1}\n",
      "0.577433 (0.107399) with: {'sonarmodel__lr': 0.1, 'sonarmodel__max_epochs': 100, 'sonarmodel__module__n_layers': 3}\n",
      "0.533678 (0.003611) with: {'sonarmodel__lr': 0.1, 'sonarmodel__max_epochs': 100, 'sonarmodel__module__n_layers': 5}\n",
      "0.524845 (0.119172) with: {'sonarmodel__lr': 0.1, 'sonarmodel__max_epochs': 150, 'sonarmodel__module__n_layers': 1}\n",
      "0.519393 (0.023814) with: {'sonarmodel__lr': 0.1, 'sonarmodel__max_epochs': 150, 'sonarmodel__module__n_layers': 3}\n",
      "0.490200 (0.049513) with: {'sonarmodel__lr': 0.1, 'sonarmodel__max_epochs': 150, 'sonarmodel__module__n_layers': 5}\n",
      "0.558316 (0.098372) with: {'sonarmodel__lr': 0.01, 'sonarmodel__max_epochs': 100, 'sonarmodel__module__n_layers': 1}\n",
      "0.577295 (0.076307) with: {'sonarmodel__lr': 0.01, 'sonarmodel__max_epochs': 100, 'sonarmodel__module__n_layers': 3}\n",
      "0.553278 (0.062528) with: {'sonarmodel__lr': 0.01, 'sonarmodel__max_epochs': 100, 'sonarmodel__module__n_layers': 5}\n",
      "0.539061 (0.093057) with: {'sonarmodel__lr': 0.01, 'sonarmodel__max_epochs': 150, 'sonarmodel__module__n_layers': 1}\n",
      "0.563078 (0.097298) with: {'sonarmodel__lr': 0.01, 'sonarmodel__max_epochs': 150, 'sonarmodel__module__n_layers': 3}\n",
      "0.563147 (0.099652) with: {'sonarmodel__lr': 0.01, 'sonarmodel__max_epochs': 150, 'sonarmodel__module__n_layers': 5}\n",
      "0.553623 (0.112584) with: {'sonarmodel__lr': 0.001, 'sonarmodel__max_epochs': 100, 'sonarmodel__module__n_layers': 1}\n",
      "0.553554 (0.099186) with: {'sonarmodel__lr': 0.001, 'sonarmodel__max_epochs': 100, 'sonarmodel__module__n_layers': 3}\n",
      "0.529538 (0.103236) with: {'sonarmodel__lr': 0.001, 'sonarmodel__max_epochs': 100, 'sonarmodel__module__n_layers': 5}\n",
      "0.543961 (0.103332) with: {'sonarmodel__lr': 0.001, 'sonarmodel__max_epochs': 150, 'sonarmodel__module__n_layers': 1}\n",
      "0.534369 (0.105114) with: {'sonarmodel__lr': 0.001, 'sonarmodel__max_epochs': 150, 'sonarmodel__module__n_layers': 3}\n",
      "0.529400 (0.083311) with: {'sonarmodel__lr': 0.001, 'sonarmodel__max_epochs': 150, 'sonarmodel__module__n_layers': 5}\n",
      "0.577502 (0.097384) with: {'sonarmodel__lr': 0.0001, 'sonarmodel__max_epochs': 100, 'sonarmodel__module__n_layers': 1}\n",
      "0.558454 (0.126706) with: {'sonarmodel__lr': 0.0001, 'sonarmodel__max_epochs': 100, 'sonarmodel__module__n_layers': 3}\n",
      "0.563078 (0.088242) with: {'sonarmodel__lr': 0.0001, 'sonarmodel__max_epochs': 100, 'sonarmodel__module__n_layers': 5}\n",
      "0.577502 (0.103652) with: {'sonarmodel__lr': 0.0001, 'sonarmodel__max_epochs': 150, 'sonarmodel__module__n_layers': 1}\n",
      "0.558592 (0.134444) with: {'sonarmodel__lr': 0.0001, 'sonarmodel__max_epochs': 150, 'sonarmodel__module__n_layers': 3}\n",
      "0.539130 (0.101187) with: {'sonarmodel__lr': 0.0001, 'sonarmodel__max_epochs': 150, 'sonarmodel__module__n_layers': 5}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, FunctionTransformer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from skorch import NeuralNetBinaryClassifier\n",
    "\n",
    "# Read data\n",
    "data = pd.read_csv(\"sonar.csv\", header=None)\n",
    "X = data.iloc[:, 0:60]\n",
    "y = data.iloc[:, 60]\n",
    "\n",
    "# Binary encoding of labels\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y)\n",
    "\n",
    "# Convert to 2D PyTorch tensors\n",
    "X = torch.tensor(X.values, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "\n",
    "class SonarClassifier(nn.Module):\n",
    "    def __init__(self, n_layers=3):\n",
    "        super().__init__()\n",
    "        self.layers = []\n",
    "        self.acts = []\n",
    "        for i in range(n_layers):\n",
    "            self.layers.append(nn.Linear(60, 60))\n",
    "            self.acts.append(nn.ReLU())\n",
    "            self.add_module(f\"layer{i}\", self.layers[-1])\n",
    "            self.add_module(f\"act{i}\", self.acts[-1])\n",
    "        self.output = nn.Linear(60, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer, act in zip(self.layers, self.acts):\n",
    "            x = act(layer(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "model = NeuralNetBinaryClassifier(\n",
    "    SonarClassifier,\n",
    "    criterion=torch.nn.BCEWithLogitsLoss,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    lr=0.0001,\n",
    "    max_epochs=150,\n",
    "    batch_size=10,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('float32', FunctionTransformer(func=lambda X: torch.tensor(X, dtype=torch.float32),\n",
    "                                    validate=False)),\n",
    "    ('sonarmodel', model.initialize()),\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'sonarmodel__module__n_layers': [1, 3, 5],\n",
    "    'sonarmodel__lr': [0.1, 0.01, 0.001, 0.0001],\n",
    "    'sonarmodel__max_epochs': [100, 150],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid, scoring='accuracy', verbose=1, cv=3)\n",
    "result = grid_search.fit(X, y)\n",
    "print(\"Best: %f using %s\" % (result.best_score_, result.best_params_))\n",
    "means = result.cv_results_['mean_test_score']\n",
    "stds = result.cv_results_['std_test_score']\n",
    "params = result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
