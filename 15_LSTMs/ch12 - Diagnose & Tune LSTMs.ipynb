{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good-Fit Diagnostic\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from matplotlib import pyplot\n",
    "from numpy import array\n",
    "\n",
    "# return training data\n",
    "def get_train():\n",
    "\tseq = [[0.0, 0.1], [0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((5, 1, 1))\n",
    "\treturn X, y\n",
    "\n",
    "# return validation data\n",
    "def get_val():\n",
    "\tseq = [[0.5, 0.6], [0.6, 0.7], [0.7, 0.8], [0.8, 0.9], [0.9, 1.0]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((len(X), 1, 1))\n",
    "\treturn X, y\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(10, input_shape=(1,1)))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# fit model\n",
    "X,y = get_train()\n",
    "valX, valY = get_val()\n",
    "history = model.fit(X, y, epochs=800, validation_data=(valX, valY), shuffle=False)\n",
    "\n",
    "# plot train and validation loss\n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic Multiple\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from matplotlib import pyplot\n",
    "from numpy import array\n",
    "from pandas import DataFrame\n",
    "\n",
    "# return training data\n",
    "def get_train():\n",
    "\tseq = [[0.0, 0.1], [0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((5, 1, 1))\n",
    "\treturn X, y\n",
    "\n",
    "# return validation data\n",
    "def get_val():\n",
    "\tseq = [[0.5, 0.6], [0.6, 0.7], [0.7, 0.8], [0.8, 0.9], [0.9, 1.0]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((len(X), 1, 1))\n",
    "\treturn X, y\n",
    "\n",
    "# collect data across multiple repeats\n",
    "train = DataFrame()\n",
    "val = DataFrame()\n",
    "for i in range(5):\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(10, input_shape=(1,1)))\n",
    "\tmodel.add(Dense(1, activation='linear'))\n",
    "\t# compile model\n",
    "\tmodel.compile(loss='mse', optimizer='adam')\n",
    "\tX,y = get_train()\n",
    "\tvalX, valY = get_val()\n",
    "\t# fit model\n",
    "\thistory = model.fit(X, y, epochs=300, validation_data=(valX, valY), shuffle=False)\n",
    "\t# story history\n",
    "\ttrain[str(i)] = history.history['loss']\n",
    "\tval[str(i)] = history.history['val_loss']\n",
    "\n",
    "# plot train and validation loss across multiple runs\n",
    "pyplot.plot(train, color='blue', label='train')\n",
    "pyplot.plot(val, color='orange', label='validation')\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic Overfit\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from matplotlib import pyplot\n",
    "from numpy import array\n",
    "\n",
    "# return training data\n",
    "def get_train():\n",
    "\tseq = [[0.0, 0.1], [0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((5, 1, 1))\n",
    "\treturn X, y\n",
    "\n",
    "# return validation data\n",
    "def get_val():\n",
    "\tseq = [[0.5, 0.6], [0.6, 0.7], [0.7, 0.8], [0.8, 0.9], [0.9, 1.0]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((len(X), 1, 1))\n",
    "\treturn X, y\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(10, input_shape=(1,1)))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# fit model\n",
    "X,y = get_train()\n",
    "valX, valY = get_val()\n",
    "history = model.fit(X, y, epochs=1200, validation_data=(valX, valY), shuffle=False)\n",
    "\n",
    "# plot train and validation loss\n",
    "pyplot.plot(history.history['loss'][500:])\n",
    "pyplot.plot(history.history['val_loss'][500:])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic Underfit 1\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from matplotlib import pyplot\n",
    "from numpy import array\n",
    "\n",
    "# return training data\n",
    "def get_train():\n",
    "\tseq = [[0.0, 0.1], [0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((len(X), 1, 1))\n",
    "\treturn X, y\n",
    "\n",
    "# return validation data\n",
    "def get_val():\n",
    "\tseq = [[0.5, 0.6], [0.6, 0.7], [0.7, 0.8], [0.8, 0.9], [0.9, 1.0]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((len(X), 1, 1))\n",
    "\treturn X, y\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(10, input_shape=(1,1)))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# fit model\n",
    "X,y = get_train()\n",
    "valX, valY = get_val()\n",
    "history = model.fit(X, y, epochs=100, validation_data=(valX, valY), shuffle=False)\n",
    "\n",
    "# plot train and validation loss\n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic Underfit 2\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from matplotlib import pyplot\n",
    "from numpy import array\n",
    "\n",
    "# return training data\n",
    "def get_train():\n",
    "\tseq = [[0.0, 0.1], [0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((5, 1, 1))\n",
    "\treturn X, y\n",
    "\n",
    "# return validation data\n",
    "def get_val():\n",
    "\tseq = [[0.5, 0.6], [0.6, 0.7], [0.7, 0.8], [0.8, 0.9], [0.9, 1.0]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((len(X), 1, 1))\n",
    "\treturn X, y\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(1, input_shape=(1,1)))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='mae', optimizer='sgd')\n",
    "\n",
    "# fit model\n",
    "X,y = get_train()\n",
    "valX, valY = get_val()\n",
    "history = model.fit(X, y, epochs=300, validation_data=(valX, valY), shuffle=False)\n",
    "\n",
    "# plot train and validation loss\n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune Batch Size\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from matplotlib import pyplot\n",
    "from pandas import DataFrame\n",
    "from numpy import array\n",
    "\n",
    "# return training data\n",
    "def get_train():\n",
    "\tseq = [[0.0, 0.1], [0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((5, 1, 1))\n",
    "\treturn X, y\n",
    "\n",
    "# return validation data\n",
    "def get_val():\n",
    "\tseq = [[0.5, 0.6], [0.6, 0.7], [0.7, 0.8], [0.8, 0.9], [0.9, 1.0]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((len(X), 1, 1))\n",
    "\treturn X, y\n",
    "\n",
    "# fit an LSTM model\n",
    "def fit_model(n_batch):\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(10, input_shape=(1,1)))\n",
    "\tmodel.add(Dense(1, activation='linear'))\n",
    "\t# compile model\n",
    "\tmodel.compile(loss='mse', optimizer='adam')\n",
    "\t# fit model\n",
    "\tX,y = get_train()\n",
    "\tmodel.fit(X, y, epochs=500, shuffle=False, verbose=0, batch_size=n_batch)\n",
    "\t# evaluate model\n",
    "\tvalX, valY = get_val()\n",
    "\tloss = model.evaluate(valX, valY, verbose=0)\n",
    "\treturn loss\n",
    "\n",
    "# define scope of search\n",
    "params = [1, 2, 3]\n",
    "n_repeats = 5\n",
    "\n",
    "# grid search parameter values\n",
    "scores = DataFrame()\n",
    "for value in params:\n",
    "    \n",
    "\t# repeat each experiment multiple times\n",
    "\tloss_values = list()\n",
    "\tfor i in range(n_repeats):\n",
    "\t\tloss = fit_model(value)\n",
    "\t\tloss_values.append(loss)\n",
    "\t\tprint('>%d/%d param=%f, loss=%f' % (i+1, n_repeats, value, loss))\n",
    "        \n",
    "\t# store results for this parameter\n",
    "\tscores[str(value)] = loss_values\n",
    "    \n",
    "# summary statistics of results\n",
    "print(scores.describe())\n",
    "\n",
    "# box and whisker plot of results\n",
    "scores.boxplot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune Memory Cells\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from matplotlib import pyplot\n",
    "from pandas import DataFrame\n",
    "from numpy import array\n",
    "\n",
    "# return training data\n",
    "def get_train():\n",
    "\tseq = [[0.0, 0.1], [0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((5, 1, 1))\n",
    "\treturn X, y\n",
    "\n",
    "# return validation data\n",
    "def get_val():\n",
    "\tseq = [[0.5, 0.6], [0.6, 0.7], [0.7, 0.8], [0.8, 0.9], [0.9, 1.0]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((len(X), 1, 1))\n",
    "\treturn X, y\n",
    "\n",
    "# fit an LSTM model\n",
    "def fit_model(n_cells):\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(n_cells, input_shape=(1,1)))\n",
    "\tmodel.add(Dense(1, activation='linear'))\n",
    "\t# compile model\n",
    "\tmodel.compile(loss='mse', optimizer='adam')\n",
    "\t# fit model\n",
    "\tX,y = get_train()\n",
    "\tmodel.fit(X, y, epochs=500, shuffle=False, verbose=0)\n",
    "\t# evaluate model\n",
    "\tvalX, valY = get_val()\n",
    "\tloss = model.evaluate(valX, valY, verbose=0)\n",
    "\treturn loss\n",
    "\n",
    "# define scope of search\n",
    "params = [1, 5, 10]\n",
    "n_repeats = 5\n",
    "\n",
    "# grid search parameter values\n",
    "scores = DataFrame()\n",
    "for value in params:\n",
    "    \n",
    "\t# repeat each experiment multiple times\n",
    "\tloss_values = list()\n",
    "\tfor i in range(n_repeats):\n",
    "\t\tloss = fit_model(value)\n",
    "\t\tloss_values.append(loss)\n",
    "\t\tprint('>%d/%d param=%f, loss=%f' % (i+1, n_repeats, value, loss))\n",
    "        \n",
    "\t# store results for this parameter\n",
    "\tscores[str(value)] = loss_values\n",
    "    \n",
    "# summary statistics of results\n",
    "print(scores.describe())\n",
    "\n",
    "# box and whisker plot of results\n",
    "scores.boxplot()\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
