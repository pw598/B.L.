{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bi-directional LSTM\n",
    "\n",
    "from random import random\n",
    "from numpy import array\n",
    "from numpy import cumsum\n",
    "from numpy import array_equal\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "# create a cumulative sum sequence\n",
    "def get_sequence(n_timesteps):\n",
    "\t# create a sequence of random numbers in [0,1]\n",
    "\tX = array([random() for _ in range(n_timesteps)])\n",
    "\t# calculate cut-off value to change class values\n",
    "\tlimit = n_timesteps/4.0\n",
    "\t# determine the class outcome for each item in cumulative sequence\n",
    "\ty = array([0 if x < limit else 1 for x in cumsum(X)])\n",
    "\treturn X, y\n",
    "\n",
    "# create multiple samples of cumulative sum sequences\n",
    "def get_sequences(n_sequences, n_timesteps):\n",
    "\tseqX, seqY = list(), list()\n",
    "\t# create and store sequences\n",
    "\tfor _ in range(n_sequences):\n",
    "\t\tX, y = get_sequence(n_timesteps)\n",
    "\t\tseqX.append(X)\n",
    "\t\tseqY.append(y)\n",
    "\t# reshape input and output for lstm\n",
    "\tseqX = array(seqX).reshape(n_sequences, n_timesteps, 1)\n",
    "\tseqY = array(seqY).reshape(n_sequences, n_timesteps, 1)\n",
    "\treturn seqX, seqY\n",
    "\n",
    "# define problem\n",
    "n_timesteps = 10\n",
    "\n",
    "# define LSTM\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(50, return_sequences=True), input_shape=(n_timesteps, 1)))\n",
    "model.add(TimeDistributed(Dense(1, activation='sigmoid')))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# train LSTM\n",
    "X, y = get_sequences(50000, n_timesteps)\n",
    "model.fit(X, y, epochs=1, batch_size=10)\n",
    "\n",
    "# evaluate LSTM\n",
    "X, y = get_sequences(100, n_timesteps)\n",
    "loss, acc = model.evaluate(X, y, verbose=0)\n",
    "print('Loss: %f, Accuracy: %f' % (loss, acc*100))\n",
    "\n",
    "# make predictions\n",
    "for _ in range(10):\n",
    "\tX, y = get_sequences(1, n_timesteps)\n",
    "\tyhat = model.predict_classes(X, verbose=0)\n",
    "\texp, pred = y.reshape(n_timesteps), yhat.reshape(n_timesteps)\n",
    "\tprint('y=%s, yhat=%s, correct=%s' % (exp, pred, array_equal(exp,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem Sequence\n",
    "\n",
    "from random import random\n",
    "from numpy import array\n",
    "from numpy import cumsum\n",
    "\n",
    "# create a cumulative sum sequence\n",
    "def get_sequence(n_timesteps):\n",
    "\t# create a sequence of random numbers in [0,1]\n",
    "\tX = array([random() for _ in range(n_timesteps)])\n",
    "\t# calculate cut-off value to change class values\n",
    "\tlimit = n_timesteps/4.0\n",
    "\t# determine the class outcome for each item in cumulative sequence\n",
    "\ty = array([0 if x < limit else 1 for x in cumsum(X)])\n",
    "\treturn X, y\n",
    "\n",
    "X, y = get_sequence(10)\n",
    "print(X)\n",
    "print(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
