{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4a46d30-b1cf-4b12-9d3e-00d07da33d4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.12342868 -0.1517207   0.11690164 ... -0.3140937  -0.11770022\n",
      "    0.1524387 ]\n",
      "  [ 0.12166029 -0.14994533  0.11930789 ... -0.3141473  -0.11569785\n",
      "    0.15038218]\n",
      "  [ 0.12226799 -0.14896883  0.11866639 ... -0.31917274 -0.11556768\n",
      "    0.14930613]\n",
      "  [ 0.12199795 -0.14818028  0.11755744 ... -0.31680956 -0.11493171\n",
      "    0.14823413]\n",
      "  [ 0.12004336 -0.1518588   0.11710919 ... -0.31365025 -0.11433545\n",
      "    0.1506803 ]]\n",
      "\n",
      " [[ 0.17224422 -0.10114577  0.10630877 ... -0.13129729 -0.27138847\n",
      "    0.14768685]\n",
      "  [ 0.170458   -0.10158765  0.10812944 ... -0.13101292 -0.27175888\n",
      "    0.14947991]\n",
      "  [ 0.17201021 -0.09873243  0.10621957 ... -0.13031156 -0.2687309\n",
      "    0.1482716 ]\n",
      "  [ 0.17286429 -0.09990538  0.104384   ... -0.13120599 -0.27025574\n",
      "    0.14890015]\n",
      "  [ 0.17191301 -0.09979012  0.10411049 ... -0.13174023 -0.26914194\n",
      "    0.14564046]]\n",
      "\n",
      " [[ 0.10522623  0.007063    0.17441152 ... -0.21797249 -0.273328\n",
      "    0.16998954]\n",
      "  [ 0.1057517   0.00514353  0.17447959 ... -0.21739508 -0.27623755\n",
      "    0.17002095]\n",
      "  [ 0.10530069  0.00616678  0.17077623 ... -0.21591783 -0.2759951\n",
      "    0.16819301]\n",
      "  [ 0.10424614  0.00428849  0.1753379  ... -0.21800168 -0.27408937\n",
      "    0.17140776]\n",
      "  [ 0.10500143  0.00626383  0.17156199 ... -0.21646366 -0.27393007\n",
      "    0.17024507]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.18641075 -0.1757738   0.08305187 ... -0.14880456 -0.2114591\n",
      "    0.31071216]\n",
      "  [ 0.18729077 -0.17599463  0.08103058 ... -0.15063755 -0.21096127\n",
      "    0.31221285]\n",
      "  [ 0.18714556 -0.17787741  0.08157025 ... -0.1502662  -0.20880432\n",
      "    0.31259114]\n",
      "  [ 0.18720178 -0.17485519  0.08338966 ... -0.15122531 -0.20917675\n",
      "    0.31358734]\n",
      "  [ 0.18597765 -0.17887333  0.08073638 ... -0.15109573 -0.21235606\n",
      "    0.31241053]]\n",
      "\n",
      " [[ 0.08932132 -0.08396795  0.13687727 ... -0.18712305 -0.25603536\n",
      "    0.12250617]\n",
      "  [ 0.09098979 -0.0806176   0.13821891 ... -0.1908949  -0.2544287\n",
      "    0.12011376]\n",
      "  [ 0.0898917  -0.08041263  0.13668926 ... -0.18778685 -0.25438887\n",
      "    0.11998239]\n",
      "  [ 0.09028089 -0.07425012  0.13367942 ... -0.18924858 -0.25740737\n",
      "    0.12045595]\n",
      "  [ 0.08891513 -0.07634719  0.13491353 ... -0.18874319 -0.25792035\n",
      "    0.12275201]]\n",
      "\n",
      " [[ 0.21029313 -0.20213261  0.24051817 ... -0.30156466 -0.22693957\n",
      "    0.2417438 ]\n",
      "  [ 0.20938748 -0.20107651  0.24223222 ... -0.30347872 -0.22617559\n",
      "    0.23892924]\n",
      "  [ 0.21227431 -0.20128813  0.24118662 ... -0.30432764 -0.22202262\n",
      "    0.23838916]\n",
      "  [ 0.21098325 -0.20124815  0.23737326 ... -0.30294475 -0.22825235\n",
      "    0.24022354]\n",
      "  [ 0.21023715 -0.19985078  0.23986484 ... -0.30208147 -0.22636195\n",
      "    0.24125464]]], shape=(64, 5, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from numpy import random\n",
    "from tensorflow import math, matmul, reshape, shape, transpose, cast, float32\n",
    "from tensorflow.keras.layers import Dense, Layer\n",
    "from tensorflow.keras.backend import softmax\n",
    "\n",
    "# Implementing the Scaled-Dot Product Attention\n",
    "class DotProductAttention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, queries, keys, values, d_k, mask=None):\n",
    "        # Scoring the queries against the keys after transposing the latter, and scaling\n",
    "        scores = matmul(queries, keys, transpose_b=True) / math.sqrt(cast(d_k, float32))\n",
    "\n",
    "        # Apply mask to the attention scores\n",
    "        if mask is not None:\n",
    "            scores += -1e9 * mask\n",
    "\n",
    "        # Computing the weights by a softmax operation\n",
    "        weights = softmax(scores)\n",
    "\n",
    "        # Computing the attention by a weighted sum of the value vectors\n",
    "        return matmul(weights, values)\n",
    "\n",
    "# Implementing the Multi-Head Attention\n",
    "class MultiHeadAttention(Layer):\n",
    "    def __init__(self, h, d_k, d_v, d_model, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.attention = DotProductAttention()  # Scaled dot product attention\n",
    "        self.heads = h  # Number of attention heads to use\n",
    "        self.d_k = d_k  # Dimensionality of the linearly projected queries and keys\n",
    "        self.d_v = d_v  # Dimensionality of the linearly projected values\n",
    "        self.d_model = d_model  # Dimensionality of the model\n",
    "        self.W_q = Dense(d_k)   # Learned projection matrix for the queries\n",
    "        self.W_k = Dense(d_k)   # Learned projection matrix for the keys\n",
    "        self.W_v = Dense(d_v)   # Learned projection matrix for the values\n",
    "        self.W_o = Dense(d_model) # Learned projection matrix for the multi-head output\n",
    "\n",
    "    def reshape_tensor(self, x, heads, flag):\n",
    "        if flag:\n",
    "            # Tensor shape after reshaping and transposing:\n",
    "            # (batch_size, heads, seq_length, -1)\n",
    "            x = reshape(x, shape=(shape(x)[0], shape(x)[1], heads, -1))\n",
    "            x = transpose(x, perm=(0, 2, 1, 3))\n",
    "        else:\n",
    "            # Reverting the reshaping and transposing operations:\n",
    "            # (batch_size, seq_length, d_k)\n",
    "            x = transpose(x, perm=(0, 2, 1, 3))\n",
    "            x = reshape(x, shape=(shape(x)[0], shape(x)[1], self.d_k))\n",
    "        return x\n",
    "\n",
    "    def call(self, queries, keys, values, mask=None):\n",
    "        # Rearrange the queries to be able to compute all heads in parallel\n",
    "        q_reshaped = self.reshape_tensor(self.W_q(queries), self.heads, True)\n",
    "        # Resulting tensor shape: (batch_size, heads, input_seq_length, -1)\n",
    "\n",
    "        # Rearrange the keys to be able to compute all heads in parallel\n",
    "        k_reshaped = self.reshape_tensor(self.W_k(keys), self.heads, True)\n",
    "        # Resulting tensor shape: (batch_size, heads, input_seq_length, -1)\n",
    "\n",
    "        # Rearrange the values to be able to compute all heads in parallel\n",
    "        v_reshaped = self.reshape_tensor(self.W_v(values), self.heads, True)\n",
    "        # Resulting tensor shape: (batch_size, heads, input_seq_length, -1)\n",
    "\n",
    "        # Compute the multi-head attention output using the reshaped queries,\n",
    "        # keys, and values\n",
    "        o_reshaped = self.attention(q_reshaped, k_reshaped, v_reshaped, self.d_k, mask)\n",
    "        # Resulting tensor shape: (batch_size, heads, input_seq_length, -1)\n",
    "\n",
    "        # Rearrange back the output into concatenated form\n",
    "        output = self.reshape_tensor(o_reshaped, self.heads, False)\n",
    "        # Resulting tensor shape: (batch_size, input_seq_length, d_v)\n",
    "\n",
    "        # Apply one final linear projection to the output to generate the multi-head\n",
    "        # attention. Resulting tensor shape: (batch_size, input_seq_length, d_model)\n",
    "        return self.W_o(output)\n",
    "\n",
    "input_seq_length = 5  # Maximum length of the input sequence\n",
    "h = 8  # Number of self-attention heads\n",
    "d_k = 64  # Dimensionality of the linearly projected queries and keys\n",
    "d_v = 64  # Dimensionality of the linearly projected values\n",
    "d_model = 512  # Dimensionality of the model sub-layers' outputs\n",
    "batch_size = 64  # Batch size from the training process\n",
    "\n",
    "queries = random.random((batch_size, input_seq_length, d_k))\n",
    "keys = random.random((batch_size, input_seq_length, d_k))\n",
    "values = random.random((batch_size, input_seq_length, d_v))\n",
    "\n",
    "multihead_attention = MultiHeadAttention(h, d_k, d_v, d_model)\n",
    "print(multihead_attention(queries, keys, values))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
