{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ba60d2b-5497-43ae-b513-2add24be2364",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer, Dropout\n",
    "from multihead_attention import MultiHeadAttention\n",
    "from positional_encoding import PositionEmbeddingFixedWeights\n",
    "from encoder import AddNormalization, FeedForward\n",
    "\n",
    "# Implementing the Decoder Layer\n",
    "class DecoderLayer(Layer):\n",
    "    def __init__(self, h, d_k, d_v, d_model, d_ff, rate, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.multihead_attention1 = MultiHeadAttention(h, d_k, d_v, d_model)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.add_norm1 = AddNormalization()\n",
    "        self.multihead_attention2 = MultiHeadAttention(h, d_k, d_v, d_model)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "        self.add_norm2 = AddNormalization()\n",
    "        self.feed_forward = FeedForward(d_ff, d_model)\n",
    "        self.dropout3 = Dropout(rate)\n",
    "        self.add_norm3 = AddNormalization()\n",
    "\n",
    "    def call(self, x, encoder_output, lookahead_mask, padding_mask, training):\n",
    "        # Multi-head attention layer\n",
    "        multihead_output1 = self.multihead_attention1(x, x, x, lookahead_mask)\n",
    "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
    "\n",
    "        # Add in a dropout layer\n",
    "        multihead_output1 = self.dropout1(multihead_output1, training=training)\n",
    "\n",
    "        # Followed by an Add & Norm layer\n",
    "        addnorm_output1 = self.add_norm1(x, multihead_output1)\n",
    "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
    "\n",
    "        # Followed by another multi-head attention layer\n",
    "        multihead_output2 = self.multihead_attention2(addnorm_output1, encoder_output,\n",
    "                                                      encoder_output, padding_mask)\n",
    "\n",
    "        # Add in another dropout layer\n",
    "        multihead_output2 = self.dropout2(multihead_output2, training=training)\n",
    "\n",
    "        # Followed by another Add & Norm layer\n",
    "        addnorm_output2 = self.add_norm1(addnorm_output1, multihead_output2)\n",
    "\n",
    "        # Followed by a fully connected layer\n",
    "        feedforward_output = self.feed_forward(addnorm_output2)\n",
    "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
    "\n",
    "        # Add in another dropout layer\n",
    "        feedforward_output = self.dropout3(feedforward_output, training=training)\n",
    "\n",
    "        # Followed by another Add & Norm layer\n",
    "        return self.add_norm3(addnorm_output2, feedforward_output)\n",
    "\n",
    "# Implementing the Decoder\n",
    "class Decoder(Layer):\n",
    "    def __init__(self, vocab_size, sequence_length, h, d_k, d_v, d_model, d_ff, n, rate,\n",
    "                       **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.pos_encoding = PositionEmbeddingFixedWeights(sequence_length, vocab_size,\n",
    "                                                          d_model)\n",
    "        self.dropout = Dropout(rate)\n",
    "        self.decoder_layer = [DecoderLayer(h, d_k, d_v, d_model, d_ff, rate)\n",
    "                              for _ in range(n)]\n",
    "\n",
    "    def call(self, output_target, encoder_output, lookahead_mask, padding_mask, training):\n",
    "        # Generate the positional encoding\n",
    "        pos_encoding_output = self.pos_encoding(output_target)\n",
    "        # Expected output shape = (number of sentences, sequence_length, d_model)\n",
    "\n",
    "        # Add in a dropout layer\n",
    "        x = self.dropout(pos_encoding_output, training=training)\n",
    "\n",
    "        # Pass on the positional encoded values to each encoder layer\n",
    "        for i, layer in enumerate(self.decoder_layer):\n",
    "            x = layer(x, encoder_output, lookahead_mask, padding_mask, training)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9274f2cc-49ad-4830-a020-c4ba4d7a5f43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 5.59292734e-01  2.22355103e+00  8.90909553e-01 ... -6.09971173e-02\n",
      "   -6.35553181e-01  8.29461038e-01]\n",
      "  [ 7.05478668e-01  2.11158848e+00  9.99278367e-01 ... -1.04395814e-01\n",
      "   -5.79155445e-01  8.66090357e-01]\n",
      "  [ 7.71365881e-01  1.95511222e+00  1.05124640e+00 ... -1.23381428e-01\n",
      "   -5.83396375e-01  8.99097681e-01]\n",
      "  [ 7.01974511e-01  1.89787149e+00  1.03085983e+00 ... -1.00039996e-01\n",
      "   -6.64912522e-01  9.04673457e-01]\n",
      "  [ 5.96575499e-01  1.99210775e+00  9.78299022e-01 ... -5.73276468e-02\n",
      "   -7.85927117e-01  8.82083058e-01]]\n",
      "\n",
      " [[ 5.90836883e-01  2.06313276e+00  8.56066108e-01 ... -3.16971004e-01\n",
      "   -3.51730548e-02  3.58320236e-01]\n",
      "  [ 7.37101078e-01  1.94755530e+00  9.57652867e-01 ... -3.58320594e-01\n",
      "   -4.10323468e-04  3.77308875e-01]\n",
      "  [ 8.00618887e-01  1.74622035e+00  1.01516020e+00 ... -3.84285212e-01\n",
      "   -3.62545624e-02  3.99406344e-01]\n",
      "  [ 7.48370111e-01  1.68027985e+00  1.01611507e+00 ... -3.65799397e-01\n",
      "   -1.39343560e-01  3.74735504e-01]\n",
      "  [ 6.32403493e-01  1.79703224e+00  9.60118294e-01 ... -3.11731935e-01\n",
      "   -2.75833815e-01  3.34839970e-01]]\n",
      "\n",
      " [[ 8.36665750e-01  2.02609682e+00  1.08519900e+00 ... -3.37501496e-01\n",
      "   -1.49105757e-01  4.09177512e-01]\n",
      "  [ 9.71379757e-01  1.91419363e+00  1.19396377e+00 ... -3.83381307e-01\n",
      "   -8.66841003e-02  4.73878682e-01]\n",
      "  [ 1.01159704e+00  1.73787844e+00  1.26003695e+00 ... -4.23369676e-01\n",
      "   -1.08666509e-01  5.27222514e-01]\n",
      "  [ 9.29859519e-01  1.67859507e+00  1.22586024e+00 ... -4.12156492e-01\n",
      "   -2.28637710e-01  5.12296915e-01]\n",
      "  [ 8.19754422e-01  1.80843174e+00  1.15663207e+00 ... -3.42865199e-01\n",
      "   -3.57670307e-01  4.75410640e-01]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 4.22385484e-01  1.91966403e+00  8.89733732e-01 ... -3.80226433e-01\n",
      "   -4.68652070e-01  3.66907269e-01]\n",
      "  [ 5.51492214e-01  1.80147946e+00  1.00146747e+00 ... -4.38799024e-01\n",
      "   -4.13383991e-01  3.92646015e-01]\n",
      "  [ 6.07124388e-01  1.61938119e+00  1.08288002e+00 ... -4.77913886e-01\n",
      "   -4.23969626e-01  4.05334771e-01]\n",
      "  [ 5.36146581e-01  1.55342495e+00  1.08082664e+00 ... -4.75072205e-01\n",
      "   -5.27444005e-01  3.91931057e-01]\n",
      "  [ 4.16907609e-01  1.66870034e+00  1.02746224e+00 ... -4.37179685e-01\n",
      "   -6.79957032e-01  3.66875798e-01]]\n",
      "\n",
      " [[ 7.83095062e-01  1.97461045e+00  9.41218197e-01 ... -1.77007228e-01\n",
      "   -3.54161531e-01  6.25953317e-01]\n",
      "  [ 9.31472778e-01  1.84738696e+00  1.04107702e+00 ... -2.37113729e-01\n",
      "   -3.06847543e-01  6.54498935e-01]\n",
      "  [ 9.79343534e-01  1.66867769e+00  1.10462725e+00 ... -2.63244838e-01\n",
      "   -3.11306268e-01  6.65959120e-01]\n",
      "  [ 9.02856052e-01  1.60571051e+00  1.09772694e+00 ... -2.39027277e-01\n",
      "   -3.91397178e-01  6.62462592e-01]\n",
      "  [ 7.68049657e-01  1.71878195e+00  1.04592526e+00 ... -1.85230598e-01\n",
      "   -5.26419938e-01  6.28814697e-01]]\n",
      "\n",
      " [[ 6.78489149e-01  2.05604529e+00  7.56409466e-01 ... -2.21565232e-01\n",
      "   -6.00156128e-01  7.25868702e-01]\n",
      "  [ 8.08280647e-01  1.92725027e+00  8.53899121e-01 ... -2.70986110e-01\n",
      "   -5.64006388e-01  7.71672785e-01]\n",
      "  [ 8.61296058e-01  1.73372447e+00  9.08912241e-01 ... -3.21428359e-01\n",
      "   -5.87795556e-01  8.18383515e-01]\n",
      "  [ 8.05743575e-01  1.64984262e+00  8.75490129e-01 ... -3.28396529e-01\n",
      "   -7.01071978e-01  8.24526250e-01]\n",
      "  [ 6.86202645e-01  1.75042784e+00  8.05305362e-01 ... -2.85305411e-01\n",
      "   -8.48905563e-01  7.93084145e-01]]], shape=(64, 5, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from numpy import random\n",
    "from tensorflow.keras.layers import Layer, Dropout\n",
    "from multihead_attention import MultiHeadAttention\n",
    "from positional_encoding import PositionEmbeddingFixedWeights\n",
    "from encoder import AddNormalization, FeedForward\n",
    "\n",
    "# Implementing the Decoder Layer\n",
    "class DecoderLayer(Layer):\n",
    "    def __init__(self, h, d_k, d_v, d_model, d_ff, rate, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.multihead_attention1 = MultiHeadAttention(h, d_k, d_v, d_model)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.add_norm1 = AddNormalization()\n",
    "        self.multihead_attention2 = MultiHeadAttention(h, d_k, d_v, d_model)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "        self.add_norm2 = AddNormalization()\n",
    "        self.feed_forward = FeedForward(d_ff, d_model)\n",
    "        self.dropout3 = Dropout(rate)\n",
    "        self.add_norm3 = AddNormalization()\n",
    "\n",
    "    def call(self, x, encoder_output, lookahead_mask, padding_mask, training):\n",
    "        # Multi-head attention layer\n",
    "        multihead_output1 = self.multihead_attention1(x, x, x, lookahead_mask)\n",
    "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
    "\n",
    "        # Add in a dropout layer\n",
    "        multihead_output1 = self.dropout1(multihead_output1, training=training)\n",
    "\n",
    "        # Followed by an Add & Norm layer\n",
    "        addnorm_output1 = self.add_norm1(x, multihead_output1)\n",
    "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
    "\n",
    "        # Followed by another multi-head attention layer\n",
    "        multihead_output2 = self.multihead_attention2(addnorm_output1, encoder_output,\n",
    "                                                      encoder_output, padding_mask)\n",
    "\n",
    "        # Add in another dropout layer\n",
    "        multihead_output2 = self.dropout2(multihead_output2, training=training)\n",
    "\n",
    "        # Followed by another Add & Norm layer\n",
    "        addnorm_output2 = self.add_norm1(addnorm_output1, multihead_output2)\n",
    "\n",
    "        # Followed by a fully connected layer\n",
    "        feedforward_output = self.feed_forward(addnorm_output2)\n",
    "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
    "\n",
    "        # Add in another dropout layer\n",
    "        feedforward_output = self.dropout3(feedforward_output, training=training)\n",
    "\n",
    "        # Followed by another Add & Norm layer\n",
    "        return self.add_norm3(addnorm_output2, feedforward_output)\n",
    "\n",
    "# Implementing the Decoder\n",
    "class Decoder(Layer):\n",
    "    def __init__(self, vocab_size, sequence_length, h, d_k, d_v, d_model, d_ff, n, rate,\n",
    "                       **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.pos_encoding = PositionEmbeddingFixedWeights(sequence_length, vocab_size,\n",
    "                                                          d_model)\n",
    "        self.dropout = Dropout(rate)\n",
    "        self.decoder_layer = [DecoderLayer(h, d_k, d_v, d_model, d_ff, rate)\n",
    "                              for _ in range(n)]\n",
    "\n",
    "    def call(self, output_target, encoder_output, lookahead_mask, padding_mask, training):\n",
    "        # Generate the positional encoding\n",
    "        pos_encoding_output = self.pos_encoding(output_target)\n",
    "        # Expected output shape = (number of sentences, sequence_length, d_model)\n",
    "\n",
    "        # Add in a dropout layer\n",
    "        x = self.dropout(pos_encoding_output, training=training)\n",
    "\n",
    "        # Pass on the positional encoded values to each encoder layer\n",
    "        for i, layer in enumerate(self.decoder_layer):\n",
    "            x = layer(x, encoder_output, lookahead_mask, padding_mask, training)\n",
    "\n",
    "        return x\n",
    "\n",
    "dec_vocab_size = 20  # Vocabulary size for the decoder\n",
    "input_seq_length = 5  # Maximum length of the input sequence\n",
    "h = 8  # Number of self-attention heads\n",
    "d_k = 64  # Dimensionality of the linearly projected queries and keys\n",
    "d_v = 64  # Dimensionality of the linearly projected values\n",
    "d_ff = 2048  # Dimensionality of the inner fully connected layer\n",
    "d_model = 512  # Dimensionality of the model sub-layers' outputs\n",
    "n = 6  # Number of layers in the decoder stack\n",
    "\n",
    "batch_size = 64  # Batch size from the training process\n",
    "dropout_rate = 0.1  # Frequency of dropping the input units in the dropout layers\n",
    "\n",
    "input_seq = random.random((batch_size, input_seq_length))\n",
    "enc_output = random.random((batch_size, input_seq_length, d_model))\n",
    "\n",
    "decoder = Decoder(dec_vocab_size, input_seq_length, h, d_k, d_v, d_model, d_ff, n,\n",
    "                  dropout_rate)\n",
    "print(decoder(input_seq, enc_output, None, True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
